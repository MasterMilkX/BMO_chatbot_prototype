{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALGORITHM\n",
    "\n",
    "TRAINING\n",
    "1. Generate a noisy sprite\n",
    "2. Choose the closest goal sprite from the training data (hamming distance)\n",
    "3. Destroy the goal sprite (sequentially over pixles) until it matches the noisy sprite\n",
    "4. Add the level repair step to the training data\n",
    "5. Repeat until it matches the noise\n",
    "\n",
    "---\n",
    "\n",
    "GENERATION \n",
    "1. Initialize a noisy sprite\n",
    "2. Randomly or sequentially pick/fix a pixel\n",
    "3. Feed the level into the network to output a repair value\n",
    "4. Update the pixel with the value\n",
    "5. If the current sprite isn't valid, keep going"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Conv2D, Conv2DTranspose, Flatten, Layer, Reshape, Input, LeakyReLU, MaxPooling2D, Concatenate, Conv1D, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import from Python folder to get the utils\n",
    "import sys\n",
    "sys.path.append('../Python')\n",
    "from utils import picoSS2np, showMultiSprPalette, showMultiSprRGB, showSprRGB, showSprPalette, animatePal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANT VARIABLES   ###\n",
    "\n",
    "# PICO-8 Palette => use colormap for matplotlib\n",
    "PICO_PALETTE = ['#000000','#1D2B53','#7E2553','#008751','#AB5236','#5F574F','#C2C3C7','#FFF1E8','#FF004D','#FFA300','#FFEC27','#00E436','#29ADFF','#83769C','#FF77A8','#FFCCAA']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food Dataset shape: (100, 8, 8)\n",
      "Char Dataset shape: (100, 8, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import from the PICO sprites posted onto Twitter \n",
    "# Food: https://twitter.com/JUSTIN_CYR/status/634546317713391616\n",
    "# Characters: https://twitter.com/johanvinet/status/635814153601597441\n",
    "pico_food_dat = np.load('../data/rip_data/pico_food.npy',allow_pickle=True)\n",
    "pico_char_dat = np.load('../data/rip_data/pico_characters.npy',allow_pickle=True)\n",
    "\n",
    "print(f\"Food Dataset shape: {pico_food_dat.shape}\")\n",
    "print(f\"Char Dataset shape: {pico_char_dat.shape}\")\n",
    "\n",
    "# show a random food and character sprite \n",
    "rand_food = random.choice(pico_food_dat)\n",
    "rand_char = random.choice(pico_char_dat)\n",
    "showMultiSprPalette([rand_food,rand_char],textArr=['Food','Character'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding labels: 100%|██████████| 100/100 [00:07<00:00, 14.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# import sentence-transformer for text embedding \n",
    "SBERT_MODEL = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "def sentEmb(txt):\n",
    "    return SBERT_MODEL.encode([txt])[0]\n",
    "\n",
    "# import the text data\n",
    "pico_char_labels = np.array([l.strip() for l in open('../data/rip_data/character_desc.txt','r').readlines()])\n",
    "\n",
    "# encode the labels\n",
    "pico_char_labels_emb = []\n",
    "with tqdm(total=len(pico_char_labels)) as pbar:\n",
    "    pbar.set_description(\"Encoding labels\")\n",
    "    for l in pico_char_labels:\n",
    "        pico_char_labels_emb.append(sentEmb(l))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character: a large yellow turtle with red hair and a large mouth\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADKklEQVR4nO3dIa9XdRzH8XMc3UIwwEZxPAM2gnQLG8KEoMFAMFlIBDYlMBLNJ0DjXuamD4HAhnSDhWDwbhYtNg+ZDbcz9tX/fbPXK999zj+89yt3v/3Wbdu2BWI+OPQPgHchXJKES5JwSRIuScIlSbgkCZck4ZJ0Zu8fruv6X/6Od7b9+fvs4Ie3Z/eGrMtPY1v3Pr4+trUsy/Ldr0/Htvb+I9eJS5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSdp9dWfUg2sH+ewe628nc2PnXoxNbS+fjG1N+3a5+b9/04lLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJ2n11Z/J1m/X7r8e2jr+6Ora1LMuy3b0zN/Zyboo3OXFJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVp952zyXti27kfxraOf740tnWqHf1z6F/wr9aHt8a2tm3b9XdOXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES9K67b0r8dfJ3Fd//Ghsav1ybGpZlmXZ/rg4N/bq/tzWafbL53NbX7i6w3tMuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQd5NWdo9GXcl4Mbs169vf5sa1PXl0e2xq/7vR4dm8PJy5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVp96s767qOffQQVz32enbh+aF/wludPPpmbOvGtdnrTpNXgfY+AuXEJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXpN3PRZ1an14cnbtydu5ZpklHn00+sdXnxCVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCTtfi4KThMnLknCJUm4JAmXJOGSJFyShEuScEkSLkmvAegGUeo/jr35AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding length: 768\n"
     ]
    }
   ],
   "source": [
    "# show a random character and its description\n",
    "rand_char_idx = random.randint(0,len(pico_char_labels))\n",
    "print(f\"Character: {pico_char_labels[rand_char_idx]}\")\n",
    "showSprPalette(pico_char_dat[rand_char_idx])\n",
    "\n",
    "desc_enc = pico_char_labels_emb[rand_char_idx]\n",
    "print(f\"Encoding length: {len(desc_enc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   CONFIUGURATIONS   ###\n",
    "\n",
    "EXPERIMENT = \"no_act-te\"\n",
    "\n",
    "GEN_CONF = {\n",
    "    \"EPOCHS\" : 50,\n",
    "    \"BATCH_SIZE\" : 64,\n",
    "    \"LEARNING_RATE\" : 0.0001,\n",
    "    \"WINDOW\" : 8\n",
    "}\n",
    "\n",
    "CONFIGS = {\n",
    "    \"normal\": {\n",
    "        \"NEW_TRAIN_DAT\" : True,\n",
    "        \"TRAIN_DAT_PATH\" : f'../data/rip_data/POD_dat/POD_train_dat_w{GEN_CONF[\"WINDOW\"]}.npy',\n",
    "        \"TRAIN_NPOD\" : False,\n",
    "        \"NPOD_MODEL\" : f\"../models/gen_models/pod/npod_char-{GEN_CONF['EPOCHS']}eR_w{GEN_CONF['WINDOW']}.h5\",\n",
    "        \"SANITY\" : False\n",
    "    },\n",
    "    \"text_enc\": {\n",
    "        \"NEW_TRAIN_DAT\" : False,\n",
    "        \"TRAIN_DAT_PATH\" : f'../data/rip_data/POD_dat/tePOD_train_dat_w{GEN_CONF[\"WINDOW\"]}.npy',\n",
    "        \"TRAIN_TEPOD\" : False,\n",
    "        \"TEPOD_MODEL\" : f\"../models/gen_models/pod/tepod_char-{GEN_CONF['EPOCHS']}eR_w{GEN_CONF['WINDOW']}.h5\",\n",
    "        \"SANITY\" : False\n",
    "    },\n",
    "    \"no_act-te\": {\n",
    "        \"NEW_TRAIN_DAT\" : True,\n",
    "        \"TRAIN_DAT_PATH\" : f'../data/rip_data/POD_dat/tenaPOD_train_dat_w{GEN_CONF[\"WINDOW\"]}_QUARTER.npy',\n",
    "        \"TRAIN_TEPOD\" : False,\n",
    "        \"TEPOD_MODEL\" : f\"../models/gen_models/pod/tenapod_char-{GEN_CONF['EPOCHS']}eR_w{GEN_CONF['WINDOW']}_HALF.h5\",\n",
    "        \"SANITY\" : False\n",
    "    }   \n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal PoD\n",
    "\n",
    "---\n",
    "\n",
    "#### Notes\n",
    "\n",
    "[window size: 5]\n",
    "[epochs: 50]\n",
    "- Abstract art-esque - not quite character looking though\n",
    "\n",
    "[window size: 8]\n",
    "[epochs: 50]\n",
    "- More character definition. Much more cohesive\n",
    "\n",
    "[window size: 9]\n",
    "[epochs: 50]\n",
    "- Not much change but makes a 'character' at earlier iterations\n",
    "\n",
    "[window size: 9 - TMNT edition]\n",
    "[epochs: 10 (reached 98%)]\n",
    "- perfectly recreates ninja turtles every time; can replace a tile with the same tile\n",
    "\n",
    "[window size: 4]\n",
    "[epochs: 50]\n",
    "- \"there is a SHAPE\" - Dipika\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalPoD():\n",
    "    def __init__(self,spr_shape, channels=16, pad_val=0, crop_size=5):\n",
    "        self.destroy_data = []\n",
    "        self.spr_shape = spr_shape\n",
    "        self.channels = channels\n",
    "        self.pad_val = pad_val\n",
    "        self.crop_size = crop_size\n",
    "\n",
    "    # make a new noisy sprite using the channels and size\n",
    "    def init_noise_sprite(self):\n",
    "        noise_spr = np.random.randint(self.channels,size=(self.spr_shape[0],self.spr_shape[1]))\n",
    "        return noise_spr\n",
    "\n",
    "    # crop a sprite from the noise sprite (use with padding) - assume pos is (x,y) and center of target crop\n",
    "    def crop(self, spr, pos, size=5):\n",
    "        hpad = size//2\n",
    "        pad_spr = np.pad(spr,((hpad,hpad),(hpad,hpad)),constant_values=self.pad_val)   # pad the sprite \n",
    "        crop_spr = pad_spr[pos[0]:pos[0]+size,pos[1]:pos[1]+size]   # get the cropped sprite (should be size,size)\n",
    "        return pad_spr, crop_spr\n",
    "\n",
    "    # return the new level and the tile replaced (also add to training data) - assume pos is (x,y)\n",
    "    def destroy(self, cur_spr, bad_spr, pos, crop_size=5):\n",
    "        # turn the cur_spr value at the pos to the bad_spr value\n",
    "        cur_spr2 = np.copy(cur_spr)\n",
    "        og_val = cur_spr[pos[0],pos[1]]\n",
    "        cur_spr2[pos[0],pos[1]] = bad_spr[pos[0],pos[1]]\n",
    "\n",
    "        # crop around the area and add to training data\n",
    "        _, crop_spr = self.crop(cur_spr2,pos,crop_size)\n",
    "\n",
    "        return cur_spr2, og_val, crop_spr\n",
    "    \n",
    "    # calculate the hamming distance from 2 sprites\n",
    "    def calc_ham_dist(self, spr1, spr2):\n",
    "        return np.sum(spr1 != spr2)\n",
    "\n",
    "    # return the sprite that is closest in hamming distance from the goal set\n",
    "    def closest_spr(self, goal_set, noise_spr):\n",
    "        min_dist_i = np.argmin([self.calc_ham_dist(noise_spr, i) for i in goal_set])\n",
    "        return goal_set[min_dist_i]\n",
    "\n",
    "    \n",
    "    # make the training data for the path of destruction\n",
    "    def make_train_dat(self,goal_set,num_noise_spr=1000):\n",
    "        train_dat = []\n",
    "        with tqdm(total=num_noise_spr) as pbar:\n",
    "            for i in range(num_noise_spr):\n",
    "                # make a noise sprite and find the closest\n",
    "                # noise_spr = self.init_noise_sprite()\n",
    "                # targ_spr = self.closest_spr(goal_set,noise_spr).copy()\n",
    "\n",
    "                #go through each goal sprite and make a noise sprite for it\n",
    "                targ_spr = goal_set[i%len(goal_set)]\n",
    "                noise_spr = self.init_noise_sprite()\n",
    "\n",
    "                # make a list of all the positions in the sprite and shuffle it\n",
    "                pos_set = []\n",
    "                for x in range(self.spr_shape[0]):\n",
    "                    for y in range(self.spr_shape[1]):\n",
    "                        pos_set.append((x,y))\n",
    "                random.shuffle(pos_set)\n",
    "\n",
    "                # iterate over the goal sprite and change until it matches the noise spr (destroy)\n",
    "                for p in pos_set:\n",
    "                        # destroy the noise sprite\n",
    "                        targ_spr, og_val, crop_spr = self.destroy(targ_spr,noise_spr,p,self.crop_size)\n",
    "                        train_dat.append([crop_spr,og_val])\n",
    "                        # showSprPalette(targ_spr)\n",
    "                pbar.update(1)\n",
    "                    \n",
    "        return train_dat\n",
    "    \n",
    "    # make the path of destruction neural network model\n",
    "    # copy of architecture from the paper [Conv(128,3) -> Conv(128,3) -> MaxPool(2), Conv(256,3)]\n",
    "    # it doesn't work though... at least not with 5x5 crop size - need to ask Sam for exact implementation\n",
    "    def makePoDCNN(self):\n",
    "        self.pod_model = Sequential([\n",
    "            InputLayer(input_shape=(self.crop_size,self.crop_size,1)),\n",
    "            Conv2D(128, (3, 3), activation='relu',padding='SAME'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(128, (3, 3), activation='relu',padding='SAME'),\n",
    "            Conv2D(256, (3, 3), activation='relu',padding='SAME'),\n",
    "            Flatten(),\n",
    "            Dense(128),\n",
    "            Dense(self.channels,activation='softmax'),\n",
    "        ])\n",
    "        self.pod_model.summary()\n",
    "        self.opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "        self.pod_model.compile(optimizer=self.opt,metrics=['accuracy'],loss='sparse_categorical_crossentropy') #not one-hot encoded\n",
    "        \n",
    "        \n",
    "    # import a model from a path\n",
    "    def importModel(self,model_path):\n",
    "        self.pod_model = tf.keras.models.load_model(model_path)\n",
    "        self.pod_model.summary()\n",
    "        self.opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "        self.pod_model.compile(optimizer=self.opt,metrics=['accuracy'],loss='sparse_categorical_crossentropy')\n",
    "\n",
    "\n",
    "    # export the model to a path\n",
    "    def exportModel(self,model_path):\n",
    "        self.pod_model.save(model_path,save_format='h5')\n",
    "                            \n",
    "\n",
    "    # train the path of destruction model on the training data\n",
    "    def trainPoD(self,train_dat,EPOCHS=500,BATCH_SIZE=64,show_acc=False):\n",
    "        # train the model\n",
    "        X = np.array([i[0] for i in train_dat])\n",
    "        Y = np.array([i[1] for i in train_dat])\n",
    "        X = np.expand_dims(X,axis=-1)\n",
    "        Y = np.expand_dims(Y,axis=-1)\n",
    "        print(X.shape,Y.shape)\n",
    "\n",
    "        h = self.pod_model.fit(X,Y,epochs=EPOCHS,batch_size=BATCH_SIZE,shuffle=True)\n",
    "        if show_acc:\n",
    "            plt.plot(h.history['accuracy'])\n",
    "            plt.show()\n",
    "\n",
    "    # repair from a noise vector\n",
    "    def repair(self,init_spr=None,mod_iter='rand',eval_met='iter',num_iter=1000,animate=False):\n",
    "        # make a noise sprite\n",
    "        if init_spr is None:\n",
    "            init_spr = self.init_noise_sprite()\n",
    "        cur_spr = np.copy(init_spr)\n",
    "\n",
    "        if animate:\n",
    "            anim_set = []\n",
    "            anim_set.append(cur_spr)\n",
    "\n",
    "        # iterate over the noise sprite and change until the iterations are done\n",
    "        pi = 0\n",
    "        if eval_met == \"iter\":\n",
    "            with tqdm(total=num_iter) as pbar:\n",
    "                for i in range(num_iter):\n",
    "                    #select a position (randomly or sequentially)\n",
    "                    if mod_iter == \"rand\":\n",
    "                        x = np.random.randint(self.spr_shape[0])\n",
    "                        y = np.random.randint(self.spr_shape[1])\n",
    "                    else:\n",
    "                        x = pi%self.spr_shape[0]\n",
    "                        y = pi//self.spr_shape[0]\n",
    "                        pi += 1\n",
    "                        if pi >= self.spr_shape[0]*self.spr_shape[1]:\n",
    "                            pi = 0\n",
    "\n",
    "                    pbar.set_description(\"@ ({},{})\".format(x,y))\n",
    "\n",
    "                    #crop the area\n",
    "                    _, crop_spr = self.crop(cur_spr,(x,y),self.crop_size)\n",
    "                    \n",
    "                    # get the pixel change input from the model\n",
    "                    pred_px = self.pod_model.predict(np.array([crop_spr]),verbose=False)\n",
    "\n",
    "                    # change the tile\n",
    "                    cur_spr[x,y] = np.argmax(pred_px)\n",
    "\n",
    "                    anim_set.append(cur_spr.copy())\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "        if animate:\n",
    "            return init_spr, cur_spr, anim_set\n",
    "        return init_spr, cur_spr\n",
    "\n",
    "if EXPERIMENT == \"normal\":\n",
    "    # Make the Path of Destruction  model\n",
    "    npod = NormalPoD((8,8),channels=16,crop_size=GEN_CONF['WINDOW'])     \n",
    "    npod.makePoDCNN() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == \"normal\":\n",
    "\n",
    "    if CONFIGS[\"normal\"][\"NEW_TRAIN_DAT\"]:\n",
    "        # make the training data\n",
    "        goal_spr_char = pico_char_dat.copy()\n",
    "        train_dat = npod.make_train_dat(goal_spr_char,num_noise_spr=(len(goal_spr_char)*10))\n",
    "\n",
    "        # ninja turtle set\n",
    "        # turtle_spr_char = pico_char_dat[30:34]\n",
    "        # showMultiSprPalette(turtle_spr_char)\n",
    "        # train_dat = npod.make_train_dat(turtle_spr_char,num_noise_spr=(len(turtle_spr_char)*100))\n",
    "\n",
    "        print(len(train_dat))\n",
    "\n",
    "        # export as .npy file\n",
    "        np.save(CONFIGS[\"normal\"][\"TRAIN_DAT_PATH\"],train_dat)\n",
    "    else:\n",
    "        # import the training data\n",
    "        train_dat = np.load(CONFIGS['normal'][\"TRAIN_DAT_PATH\"],allow_pickle=True)\n",
    "        print(len(train_dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train or import the model\n",
    "if EXPERIMENT == \"normal\":\n",
    "    if CONFIGS[\"normal\"][\"TRAIN_NPOD\"]:\n",
    "        npod.trainPoD(train_dat,EPOCHS=GEN_CONF['EPOCHS'],BATCH_SIZE=GEN_CONF['BATCH_SIZE'],show_acc=True)\n",
    "        npod.exportModel(CONFIGS[\"normal\"][\"NPOD_MODEL\"])\n",
    "    else:\n",
    "        npod.importModel(CONFIGS[\"normal\"][\"NPOD_MODEL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the output from repairing a noise sprite\n",
    "if EXPERIMENT == \"normal\":\n",
    "    init_spr, cur_spr, anims = npod.repair(mod_iter='rand',num_iter=1069,animate=True)\n",
    "    showMultiSprPalette([init_spr,cur_spr],textArr=['init','final'])\n",
    "\n",
    "    # save the animation\n",
    "    animatePal(anims,f\"../prelim_output/pod_anim/npod_{GEN_CONF['EPOCHS']}e_w{GEN_CONF['WINDOW']}-2.gif\",fps=32,textArr=[f\"Iter: {i}\" for i in range(len(anims))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NPOD Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == \"normal\" and CONFIGS[\"normal\"][\"SANITY\"]:\n",
    "    # test destroy function\n",
    "    turt_spr = pico_char_dat[30]\n",
    "    n_spr = npod.init_noise_sprite()\n",
    "\n",
    "    pos = (4,4)\n",
    "    a,b,c = npod.destroy(turt_spr,n_spr,pos,crop_size=8)\n",
    "    b2d = np.full((2,2),b)\n",
    "    print(a.shape)\n",
    "    print(b2d.shape)\n",
    "    print(c.shape)\n",
    "\n",
    "    # showMultiSprPalette([turt_spr,n_spr], ['turt','noise'])\n",
    "    showMultiSprPalette([turt_spr,n_spr,a,b2d,c],textArr=['turt','noise','new turt','pixel','crop'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train data creation\n",
    "if EXPERIMENT == \"normal\" and CONFIGS[\"normal\"][\"SANITY\"]:\n",
    "    turt_spr = pico_char_dat[30]\n",
    "    tdat = npod.make_train_dat([turt_spr],num_noise_spr=1)\n",
    "    print(len(tdat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test output of the model\n",
    "if EXPERIMENT == \"normal\" and CONFIGS[\"normal\"][\"SANITY\"]:\n",
    "    turt_spr = pico_char_dat[0].copy()\n",
    "    turt_spr2 = turt_spr.copy()\n",
    "    turt_spr2[4,2] = 14\n",
    "    _,c = npod.crop(turt_spr2,(4,2),5)\n",
    "    print(c.shape)\n",
    "\n",
    "    #fix the sprite\n",
    "    new_px = npod.pod_model.predict(np.array([c]),verbose=False)\n",
    "    turt_spr3 = np.copy(turt_spr2)\n",
    "    turt_spr3[4,2] = np.argmax(new_px)\n",
    "\n",
    "    showMultiSprPalette([turt_spr,turt_spr2,turt_spr3],textArr=['OG','destroy','repair'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT ENCODED PoD\n",
    "Path of Destruction with an additional text embedding secondary input\n",
    "\n",
    "---\n",
    "\n",
    "#### Notes\n",
    "[window size: 8]\n",
    "[epochs: 50]\n",
    "- Much better and more consistent - works best on seen text. Can perfectly recreate direct from the dataset. Starts overwritting good pixels with more iterations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TECPoD():\n",
    "    def __init__(self,spr_shape, channels=16, pad_val=0, crop_size=5):\n",
    "        self.destroy_data = []\n",
    "        self.spr_shape = spr_shape\n",
    "        self.channels = channels\n",
    "        self.pad_val = pad_val\n",
    "        self.crop_size = crop_size\n",
    "\n",
    "        self.ENC_SIZE = 768\n",
    "\n",
    "    # make a new noisy sprite using the channels and size\n",
    "    def init_noise_sprite(self):\n",
    "        noise_spr = np.random.randint(self.channels,size=(self.spr_shape[0],self.spr_shape[1]))\n",
    "        return noise_spr\n",
    "\n",
    "    # crop a sprite from the noise sprite (use with padding) - assume pos is (x,y) and center of target crop\n",
    "    def crop(self, spr, pos, size=5):\n",
    "        hpad = size//2\n",
    "        pad_spr = np.pad(spr,((hpad,hpad),(hpad,hpad)),constant_values=self.pad_val)   # pad the sprite \n",
    "        crop_spr = pad_spr[pos[0]:pos[0]+size,pos[1]:pos[1]+size]   # get the cropped sprite (should be size,size)\n",
    "        return pad_spr, crop_spr\n",
    "\n",
    "    # return the new level and the tile replaced (also add to training data) - assume pos is (x,y)\n",
    "    def destroy(self, cur_spr, bad_spr, pos, crop_size=5):\n",
    "        # turn the cur_spr value at the pos to the bad_spr value\n",
    "        cur_spr2 = np.copy(cur_spr)\n",
    "        og_val = cur_spr[pos[0],pos[1]]\n",
    "        cur_spr2[pos[0],pos[1]] = bad_spr[pos[0],pos[1]]\n",
    "\n",
    "        # crop around the area and add to training data\n",
    "        _, crop_spr = self.crop(cur_spr2,pos,crop_size)\n",
    "\n",
    "        return cur_spr2, og_val, crop_spr\n",
    "    \n",
    "    # calculate the hamming distance from 2 sprites\n",
    "    def calc_ham_dist(self, spr1, spr2):\n",
    "        return np.sum(spr1 != spr2)\n",
    "\n",
    "    # return the sprite that is closest in hamming distance from the goal set\n",
    "    def closest_spr(self, goal_set, noise_spr):\n",
    "        min_dist_i = np.argmin([self.calc_ham_dist(noise_spr, i) for i in goal_set])\n",
    "        return goal_set[min_dist_i]\n",
    "\n",
    "    \n",
    "    # make the training data for the path of destruction\n",
    "    def make_train_dat(self,goal_img_set,goal_enc_set,num_noise_spr=1000):\n",
    "        train_dat = []\n",
    "        with tqdm(total=num_noise_spr) as pbar:\n",
    "            for i in range(num_noise_spr):\n",
    "                # make a noise sprite and find the closest\n",
    "                # noise_spr = self.init_noise_sprite()\n",
    "                # targ_spr = self.closest_spr(goal_set,noise_spr).copy()\n",
    "\n",
    "                #go through each goal sprite (with associated annotation) and make a noise sprite for it\n",
    "                targ_spr = goal_img_set[i%len(goal_img_set)]\n",
    "                in_enc = goal_enc_set[i%len(goal_enc_set)]\n",
    "                noise_spr = self.init_noise_sprite()\n",
    "\n",
    "                # make a list of all the positions in the sprite and shuffle it\n",
    "                pos_set = []\n",
    "                for x in range(self.spr_shape[0]):\n",
    "                    for y in range(self.spr_shape[1]):\n",
    "                        pos_set.append((x,y))\n",
    "                random.shuffle(pos_set)\n",
    "\n",
    "                # iterate over the goal sprite and change until it matches the noise spr (destroy)\n",
    "                for p in pos_set:\n",
    "                    # destroy the noise sprite\n",
    "                    targ_spr, og_val, crop_spr = self.destroy(targ_spr,noise_spr,p,self.crop_size)\n",
    "                    train_dat.append([crop_spr,in_enc,og_val])\n",
    "                    # showSprPalette(targ_spr)\n",
    "                pbar.update(1)\n",
    "                    \n",
    "        return train_dat\n",
    "    \n",
    "    # make the path of destruction neural network model\n",
    "    # copy of architecture from the paper [Conv(128,3) -> Conv(128,3) -> MaxPool(2), Conv(256,3)]\n",
    "    # it doesn't work though... at least not with 5x5 crop size - need to ask Sam for exact implementation\n",
    "    def makePoDCNN(self):\n",
    "\n",
    "        # image input\n",
    "        in1 = Input(shape=(self.crop_size,self.crop_size,1))\n",
    "        in1 = Lambda(lambda x: K.cast(x, dtype='float32'))(in1)\n",
    "\n",
    "        # text encoding input\n",
    "        in2 = Input(shape=(self.ENC_SIZE,)),\n",
    "        in2r = K.reshape(in2,(-1,8,8,12))     #needs these 2 lines even though they are redundant\n",
    "        in2f = Flatten()(in2r)\n",
    "        in2d = Dense(self.crop_size*self.crop_size)(in2f)\n",
    "        in2r2 = K.reshape(in2d,(-1,self.crop_size,self.crop_size,1))\n",
    "        # in2r2 = Conv1D(1, 3, activation='relu',padding='SAME')(in2r)\n",
    "\n",
    "        # combined and sent through the CNN\n",
    "        x = Concatenate(axis=-1)([in1,in2r2])\n",
    "        x = Conv2D(128, (3, 3), activation='relu',padding='SAME')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Conv2D(128, (3, 3), activation='relu',padding='SAME')(x)\n",
    "        x = Conv2D(256, (3, 3), activation='relu',padding='SAME')(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        out1 = Dense(self.channels,activation='softmax')(x)\n",
    "\n",
    "        self.pod_model = Model(inputs=[in1,in2], outputs=out1)\n",
    "        self.pod_model.summary()\n",
    "        self.opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "        self.pod_model.compile(optimizer=self.opt,metrics=['accuracy'],loss='sparse_categorical_crossentropy') #not one-hot encoded\n",
    "        \n",
    "        \n",
    "    # import a model from a path\n",
    "    def importModel(self,model_path):\n",
    "        self.pod_model = tf.keras.models.load_model(model_path)\n",
    "        self.pod_model.summary()\n",
    "        self.opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "        self.pod_model.compile(optimizer=self.opt,metrics=['accuracy'],loss='sparse_categorical_crossentropy')\n",
    "\n",
    "\n",
    "    # export the model to a path\n",
    "    def exportModel(self,model_path):\n",
    "        self.pod_model.save(model_path,save_format='h5')\n",
    "                            \n",
    "\n",
    "    # train the path of destruction model on the training data\n",
    "    def trainPoD(self,train_dat,EPOCHS=500,BATCH_SIZE=64,show_acc=False):\n",
    "        # train the model\n",
    "        X1 = np.array([i[0] for i in train_dat])\n",
    "        X2 = np.array([i[1] for i in train_dat])\n",
    "        Y = np.array([i[2] for i in train_dat])\n",
    "        X1 = np.expand_dims(X1,axis=-1)\n",
    "        # X2 = np.expand_dims(X2,axis=-1)\n",
    "        Y = np.expand_dims(Y,axis=-1)\n",
    "        print(X1.shape,X2.shape,Y.shape)\n",
    "\n",
    "        h = self.pod_model.fit([X1,X2],Y,epochs=EPOCHS,batch_size=BATCH_SIZE,shuffle=True)\n",
    "        if show_acc:\n",
    "            plt.plot(h.history['accuracy'])\n",
    "            plt.show()\n",
    "\n",
    "    # repair from a noise vector\n",
    "    def repair(self,text_in,init_spr=None,mod_iter='rand',eval_met='iter',num_iter=1000,animate=False):\n",
    "        #encode the text\n",
    "        text_enc = sentEmb(text_in)\n",
    "        text_enc = np.expand_dims(text_enc,axis=0)\n",
    "        print(text_enc.shape)\n",
    "\n",
    "        # make a noise sprite\n",
    "        if init_spr is None:\n",
    "            init_spr = self.init_noise_sprite()\n",
    "        cur_spr = np.copy(init_spr)\n",
    "\n",
    "        if animate:\n",
    "            anim_set = []\n",
    "            anim_set.append(cur_spr)\n",
    "\n",
    "        # iterate over the noise sprite and change until the iterations are done\n",
    "        pi = 0\n",
    "        if eval_met == \"iter\":\n",
    "            with tqdm(total=num_iter) as pbar:\n",
    "                for i in range(num_iter):\n",
    "                    #select a position (randomly or sequentially)\n",
    "                    if mod_iter == \"rand\":\n",
    "                        x = np.random.randint(self.spr_shape[0])\n",
    "                        y = np.random.randint(self.spr_shape[1])\n",
    "                    else:\n",
    "                        x = pi%self.spr_shape[0]\n",
    "                        y = pi//self.spr_shape[0]\n",
    "                        pi += 1\n",
    "                        if pi >= self.spr_shape[0]*self.spr_shape[1]:\n",
    "                            pi = 0\n",
    "\n",
    "                    pbar.set_description(\"@ ({},{})\".format(x,y))\n",
    "\n",
    "                    #crop the area\n",
    "                    _, crop_spr = self.crop(cur_spr,(x,y),self.crop_size)\n",
    "\n",
    "                    # preproc\n",
    "                    crop_spr = np.expand_dims(np.expand_dims(crop_spr,axis=-1),axis=0)  #make it a batch of 1\n",
    "                    \n",
    "                    \n",
    "                    # get the pixel change input from the model\n",
    "                    # pred_px = self.pod_model.predict(np.array([crop_spr,text_enc]),verbose=False)\n",
    "                    pred_px = self.pod_model.predict([crop_spr,text_enc],verbose=False)\n",
    "\n",
    "                    # change the tile\n",
    "                    cur_spr[x,y] = np.argmax(pred_px)\n",
    "\n",
    "                    anim_set.append(cur_spr.copy())\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "        if animate:\n",
    "            return init_spr, cur_spr, anim_set\n",
    "        return init_spr, cur_spr\n",
    "\n",
    "if EXPERIMENT == \"text_enc\":\n",
    "    # Make the Path of Destruction  model with the text encoded input\n",
    "    tepod = TECPoD((8,8),channels=16,crop_size=GEN_CONF['WINDOW'])     \n",
    "    tepod.makePoDCNN() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == \"text_enc\":\n",
    "\n",
    "    if CONFIGS[\"text_enc\"][\"NEW_TRAIN_DAT\"]:\n",
    "        # make the training data\n",
    "        goal_spr_char = pico_char_dat.copy()\n",
    "        goal_enc_char = pico_char_labels_emb.copy()\n",
    "        train_dat = tepod.make_train_dat(goal_spr_char,goal_enc_char,num_noise_spr=(len(goal_spr_char)*10))\n",
    "\n",
    "        # ninja turtle set\n",
    "        # turtle_spr_char = pico_char_dat[30:34]\n",
    "        # showMultiSprPalette(turtle_spr_char)\n",
    "        # train_dat = npod.make_train_dat(turtle_spr_char,num_noise_spr=(len(turtle_spr_char)*100))\n",
    "\n",
    "        print(len(train_dat))\n",
    "        print(train_dat[0][0].shape,train_dat[0][1].shape,train_dat[0][2])\n",
    "\n",
    "        # export as .npy file\n",
    "        np.save(CONFIGS[\"text_enc\"][\"TRAIN_DAT_PATH\"],train_dat)\n",
    "    else:\n",
    "        # import the training data\n",
    "        train_dat = np.load(CONFIGS['text_enc'][\"TRAIN_DAT_PATH\"],allow_pickle=True)\n",
    "        print(len(train_dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train or import the model\n",
    "if EXPERIMENT == \"text_enc\":\n",
    "    if CONFIGS[\"text_enc\"][\"TRAIN_TEPOD\"]:\n",
    "        tepod.trainPoD(train_dat,EPOCHS=GEN_CONF['EPOCHS'],BATCH_SIZE=GEN_CONF['BATCH_SIZE'],show_acc=True)\n",
    "        tepod.exportModel(CONFIGS[\"text_enc\"][\"TEPOD_MODEL\"])\n",
    "    else:\n",
    "        tepod.importModel(CONFIGS[\"text_enc\"][\"TEPOD_MODEL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TEXT = \"an orange fox with red shoes\" \n",
    "gifLabel = \"tails\"\n",
    "# show the output from repairing a noise sprite\n",
    "if EXPERIMENT == \"text_enc\":\n",
    "    init_spr, cur_spr, anims = tepod.repair(TEXT,mod_iter='rand',num_iter=256,animate=True)\n",
    "    showMultiSprPalette([init_spr,cur_spr],textArr=['init','final'])\n",
    "\n",
    "    # save the animation\n",
    "    animatePal(anims,f\"../prelim_output/pod_anim/text-enc_50e/tepod_{GEN_CONF['EPOCHS']}e_w{GEN_CONF['WINDOW']}-{gifLabel}.gif\",fps=32,textArr=[f\"Iter: {i}\" for i in range(len(anims))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == \"text_enc\" and CONFIGS['text_enc']['SANITY']:\n",
    "    x = np.array([init_spr,sentEmb(TEXT)])\n",
    "    x = tf.cast(x,tf.float32)\n",
    "    # print(x)\n",
    "    tepod.pod_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == \"text_enc\" and CONFIGS['text_enc']['SANITY']:      \n",
    "    # img = np.expand_dims(init_spr,axis=-1)\n",
    "    _, img = tepod.crop(init_spr,(4,4),8)\n",
    "    img = np.expand_dims(np.expand_dims(img,axis=-1),axis=0)\n",
    "    e = np.expand_dims(sentEmb(TEXT),axis=0)\n",
    "    print(img)\n",
    "    print(e)\n",
    "\n",
    "    print(img.shape,e.shape)\n",
    "\n",
    "    tepod.pod_model.predict([img,e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == \"text_enc\" and CONFIGS['text_enc']['SANITY']:\n",
    "    d = train_dat[0]\n",
    "    print(d[0].shape,d[1].shape,d[2].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT ENCODED + No Action PoD\n",
    "Text Encoded PoD with no-action as a (n+1)th possible output for the network\n",
    "\n",
    "---\n",
    "\n",
    "#### Notes\n",
    "[(90%-10%)/64 same tile chance decay] \n",
    "- dataset imbalance (creates 170k samples total with 64k being replaced tiles); noticeably worse than 'action' text encoded models\n",
    "\n",
    "\n",
    "[(80%-2.5%)/32 same tile chance decay] \"HALF\"\n",
    "- slightly better, but stops fixing too early\n",
    "\n",
    "\n",
    "[(95%-0%)/16 same tile chance decay] \"QUARTER\"\n",
    "- worst; no structure to the character and stops way too early\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_52 (InputLayer)          [(None, 768)]        0           []                               \n",
      "                                                                                                  \n",
      " tf.reshape_21 (TFOpLambda)     (None, 8, 8, 12)     0           ['input_52[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_22 (Flatten)           (None, 768)          0           ['tf.reshape_21[1][0]']          \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 64)           49216       ['flatten_22[1][0]']             \n",
      "                                                                                                  \n",
      " input_53 (InputLayer)          [(None, 8, 8, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " tf.reshape_22 (TFOpLambda)     (None, 8, 8, 1)      0           ['dense_38[1][0]']               \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 8, 8, 2)      0           ['input_53[0][0]',               \n",
      "                                                                  'tf.reshape_22[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 8, 8, 128)    2432        ['concatenate_10[1][0]']         \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 4, 4, 128)   0           ['conv2d_30[1][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 4, 4, 128)    147584      ['max_pooling2d_10[1][0]']       \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 4, 4, 256)    295168      ['conv2d_31[1][0]']              \n",
      "                                                                                                  \n",
      " flatten_23 (Flatten)           (None, 4096)         0           ['conv2d_32[1][0]']              \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 128)          524416      ['flatten_23[1][0]']             \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 17)           2193        ['dense_39[1][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,021,009\n",
      "Trainable params: 1,021,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class TECNAPoD():\n",
    "    def __init__(self,spr_shape, channels=16, pad_val=0, crop_size=5):\n",
    "        self.destroy_data = []\n",
    "        self.spr_shape = spr_shape\n",
    "        self.channels = channels\n",
    "        self.pad_val = pad_val\n",
    "        self.crop_size = crop_size\n",
    "\n",
    "        self.ENC_SIZE = 768\n",
    "\n",
    "    # make a new noisy sprite using the channels and size\n",
    "    def init_noise_sprite(self):\n",
    "        noise_spr = np.random.randint(self.channels,size=(self.spr_shape[0],self.spr_shape[1]))\n",
    "        return noise_spr\n",
    "\n",
    "    # crop a sprite from the noise sprite (use with padding) - assume pos is (x,y) and center of target crop\n",
    "    def crop(self, spr, pos, size=5):\n",
    "        hpad = size//2\n",
    "        pad_spr = np.pad(spr,((hpad,hpad),(hpad,hpad)),constant_values=self.pad_val)   # pad the sprite \n",
    "        crop_spr = pad_spr[pos[0]:pos[0]+size,pos[1]:pos[1]+size]   # get the cropped sprite (should be size,size)\n",
    "        return pad_spr, crop_spr\n",
    "\n",
    "    # return the new level and the tile replaced (also add to training data) - assume pos is (x,y)\n",
    "    def destroy(self, cur_spr, bad_spr, pos, crop_size=5):\n",
    "        # turn the cur_spr value at the pos to the bad_spr value\n",
    "        cur_spr2 = np.copy(cur_spr)\n",
    "        og_val = cur_spr[pos[0],pos[1]]\n",
    "        cur_spr2[pos[0],pos[1]] = bad_spr[pos[0],pos[1]]\n",
    "\n",
    "        # crop around the area and add to training data\n",
    "        _, crop_spr = self.crop(cur_spr2,pos,crop_size)\n",
    "\n",
    "        return cur_spr2, og_val, crop_spr\n",
    "    \n",
    "    # calculate the hamming distance from 2 sprites\n",
    "    def calc_ham_dist(self, spr1, spr2):\n",
    "        return np.sum(spr1 != spr2)\n",
    "\n",
    "    # return the sprite that is closest in hamming distance from the goal set\n",
    "    def closest_spr(self, goal_set, noise_spr):\n",
    "        min_dist_i = np.argmin([self.calc_ham_dist(noise_spr, i) for i in goal_set])\n",
    "        return goal_set[min_dist_i]\n",
    "\n",
    "    \n",
    "    # make the training data for the path of destruction\n",
    "    # NO ACTION Modification: add a probability for keeping the original pixel color (n+1th channel label)\n",
    "    def make_train_dat(self,goal_img_set,goal_enc_set,num_noise_spr=1000):\n",
    "        train_dat = []\n",
    "        no_act_freq = []\n",
    "        with tqdm(total=num_noise_spr) as pbar:\n",
    "            for i in range(num_noise_spr):\n",
    "\n",
    "                # probability and decay for keeping the original pixel color\n",
    "                tot_pix = self.spr_shape[0]*self.spr_shape[1]\n",
    "                same_prob = 0.95\n",
    "                end_same_prob = 0\n",
    "                same_prob_decay = (same_prob-end_same_prob)/(tot_pix/4)\n",
    "\n",
    "                # make a noise sprite and find the closest\n",
    "                # noise_spr = self.init_noise_sprite()\n",
    "                # targ_spr = self.closest_spr(goal_set,noise_spr).copy()\n",
    "\n",
    "                #go through each goal sprite (with associated annotation) and make a noise sprite for it\n",
    "                targ_spr = goal_img_set[i%len(goal_img_set)]\n",
    "                in_enc = goal_enc_set[i%len(goal_enc_set)]\n",
    "                noise_spr = self.init_noise_sprite()\n",
    "\n",
    "                # make a list of all the positions in the sprite and shuffle it\n",
    "                pos_set = []\n",
    "                for x in range(self.spr_shape[0]):\n",
    "                    for y in range(self.spr_shape[1]):\n",
    "                        pos_set.append((x,y))\n",
    "                random.shuffle(pos_set)\n",
    "\n",
    "                # iterate over the goal sprite and change until it matches the noise spr (destroy)\n",
    "                # for p in pos_set:\n",
    "                while len(pos_set) > 0:\n",
    "                    p = pos_set.pop()\n",
    "\n",
    "                    # if under the probability - keep the same; label as n+1th channel\n",
    "                    if random.random() < same_prob:\n",
    "                        _, crop_spr = self.crop(targ_spr,p,self.crop_size)\n",
    "                        train_dat.append([crop_spr,in_enc,self.channels])  # add the crop to the training data with the n+1th channel label\n",
    "                        pos_set.insert(random.randint(0,len(pos_set)),p)  # add the position back to the set\n",
    "                        no_act_freq.append(tot_pix-len(pos_set))  # add the destruction iteration to the no action frequency\n",
    "                        continue\n",
    "\n",
    "                    # otherwise, destroy the noise sprite and decay the probability\n",
    "                    else:\n",
    "                        targ_spr, og_val, crop_spr = self.destroy(targ_spr,noise_spr,p,self.crop_size)\n",
    "                        train_dat.append([crop_spr,in_enc,og_val])\n",
    "                        same_prob -= same_prob_decay\n",
    "                        # showSprPalette(targ_spr)\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "\n",
    "        # calculate frequency of no action\n",
    "        no_act_iter_freq = [no_act_freq.count(i) for i in range(tot_pix)]\n",
    "                    \n",
    "        return train_dat, no_act_iter_freq\n",
    "    \n",
    "    # make the path of destruction neural network model\n",
    "    # copy of architecture from the paper [Conv(128,3) -> Conv(128,3) -> MaxPool(2), Conv(256,3)]\n",
    "    # it doesn't work though... at least not with 5x5 crop size - need to ask Sam for exact implementation\n",
    "    def makePoDCNN(self):\n",
    "\n",
    "        # image input\n",
    "        in1 = Input(shape=(self.crop_size,self.crop_size,1))\n",
    "        in1 = Lambda(lambda x: K.cast(x, dtype='float32'))(in1)\n",
    "\n",
    "        # text encoding input\n",
    "        in2 = Input(shape=(self.ENC_SIZE,)),\n",
    "        in2r = K.reshape(in2,(-1,8,8,12))\n",
    "        in2f = Flatten()(in2r)\n",
    "        in2d = Dense(self.crop_size*self.crop_size)(in2f)\n",
    "        in2r2 = K.reshape(in2d,(-1,self.crop_size,self.crop_size,1))\n",
    "        # in2r2 = Conv1D(1, 3, activation='relu',padding='SAME')(in2r)\n",
    "\n",
    "        # combined and sent through the CNN\n",
    "        x = Concatenate(axis=-1)([in1,in2r2])\n",
    "        x = Conv2D(128, (3, 3), activation='relu',padding='SAME')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Conv2D(128, (3, 3), activation='relu',padding='SAME')(x)\n",
    "        x = Conv2D(256, (3, 3), activation='relu',padding='SAME')(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        out1 = Dense(self.channels+1,activation='softmax')(x)\n",
    "\n",
    "        self.pod_model = Model(inputs=[in1,in2], outputs=out1)\n",
    "        self.pod_model.summary()\n",
    "        self.opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "        self.pod_model.compile(optimizer=self.opt,metrics=['accuracy'],loss='sparse_categorical_crossentropy') #not one-hot encoded\n",
    "        \n",
    "        \n",
    "    # import a model from a path\n",
    "    def importModel(self,model_path):\n",
    "        self.pod_model = tf.keras.models.load_model(model_path)\n",
    "        self.pod_model.summary()\n",
    "        self.opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "        self.pod_model.compile(optimizer=self.opt,metrics=['accuracy'],loss='sparse_categorical_crossentropy')\n",
    "\n",
    "\n",
    "    # export the model to a path\n",
    "    def exportModel(self,model_path):\n",
    "        self.pod_model.save(model_path,save_format='h5')\n",
    "                            \n",
    "\n",
    "    # train the path of destruction model on the training data\n",
    "    def trainPoD(self,train_dat,EPOCHS=500,BATCH_SIZE=64,show_acc=False):\n",
    "        # train the model\n",
    "        X1 = np.array([i[0] for i in train_dat])\n",
    "        X2 = np.array([i[1] for i in train_dat])\n",
    "        Y = np.array([i[2] for i in train_dat])\n",
    "        X1 = np.expand_dims(X1,axis=-1)\n",
    "        # X2 = np.expand_dims(X2,axis=-1)\n",
    "        Y = np.expand_dims(Y,axis=-1)\n",
    "        print(X1.shape,X2.shape,Y.shape)\n",
    "\n",
    "        h = self.pod_model.fit([X1,X2],Y,epochs=EPOCHS,batch_size=BATCH_SIZE,shuffle=True)\n",
    "        if show_acc:\n",
    "            plt.plot(h.history['accuracy'])\n",
    "            plt.show()\n",
    "\n",
    "    # repair from a noise vector\n",
    "    def repair(self,text_in,init_spr=None,mod_iter='rand',eval_met='iter',num_iter=1000,animate=False):\n",
    "        #encode the text\n",
    "        text_enc = sentEmb(text_in)\n",
    "        text_enc = np.expand_dims(text_enc,axis=0)\n",
    "        print(text_enc.shape)\n",
    "\n",
    "        # make a noise sprite\n",
    "        if init_spr is None:\n",
    "            init_spr = self.init_noise_sprite()\n",
    "        cur_spr = np.copy(init_spr)\n",
    "\n",
    "        if animate:\n",
    "            anim_set = []\n",
    "            anim_set.append(cur_spr)\n",
    "\n",
    "        # iterate over the noise sprite and change until the iterations are done\n",
    "        pi = 0\n",
    "        if eval_met == \"iter\":\n",
    "            with tqdm(total=num_iter) as pbar:\n",
    "                for i in range(num_iter):\n",
    "                    #select a position (randomly or sequentially)\n",
    "                    if mod_iter == \"rand\":\n",
    "                        x = np.random.randint(self.spr_shape[0])\n",
    "                        y = np.random.randint(self.spr_shape[1])\n",
    "                    else:\n",
    "                        x = pi%self.spr_shape[0]\n",
    "                        y = pi//self.spr_shape[0]\n",
    "                        pi += 1\n",
    "                        if pi >= self.spr_shape[0]*self.spr_shape[1]:\n",
    "                            pi = 0\n",
    "\n",
    "                    pbar.set_description(\"@ ({},{})\".format(x,y))\n",
    "\n",
    "                    #crop the area\n",
    "                    _, crop_spr = self.crop(cur_spr,(x,y),self.crop_size)\n",
    "\n",
    "                    # preproc\n",
    "                    crop_spr = np.expand_dims(np.expand_dims(crop_spr,axis=-1),axis=0)  #make it a batch of 1\n",
    "                    \n",
    "                    \n",
    "                    # get the pixel change input from the model\n",
    "                    # pred_px = self.pod_model.predict(np.array([crop_spr,text_enc]),verbose=False)\n",
    "                    pred_px = self.pod_model.predict([crop_spr,text_enc],verbose=False)\n",
    "\n",
    "                    # only change the tile if no a 'no action' color\n",
    "                    color = np.argmax(pred_px)\n",
    "                    if color != self.channels:\n",
    "                        cur_spr[x,y] = color\n",
    "\n",
    "                    anim_set.append(cur_spr.copy())\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "        if animate:\n",
    "            return init_spr, cur_spr, anim_set\n",
    "        return init_spr, cur_spr\n",
    "\n",
    "if EXPERIMENT == \"no_act-te\":\n",
    "    # Make the Path of Destruction  model with the text encoded input with no action output possibility\n",
    "    tenapod = TECNAPoD((8,8),channels=16,crop_size=GEN_CONF['WINDOW'])     \n",
    "    tenapod.makePoDCNN() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 187.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108976\n",
      "(8, 8) (768,) 16\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if EXPERIMENT == \"no_act-te\":\n",
    "\n",
    "    if CONFIGS[\"no_act-te\"][\"NEW_TRAIN_DAT\"]:\n",
    "        # make the training data\n",
    "        goal_spr_char = pico_char_dat.copy()\n",
    "        goal_enc_char = pico_char_labels_emb.copy()\n",
    "        train_dat, na_iter = tenapod.make_train_dat(goal_spr_char,goal_enc_char,num_noise_spr=(len(goal_spr_char)*10))\n",
    "\n",
    "        # ninja turtle set\n",
    "        # turtle_spr_char = pico_char_dat[30:34]\n",
    "        # showMultiSprPalette(turtle_spr_char)\n",
    "        # train_dat = npod.make_train_dat(turtle_spr_char,num_noise_spr=(len(turtle_spr_char)*100))\n",
    "\n",
    "        print(len(train_dat))\n",
    "        print(train_dat[0][0].shape,train_dat[0][1].shape,train_dat[0][2])\n",
    "\n",
    "        # show the frequency of the no actions in the training data\n",
    "        plt.plot(na_iter)\n",
    "        plt.title(\"Frequency of No Actions in Training Data\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.show()\n",
    "\n",
    "        # export as .npy file\n",
    "        np.save(CONFIGS[\"no_act-te\"][\"TRAIN_DAT_PATH\"],train_dat)\n",
    "    else:\n",
    "        # import the training data\n",
    "        train_dat = np.load(CONFIGS['no_act-te'][\"TRAIN_DAT_PATH\"],allow_pickle=True)\n",
    "        print(len(train_dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 768)]        0           []                               \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)      (None, 8, 8, 12)     0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 768)          0           ['tf.reshape_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           49216       ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 8, 8, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " tf.reshape_3 (TFOpLambda)      (None, 8, 8, 1)      0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 2)      0           ['input_6[0][0]',                \n",
      "                                                                  'tf.reshape_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 128)    2432        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 4, 4, 128)   0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 4, 4, 128)    147584      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 4, 4, 256)    295168      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 4096)         0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          524416      ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 17)           2193        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,021,009\n",
      "Trainable params: 1,021,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train or import the model\n",
    "if EXPERIMENT == \"no_act-te\":\n",
    "    if CONFIGS[\"no_act-te\"][\"TRAIN_TEPOD\"]:\n",
    "        tenapod.trainPoD(train_dat,EPOCHS=GEN_CONF['EPOCHS'],BATCH_SIZE=GEN_CONF['BATCH_SIZE'],show_acc=True)\n",
    "        tenapod.exportModel(CONFIGS[\"no_act-te\"][\"TEPOD_MODEL\"])\n",
    "    else:\n",
    "        tenapod.importModel(CONFIGS[\"no_act-te\"][\"TEPOD_MODEL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@ (7,4): 100%|██████████| 300/300 [00:16<00:00, 18.27it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "saving GIF 301...: 100%|██████████| 301/301 [00:18<00:00, 16.45it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TEXT = \"a man with a blue shirt and red gloves\" \n",
    "gifLabel = \"man_blueshirt_redgloves_HALF\"\n",
    "\n",
    "# show the output from repairing a noise sprite\n",
    "if EXPERIMENT == \"no_act-te\":\n",
    "    init_spr, cur_spr, anims = tenapod.repair(TEXT,mod_iter='rand',num_iter=300,animate=True)\n",
    "    showMultiSprPalette([init_spr,cur_spr],textArr=['init','final'])\n",
    "\n",
    "    # save the animation\n",
    "    animatePal(anims,f\"../prelim_output/pod_anim/text-enc_na_50e/tenapod_{GEN_CONF['EPOCHS']}e_w{GEN_CONF['WINDOW']}-{gifLabel}.gif\",fps=32,textArr=[f\"Iter: {i}\" for i in range(len(anims))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SANITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is insane already - no sanity check could help it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmo-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f94925f3cff0b0ac90dd538919dcd2d4d02467fa3fdafdf86812e92b857d43c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

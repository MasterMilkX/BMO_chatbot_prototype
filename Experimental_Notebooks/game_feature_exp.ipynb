{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Feature Recommendation System\n",
    "Recommends to the user on prompting game features extracted from game database information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "import math\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External data imports\n",
    "def loadFeatData():\n",
    "    DAT = {}\n",
    "    with open(\"../data/game_datfeat.txt\", \"r\") as f:\n",
    "        lines = [l.strip() for l in f.readlines()]\n",
    "        CUR_GAME = \"\"\n",
    "        for l in lines:\n",
    "            # empty line (between entries)\n",
    "            if l == \"\":\n",
    "                continue\n",
    "            #new entry\n",
    "            else:\n",
    "                if l[0] == \"+\":\n",
    "                    CUR_GAME = l[2:]\n",
    "                    DAT[CUR_GAME] = {\"tags\":[],\"entities\":[],\"features\":[]}\n",
    "                elif l[0] == \"#\":\n",
    "                    DAT[CUR_GAME][\"tags\"] = [t.lower() for t in l[2:].split(\",\")]\n",
    "                elif l[0] == \"@\":\n",
    "                    DAT[CUR_GAME][\"entities\"] = l[2:].split(\",\")\n",
    "                else:\n",
    "                    DAT[CUR_GAME][\"features\"].append(l)\n",
    "    return DAT\n",
    "\n",
    "\n",
    "#get all of the tags and the entities from the game data\n",
    "def getTagsEntities():\n",
    "    # get all of the tags and entities\n",
    "    ALL_TAGS = []\n",
    "    ALL_ENTITIES = []\n",
    "    for g in GAME_DATA:\n",
    "        ALL_TAGS += [t.lower() for t in GAME_DATA[g][\"tags\"]]\n",
    "        ALL_ENTITIES += [e.lower() for e in GAME_DATA[g][\"entities\"]]\n",
    "\n",
    "    # remove duplicates\n",
    "    ALL_TAGS = list(set(ALL_TAGS))\n",
    "    ALL_ENTITIES = list(set(ALL_ENTITIES))\n",
    "\n",
    "    return ALL_TAGS, ALL_ENTITIES\n",
    "\n",
    "\n",
    "GAME_DATA = loadFeatData()\n",
    "ALL_TAGS, ALL_ENTITIES = getTagsEntities()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTS\n",
    "* Sample input text: \"_top-down multiplayer action game about knights, castles, and assassinations_\"\n",
    "* Target selection games: [Castle Crashers, Hammerwatch, Kingsway], Thief Gold, Skyrim, Elden Ring\n",
    "\n",
    "_Notes:_ \n",
    "- Maybe having some not perfect predictions is necessary for the user to prevent from making cloned games? -> #5 has best predictions so far, but aren't spot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general functions\n",
    "TRAIN_MODE = \"TFIDF_TRANS\"\n",
    "SENT_MODEL = None\n",
    "custom_stopwords = [\"game\", \",\", \".\", \"!\"]\n",
    "\n",
    "#setup abstract function\n",
    "def getClosestGames(txt,k=3):\n",
    "    return [(\"?\",0)]\n",
    "\n",
    "#tokenizes the text\n",
    "def tokenize(txt):\n",
    "    raw_toks = word_tokenize(txt)\n",
    "    toks = [w.lower() for w in raw_toks if w.lower() not in stopwords.words(\"english\") and w.lower() not in custom_stopwords]\n",
    "    #add the custom tag words (can be compound words)\n",
    "    for t in ALL_TAGS:\n",
    "        if t in txt and t not in toks:\n",
    "            toks.append(t)\n",
    "    return toks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. VECTORIZE THE TAGS + ENTITIES\n",
    "- Note: Completely wrong. Vectorizing doesn't work with unbalanced dataset - picked the matches with fewest amount of data in vector\n",
    "- Result: [\"The Ramp\", \"Batman: Arkham City\", \"Among Us\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   VECTOR THE TAGS AND ENTITIES   ###\n",
    "if TRAIN_MODE == \"VECTOR\":\n",
    "\n",
    "    # get all of the tags and entities\n",
    "    ALL_TAGS = []\n",
    "    ALL_ENTITIES = []\n",
    "    for g in GAME_DATA:\n",
    "        ALL_TAGS += [t.lower() for t in GAME_DATA[g][\"tags\"]]\n",
    "        ALL_ENTITIES += [e.lower() for e in GAME_DATA[g][\"entities\"]]\n",
    "\n",
    "    # remove duplicates\n",
    "    ALL_TAGS = list(set(ALL_TAGS))\n",
    "    ALL_ENTITIES = list(set(ALL_ENTITIES))\n",
    "\n",
    "    #make a tag embedding\n",
    "    def tagEmbed(tags):\n",
    "        vec = [0]*len(ALL_TAGS)\n",
    "        for t in tags:\n",
    "            tt = t.lower()\n",
    "            if tt in ALL_TAGS:\n",
    "                vec[ALL_TAGS.index(tt)] = 1\n",
    "        return vec\n",
    "\n",
    "    #make a entity embedding\n",
    "    def entEmbed(entities):\n",
    "        vec = [0]*len(ALL_ENTITIES)\n",
    "        for e in entities:\n",
    "            ee = e.lower()\n",
    "            if ee in ALL_ENTITIES:\n",
    "                vec[ALL_ENTITIES.index(ee)] = 1\n",
    "        return vec\n",
    "\n",
    "\n",
    "    # make the embeddings for each game\n",
    "    TAG_EMBEDDINGS = {}\n",
    "    ENTITY_EMBEDDINGS = {}\n",
    "    for g in GAME_DATA:\n",
    "        TAG_EMBEDDINGS[g] = tagEmbed(GAME_DATA[g][\"tags\"])\n",
    "        ENTITY_EMBEDDINGS[g] = entEmbed(GAME_DATA[g][\"entities\"])\n",
    "\n",
    "    #make a combined embedding\n",
    "    FULL_EMVEDDINGS = {}\n",
    "    for g in GAME_DATA:\n",
    "        FULL_EMVEDDINGS[g] = TAG_EMBEDDINGS[g]+ENTITY_EMBEDDINGS[g]\n",
    "\n",
    "\n",
    "    ## GET CLOSEST GAME FROM TEXT BASED ON EMBEDDINGS ##\n",
    "    def getClosestGames(txt,k=3):\n",
    "        # tokenize and remove all stop words\n",
    "        toks = tokenize(txt)\n",
    "        # print(toks)\n",
    "\n",
    "        # get the embedding for the text\n",
    "        txt_embed = tagEmbed(toks)+entEmbed(toks)\n",
    "\n",
    "        # get the closest games using distance metrics\n",
    "        dists = {}\n",
    "        for g in GAME_DATA:\n",
    "            dists[g] = np.linalg.norm(np.array(txt_embed) - np.array(FULL_EMVEDDINGS[g]))\n",
    "        dists = sorted(dists.items(), key=lambda x: x[1])\n",
    "        # print(dists)\n",
    "        return dists[:k], None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. COUNT THE MATCHES\n",
    "- Note: Doesn't get the right matches for the secondary choices - especially if the tags themselves are too general. No way to account for tie-breakers\n",
    "- Result: [\"Castle Crashers\", \"Hammerwatch\", \"Among Us\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of tags and entities matches \n",
    "if TRAIN_MODE == \"COUNT\":\n",
    "    \n",
    "    # get the closest games using count matches\n",
    "    def getClosestGames(txt,k=3):\n",
    "        # tokenize and remove all stop words\n",
    "        toks = tokenize(txt)\n",
    "\n",
    "        # initialize the counts\n",
    "        cts = {}\n",
    "        for g in GAME_DATA:\n",
    "            cts[g] = 0\n",
    "        \n",
    "        # count the matches for each game\n",
    "        matches = {}\n",
    "        for t in toks:\n",
    "            for g in GAME_DATA:\n",
    "                if t in GAME_DATA[g][\"tags\"] or t in GAME_DATA[g][\"entities\"]:\n",
    "                    cts[g] += 1\n",
    "                    if g not in matches:\n",
    "                        matches[g] = []\n",
    "                    matches[g].append(t)\n",
    "\n",
    "        # sort the counts\n",
    "        cts = sorted(cts.items(), key=lambda x: x[1], reverse=True)\n",
    "        return cts[:k], matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. BERT SENTENCE TRANSFORMER MODEL\n",
    "- Note: Ok, but places too much weight on the word semantics themselves.\n",
    "- Result: [\"Kingsway\", \"Hammerwatch\", \"Batman: Arkham City\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODE == \"TRANSFORMER\":\n",
    "    # load the model\n",
    "    if SENT_MODEL == None:\n",
    "        SENT_MODEL = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODE == \"TRANSFORMER\":\n",
    "\n",
    "    # turn game data into a \"sentence\" for the sentence-transformer\n",
    "    def sentGame(g):\n",
    "        return \" \".join(GAME_DATA[g][\"tags\"])+\" \"+\" \".join(GAME_DATA[g][\"entities\"])\n",
    "\n",
    "    # encode the game data\n",
    "    def encodeGames():\n",
    "        emb_dat = {}\n",
    "        with tqdm(total=len(GAME_DATA)) as pbar:\n",
    "            for g in GAME_DATA:\n",
    "                emb_dat[g] = SENT_MODEL.encode(sentGame(g))\n",
    "                pbar.update(1)\n",
    "        return emb_dat\n",
    "\n",
    "    GAME_DAT_EMB = encodeGames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODE == \"TRANSFORMER\":\n",
    "    # find the closest game based on the encoded game data\n",
    "    def getClosestGames(txt,k=3):\n",
    "        # tokenize and remove all stop words\n",
    "        toks = tokenize(txt)\n",
    "\n",
    "        # encode the text\n",
    "        txt_embed = SENT_MODEL.encode([\" \".join(toks)])\n",
    "\n",
    "        # get the closest games using distance metrics\n",
    "        dists = {}\n",
    "        for g in GAME_DATA:\n",
    "            temb = np.array(txt_embed)\n",
    "            gemb = np.array(GAME_DAT_EMB[g])\n",
    "            dists[g] = cosine_similarity(temb,[gemb])\n",
    "        dists = sorted(dists.items(), key=lambda x: x[1], reverse=True)\n",
    "        # print(dists)\n",
    "        return dists[:k], None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. TAG MATCH + SENTENCE TRANSFORMER SIMILARITY\n",
    "- Note: Ok, but has both problems of the counter and transformer experiments. Too much weight on tags, not enough on less frequently occuring entities\n",
    "- Result: [\"Hammerwatch\", \"Binding of Isaac\", \"Castle Crashers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODE == \"CT_TRANS\":\n",
    "    # load the model\n",
    "    if SENT_MODEL == None:\n",
    "        SENT_MODEL = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODE == \"CT_TRANS\":\n",
    "    # turn game data into a \"sentence\" for the sentence-transformer\n",
    "    def sentGame(g):\n",
    "        return \" \".join(GAME_DATA[g][\"tags\"])+\" \"+\" \".join(GAME_DATA[g][\"entities\"])\n",
    "\n",
    "    # encode the game data\n",
    "    def encodeGames():\n",
    "        emb_dat = {}\n",
    "        with tqdm(total=len(GAME_DATA)) as pbar:\n",
    "            for g in GAME_DATA:\n",
    "                emb_dat[g] = SENT_MODEL.encode(sentGame(g))\n",
    "                pbar.update(1)\n",
    "        return emb_dat\n",
    "\n",
    "    GAME_DAT_EMB = encodeGames()\n",
    "\n",
    "    # count the number of tags found in each game's list\n",
    "    def tagsFound(txt):\n",
    "        # tokenize and remove all stop words\n",
    "        toks = tokenize(txt)\n",
    "\n",
    "        # initialize the counts\n",
    "        cts = {}\n",
    "        for g in GAME_DATA:\n",
    "            cts[g] = 0\n",
    "        \n",
    "        # count the matches for each game\n",
    "        for g in GAME_DATA:\n",
    "            for t in toks:\n",
    "                if t in GAME_DATA[g][\"tags\"]:\n",
    "                    cts[g] += 1\n",
    "\n",
    "        # sort the counts\n",
    "        cts = dict(sorted(cts.items(), key=lambda x: x[1], reverse=True))\n",
    "        return cts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODE == \"CT_TRANS\":\n",
    "    # get the closest games using count matches and the sentence transformer distance metric\n",
    "    def getClosestGames(txt,k=3):\n",
    "        # tokenize and remove all stop words\n",
    "        toks = tokenize(txt)\n",
    "\n",
    "        # encode the text\n",
    "        txt_embed = SENT_MODEL.encode([\" \".join(toks)])\n",
    "\n",
    "        # get the closest games using distance metrics\n",
    "        dists = {}\n",
    "        for g in GAME_DATA:\n",
    "            temb = np.array(txt_embed)\n",
    "            gemb = np.array(GAME_DAT_EMB[g])\n",
    "            dists[g] = cosine_similarity(temb,[gemb])\n",
    "\n",
    "        #multiply by the tag matches\n",
    "        TAG_MATCHES = tagsFound(txt)\n",
    "        print(TAG_MATCHES)\n",
    "        for g in dists:\n",
    "            dists[g] *= TAG_MATCHES[g]\n",
    "\n",
    "        # sort by distance\n",
    "        dists = sorted(dists.items(), key=lambda x: x[1], reverse=True)\n",
    "        # print(dists)\n",
    "        return dists[:k], None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. TF-IDF + SENTENCE TRANSFORMER SIMILARITY\n",
    "- Notes: Closer... Needs a mix of tf-idf with semantic similarity score that the transformer can offer\n",
    "- Result: [\"Castle Crashers\", \"Hammerwatch\", \"Among Us\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Code heheh\n",
    "\n",
    "#term frequency - how often a term appears in a document / total number of terms in the document\n",
    "def tf(doc):  # assume doc is a list of words already tokenized\n",
    "    tf_dict = {}\n",
    "    for word in doc:\n",
    "        if word not in tf_dict:\n",
    "            tf_dict[word] = 1\n",
    "        tf_dict[word] += 1\n",
    "    for word in tf_dict:\n",
    "        tf_dict[word] = tf_dict[word] / len(doc)\n",
    "    return tf_dict\n",
    "\n",
    "#inverse document frequency - log(total number of documents / number of documents with term t in it)\n",
    "def idf(documents):  # assume documents is a list of lists of words already tokenized\n",
    "    df = {}\n",
    "    for doc in documents:  \n",
    "        for word in doc:\n",
    "            if word in df:\n",
    "                df[word] += 1\n",
    "            else:\n",
    "                df[word] = 1\n",
    "\n",
    "    idf_dict = {}\n",
    "    for word in df:\n",
    "        idf_dict[word] = math.log(len(documents) / df[word])\n",
    "    return idf_dict\n",
    "    \n",
    "# get the full tfidf score for each word in each game's dataset\n",
    "def tfidf(doc_set):  # assume doc_set is a dictionary of games with word lists already tokenized\n",
    "    tfidf_dict = {}\n",
    "    corpuses = [d for d in doc_set.values()]\n",
    "    # print(corpuses)\n",
    "    idf_dat = idf(corpuses)\n",
    "    for game, doc in doc_set.items():\n",
    "        tf_dat = tf(doc)\n",
    "        tfidf_dict[game] = {}\n",
    "        for word in doc:\n",
    "            tfidf_dict[game][word] = tf_dat[word] * idf_dat[word]   #note: the tf will be uniform for each word in a doc since it only saves unique words\n",
    "    return tfidf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:09<00:00,  5.36it/s]\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_MODE == \"TFIDF_TRANS\":\n",
    "    # load the model\n",
    "    if SENT_MODEL == None:\n",
    "        SENT_MODEL = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    # turn game data into a \"sentence\" for the sentence-transformer\n",
    "    def sentGame(g):\n",
    "        return \" \".join(GAME_DATA[g][\"tags\"])+\" \"+\" \".join(GAME_DATA[g][\"entities\"])\n",
    "\n",
    "    # encode the game data\n",
    "    def encodeGames():\n",
    "        emb_dat = {}\n",
    "        with tqdm(total=len(GAME_DATA)) as pbar:\n",
    "            for g in GAME_DATA:\n",
    "                emb_dat[g] = SENT_MODEL.encode(sentGame(g))\n",
    "                pbar.update(1)\n",
    "        return emb_dat\n",
    "\n",
    "    GAME_DAT_EMB = encodeGames()\n",
    "\n",
    "    # get the tfidf scores for each game\n",
    "    GAME_DOCS = {}\n",
    "    for g in GAME_DATA:\n",
    "        GAME_DOCS[g] = GAME_DATA[g][\"tags\"]+GAME_DATA[g][\"entities\"]\n",
    "    GAME_DAT_TFIDF = tfidf(GAME_DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODE == \"TFIDF_TRANS\":\n",
    "    def getClosestGames(txt,k=3):\n",
    "        # tokenize and remove all stop words\n",
    "        toks = tokenize(txt)\n",
    "\n",
    "        # encode the text\n",
    "        txt_embed = SENT_MODEL.encode([\" \".join(toks)])\n",
    "\n",
    "        # get the closest games using distance metrics\n",
    "        dists = {}\n",
    "        for g in GAME_DATA:\n",
    "            temb = np.array(txt_embed)\n",
    "            gemb = np.array(GAME_DAT_EMB[g])\n",
    "            dists[g] = cosine_similarity(temb,[gemb])\n",
    "\n",
    "        #multiply by the tag matches\n",
    "        TAG_MATCHES = tagsFound(txt)\n",
    "        for g in dists:\n",
    "            dists[g] *= TAG_MATCHES[g]\n",
    "\n",
    "        # multiply by the tfidf scores\n",
    "        for g in dists:\n",
    "            for t in toks:\n",
    "                if t in GAME_DAT_TFIDF[g]:\n",
    "                    dists[g] *= GAME_DAT_TFIDF[g][t]\n",
    "                else:\n",
    "                    dists[g] *= 0.0001\n",
    "\n",
    "        # sort by distance\n",
    "        dists = sorted(dists.items(), key=lambda x: x[1], reverse=True)\n",
    "        # print(dists)\n",
    "        return dists[:k], sorted([(d[0],d[1][0][0]) for d in dists], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN RECOMMENDATION SYSTEM\n",
    "\n",
    "#### Steps: \n",
    "1. Load the data (games => tags, entities, features)\n",
    "2. Get a user prompt for a game and its genre\n",
    "3. Recommend some random features based on the text similarity and closest tags\n",
    "\n",
    "* Note: Keep in mind, there are over 150k games with tags, features, and entities - the search cannot be too large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend some features to the user based on a prompt\n",
    "def recommendFeatures(userPrompt):\n",
    "    # get the closest game\n",
    "    closestGames, other = getClosestGames(userPrompt)\n",
    "    print(closestGames)\n",
    "\n",
    "    #show more debug info\n",
    "    if other:\n",
    "        print(other)\n",
    "        print(\"\")\n",
    "\n",
    "    # get the features for that game\n",
    "    for i in closestGames:\n",
    "        g,v = i\n",
    "        print(f\"{g} -> {v}\")\n",
    "        print(sentGame(g))\n",
    "        print(GAME_DATA[g][\"features\"])\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['top-down', 'multiplayer', 'action', 'knights', 'castles', 'assassinations']\n",
      "[('CASTLE CRASHERS', array([[3.9934258e-16]], dtype=float32)), ('HAMMERWATCH', array([[1.6724053e-16]], dtype=float32)), ('AMONG US', array([[2.7277695e-18]], dtype=float32))]\n",
      "[('CASTLE CRASHERS', 3.9934258e-16), ('HAMMERWATCH', 1.6724053e-16), ('AMONG US', 2.7277695e-18), ('THE BINDING OF ISAAC', 4.2837838e-19), ('HYPER LIGHT DRIFTER', 3.2989625e-19), ('NIDHOGG', 1.9977411e-19), ('CUPHEAD', 1.4612603e-19), ('SCRIBBLENAUTS UNLIMITED', 1.3349024e-19), ('BATTLEBLOCK THEATER', 1.01988694e-19), ('MINI NINJAS', 8.5278806e-20), ('OVERCOOKED! 2', 7.959631e-20), ('GRAND THEFT AUTO V', 6.35636e-20), ('BABA IS YOU', 7.867711e-22), ('SUPER FANCY PANTS ADVENTURE', 5.4668944e-22), ('BATMAN: ARKHAM CITY', 4.4090236e-22), ('STREETS OF ROGUE', 3.1294016e-22), ('STARDEW VALLEY', 2.473096e-22), ('SPELUNKY', 1.7162156e-22), ('THE ELDER SCROLLS V: SKYRIM', 1.595181e-22), ('DOWNWELL', 1.413041e-22), ('GOAT SIMULATOR', 1.3032527e-22), ('MONSTER PROM', 1.1611606e-22), ('QUADRILATERAL COWBOY', 1.1473101e-22), (\"MIRROR'S EDGE\", 1.1397383e-22), ('PORTAL', 8.208662e-23), ('SUPER MEAT BOY', 7.814169e-23), ('JET SET RADIO', 7.7817216e-23), ('THIEF GOLD', 4.4500477e-23), ('CAVEBLAZERS', 0.0), ('CHROMA SQUAD', 0.0), ('CYBERPUNK 2077', 0.0), ('DONUT COUNTY', 0.0), ('ELDEN RING', 0.0), ('EMILY IS AWAY TOO', 0.0), ('ESCAPE SIMULATOR', 0.0), ('FEZ', 0.0), ('HADES', 0.0), ('KINDERGARTEN', 0.0), ('KINGSWAY', 0.0), ('LAST CALL BBS', 0.0), ('NIGHT IN THE WOODS', 0.0), ('OMORI', 0.0), ('OUTER WILDS', 0.0), ('THE RAMP', 0.0), ('RETROWAVE', 0.0), ('A SHORT HIKE', 0.0), ('TROMBONE CHAMP', 0.0), ('ULTRAKILL', 0.0), ('UNDERTALE', 0.0), ('VAMPIRE SURVIVORS', 0.0)]\n",
      "\n",
      "CASTLE CRASHERS -> [[3.9934258e-16]]\n",
      "action casual singleplayer adventure rpg 2d multiplayer cute arcade funny comedy co-op cartoony medieval online co-op local multiplayer hack and slash local co-op 4 player local beat 'em up adventure arcade award castles characters crashers friends hack hand hi kingdom princess res slash victory visuals way\n",
      "['defend your kingdom', 'play locally or online to save your princess', 'smash your way to victory', 'crash some castles']\n",
      "\n",
      "HAMMERWATCH -> [[1.6724053e-16]]\n",
      "indie action singleplayer adventure rpg 2d pixel graphics fantasy multiplayer retro top-down co-op online co-op rogue-like local multiplayer hack and slash dungeon crawler local co-op 4 player local level editor - action adventure art bottom classes co customize development difficulty editing enemies environment environments fantasy features gamepads- hack hordes levels liking looks medium modifiers- online op players puzzles secrets skills- solo support things top traps unlocks\n",
      "['Kill hordes of enemies', 'make your own levels', 'upgrades- Hard, medium', 'change other things', 'slash action', 'Play solo or co']\n",
      "\n",
      "AMONG US -> [[2.7277695e-18]]\n",
      "colorful multiplayer funny sci-fi survival top-down co-op pvp cartoony space online co-op local multiplayer aliens psychological party game minigames social deduction departure impostors player players spaceship\n",
      "['beware as one or more random players', 'Play with 4 - 10 player']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_txt = \"top-down multiplayer action game about knights, castles, and assassinations\"  #ideally should return \"castle crashers\" or \"hammerwatch\" or \"thief\"\n",
    "print(tokenize(user_txt))\n",
    "recommendFeatures(user_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASTLE CRASHERS\n",
      "action casual singleplayer adventure rpg 2d multiplayer cute arcade funny comedy co-op cartoony medieval online co-op local multiplayer hack and slash local co-op 4 player local beat 'em up adventure arcade award castles characters crashers friends hack hand hi kingdom princess res slash victory visuals way\n",
      "['defend your kingdom', 'play locally or online to save your princess', 'smash your way to victory', 'crash some castles']\n",
      "\n",
      "HYPER LIGHT DRIFTER\n",
      "indie action singleplayer adventure rpg 2d atmospheric pixel graphics fantasy colorful exploration sci-fi difficult top-down great soundtrack action rpg hack and slash post-apocalyptic metroidvania souls-like action adventure bit blood classics collectors designs disease drifter drifters echoes grander histories illness knowledge land lands mechanics past resonate rpg scale technologies treasure vein way world\n",
      "['quiet the vicious disease']\n",
      "\n",
      "THIEF GOLD\n",
      "action singleplayer adventure atmospheric story rich fantasy exploration first-person horror dark medieval dark fantasy immersive sim 1990's stealth classic moddable steampunk cult classic immersive addition amount areas arrows beggar blackjack bodies bombs bow bugfixes campaign challenges changes chasms combat company cross design difficulties difficulty disposal elements enemies equipment era extinguishes fantasy fire flash footsteps forces game gem goals gold ground guard guards head keys lack level levels line lockpicks master masters metropolis mines mission missions modifications moss nobles noisemaker noises objective objects opponents order organization parts paths people person place places plans player plot purpose range reissue requirements rope ropes shadows skills sounds spots stage stealth streets surfaces surfacing sword technology thief thieving time torches town training treasures trinkets type types undead version visibility water way ways work world\n",
      "['sneak on guards', 'skip some of the harder areas', 'provide new challenges', 'steal their keys', 'appropriate the treasures', 'accomplish the objective', 'enter forbidden places', 'avoid being heard ( different surfaces', 'avoid being seen ( the level', 'allow the player', 'include bugfixes', 'keep his head', 'soften the sounds', 'move their bodies']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gt in [\"CASTLE CRASHERS\", \"HYPER LIGHT DRIFTER\", \"THIEF GOLD\"]:\n",
    "    print(gt)\n",
    "    print(sentGame(gt))\n",
    "    print(GAME_DATA[gt][\"features\"])\n",
    "    print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colorful': 0.15589076619017514,\n",
       " 'multiplayer': 0.1035849348353059,\n",
       " 'funny': 0.07059352631809057,\n",
       " 'sci-fi': 0.16659831488621002,\n",
       " 'survival': 0.25576461061454875,\n",
       " 'top-down': 0.20932591754491328,\n",
       " 'co-op': 0.12246124072423722,\n",
       " 'pvp': 0.22961169493711414,\n",
       " 'cartoony': 0.25576461061454875,\n",
       " 'space': 0.22961169493711414,\n",
       " 'online co-op': 0.15589076619017514,\n",
       " 'local multiplayer': 0.14631253749400913,\n",
       " 'aliens': 0.3556384550389224,\n",
       " 'psychological': 0.3556384550389224,\n",
       " 'party game': 0.29262507498801826,\n",
       " 'minigames': 0.3556384550389224,\n",
       " 'social deduction': 0.3556384550389224,\n",
       " 'departure': 0.3556384550389224,\n",
       " 'impostors': 0.3556384550389224,\n",
       " 'player': 0.12246124072423722,\n",
       " 'players': 0.10945207312053964,\n",
       " 'spaceship': 0.3556384550389224}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAME_DAT_TFIDF[\"AMONG US\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('bmo-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f94925f3cff0b0ac90dd538919dcd2d4d02467fa3fdafdf86812e92b857d43c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

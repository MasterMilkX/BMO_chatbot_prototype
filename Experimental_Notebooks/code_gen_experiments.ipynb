{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE SNIPPET GENERATION EXPERIMENTS \n",
    "Generates code (pseudocode, function snippets from comment prompt generation) using genetic programming and transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milk/Desktop/GIL_Lab/BMO/BMO_chatbot_prototype/bmo-venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1: CodeGenT5\n",
    "Note: Can generate from a snippet of Python code. Modifying the max_time, max_new_tokens, and input string (comment with snippet of code) affects how accurate it returns the value. Needs a starter function with parameters in order to actually write the code (follow comment with a \"\\ndef x(\"). Doesn't improve with beam search. Low temperature is best.\n",
    "\n",
    "\\> Input: `\"# write a function that multiplies all numbers in a list by a random number\\ndef x(\"`\n",
    "\n",
    "\\> Options:\n",
    "```\n",
    "options = {\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"temperature\": 0.2,    #lower is better for more efficient code\n",
    "    \"do_sample\": True,\n",
    "    \"max_time\": 10,   #maximum time allotted to generate\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "\\> Output: \n",
    "\n",
    "```# write a function that multiplies all numbers in a list by a random number\n",
    "def x(n):\n",
    "    return n*random.randint(1,10)\n",
    "\n",
    "# write a function that takes a list of numbers and returns the largest number\n",
    "def largest(n):\n",
    "    return max(n)\n",
    "\n",
    "# write a function that```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# write a function that multiplies all numbers in a list by a random number\n",
      "def x(lst):\n",
      "    return lst[0] * random.randint(1, 10)\n",
      "\n",
      "# write a function that takes a list of numbers and returns the largest number\n",
      "def largest(lst):\n",
      "    return max(lst)\n",
      "\n",
      "# write\n",
      "=========================================\n",
      "# write a function that multiplies all numbers in a list by a random number\n",
      "def x(numbers):\n",
      "    # write your code here\n",
      "    return numbers[0] * numbers[1]\n",
      "\n",
      "# write a function that takes a list of numbers and returns the sum of those numbers\n",
      "def sum(numbers):\n",
      "    # write your code here\n",
      "    \n",
      "=========================================\n",
      "# write a function that multiplies all numbers in a list by a random number\n",
      "def x(nums):\n",
      "    return nums[0] * nums[1] * nums[2] * nums[3] * nums[4] * nums[5] * nums[6] * nums[7] * nums[\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"Salesforce/codegen-350M-mono\"\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "text = \"# write a function that multiplies all numbers in a list by a random number\\ndef x(\"\n",
    "\n",
    "options = {\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"temperature\": 0.2,    #lower is better for more efficient code\n",
    "    # \"repetition_penalty\": 0.01,\n",
    "    \"do_sample\": True,\n",
    "    \"max_time\": 10,   #maximum time allotted to generate\n",
    "    \"num_return_sequences\": 3,\n",
    "}\n",
    "completion = model.generate(**tokenizer(text, return_tensors=\"pt\"), **options)\n",
    "\n",
    "for c in completion:\n",
    "    print(tokenizer.decode(c))\n",
    "    print(\"=========================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmo-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f94925f3cff0b0ac90dd538919dcd2d4d02467fa3fdafdf86812e92b857d43c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

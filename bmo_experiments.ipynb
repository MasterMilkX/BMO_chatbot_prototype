{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasterMilkX/BMO_chatbot_prototype/blob/main/bmo_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa3GPYKSblkU",
        "outputId": "40e73877-2010-4471-dabf-559acc2cd6b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGcRA9HFOWYB"
      },
      "source": [
        "#scrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQDwP3rqw5V9"
      },
      "outputs": [],
      "source": [
        "#use the microstudio_scrapper to get links.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdwWL8gjF00e"
      },
      "outputs": [],
      "source": [
        "# !pip install wget\n",
        "import wget\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GgW4Fb5FT5d"
      },
      "outputs": [],
      "source": [
        "# find source \n",
        "def author_game(string):\n",
        "    index = []\n",
        "    for i, c in enumerate(string):\n",
        "        if c == '/':\n",
        "            index.append(i)\n",
        "    return string[index[2] : index[4]]\n",
        "\n",
        "# extract ms folder from the zip file\n",
        "def extract_zip(file_name):\n",
        "    archive = zipfile.ZipFile(file_name+'.zip')\n",
        "\n",
        "    for file in archive.namelist():\n",
        "        if file.startswith('ms'):\n",
        "            archive.extract(file, 'codes/'+file_name)\n",
        "        if file.startswith('sprites'):\n",
        "            archive.extract(file, 'sprites/'+file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkbkQL4KFJO1"
      },
      "outputs": [],
      "source": [
        "file1 = open('links.txt', 'r')\n",
        "lines = file1.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFQe7-zzFpt_"
      },
      "outputs": [],
      "source": [
        "for line in lines:\n",
        "    url = line\n",
        "    url_name = \"_\".join(author_game(url).split(\"/\")[1:])\n",
        "    wget.download(url, url_name + '.zip')\n",
        "    extract_zip(url_name)\n",
        "    # os.remove(url_name + '.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubYGf3L_Glwq",
        "outputId": "1c54163a-abcf-4730-f078-9ac0b84cef3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘zips’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir zips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPdHXvHwGJdT"
      },
      "outputs": [],
      "source": [
        "!mv sprites /content/drive/MyDrive/microstudio_games"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gc6pB6TIGvdO"
      },
      "outputs": [],
      "source": [
        "!du /content/drive/MyDrive/microstudio_games -h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z0TSDzPOaKS"
      },
      "source": [
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "UX6laYDxVgTy"
      },
      "outputs": [],
      "source": [
        "#path to zip file\n",
        "!cp \"/content/drive/MyDrive/bmo s/microstudio_games.zip\" ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "CiEz5BAmcUYN"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"microstudio_games.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "x27TZ0QdV97b"
      },
      "outputs": [],
      "source": [
        "#convert directories to list of source code\n",
        "import os\n",
        "def getListOfFiles(dirName):\n",
        "    listOfFile = os.listdir(dirName)\n",
        "    allFiles = list()\n",
        "    for entry in listOfFile:\n",
        "        fullPath = os.path.join(dirName, entry)\n",
        "        if os.path.isdir(fullPath):\n",
        "            allFiles = allFiles + getListOfFiles(fullPath)\n",
        "        else:\n",
        "            allFiles.append(fullPath)\n",
        "                \n",
        "    return allFiles \n",
        "code_list = getListOfFiles(\"microstudio_games/codes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "7Jz3SGs4crKE"
      },
      "outputs": [],
      "source": [
        "# converting into pandas df/csv\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(columns = [\"codes\"])\n",
        "for file in code_list:\n",
        "  with open(file, 'r') as f:\n",
        "    string = f.read()\n",
        "    df = df.append({\"codes\" : string}, ignore_index=True)\n",
        "\n",
        "df.to_csv('data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# modify data"
      ],
      "metadata": {
        "id": "sAvSKcrECydY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df\n",
        "data"
      ],
      "metadata": {
        "id": "yYrJTXa-C0XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_m_lines = data.copy()\n",
        "for i, code in enumerate(data[\"codes\"]):\n",
        "  data_m_lines[\"codes\"][i] = \"%\"+ code.replace(\"\\n\", \"\\n%\")\n",
        "\n",
        "data_m_lines.to_csv(\"data_m_lines.csv\")"
      ],
      "metadata": {
        "id": "OxLglgwnC7GY"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('data_m_lines.csv')\n",
        "df['split'] = np.random.randn(df.shape[0], 1)\n",
        "\n",
        "msk = np.random.rand(len(df)) <= 0.8\n",
        "\n",
        "train = df[msk]\n",
        "val = df[~msk]\n",
        "train['codes'].to_csv(\"train.csv\", index=False)\n",
        "val['codes'].to_csv(\"val.csv\", index = False)"
      ],
      "metadata": {
        "id": "PyjQ6uF3ThKF"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run using hugging face examples"
      ],
      "metadata": {
        "id": "vq_3vcozWEkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('run_clm.py', 'w') as f:\n",
        "  import requests\n",
        "  r = requests.get(\"https://raw.githubusercontent.com/huggingface/transformers/main/examples/pytorch/language-modeling/run_clm.py\")\n",
        "  f.write(r.text)"
      ],
      "metadata": {
        "id": "J-01ohncSPRF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "id": "bAF8e--RVSJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_clm.py \\\n",
        "    --model_name_or_path \"Salesforce/codegen-350M-multi\" \\\n",
        "    --train_file /content/train.csv \\\n",
        "    --validation_file /content/val.csv \\\n",
        "    --per_device_train_batch_size 1 \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --do_train yes \\\n",
        "    --do_eval yes \\\n",
        "    --output_dir /outputs/test-clm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9apg3LWSyDB",
        "outputId": "14836503-802d-4083-b601-27b529d9ed1c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=passive,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/outputs/test-clm/runs/Oct23_15-01-10_e0ad22031bf2,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_hf,\n",
            "output_dir=/outputs/test-clm,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=1,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/outputs/test-clm,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "WARNING:datasets.builder:Using custom data configuration default-07ceba0c76421595\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.7/dist-packages/datasets/packaged_modules/csv\n",
            "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
            "INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-07ceba0c76421595/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\n",
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-07ceba0c76421595/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
            "INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-07ceba0c76421595/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\n",
            "100% 2/2 [00:00<00:00, 1042.84it/s]\n",
            "[INFO|configuration_utils.py:653] 2022-10-23 15:01:13,542 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-multi/snapshots/1748d49531519340782a2c6ed3f436ec2c521167/config.json\n",
            "[INFO|configuration_utils.py:705] 2022-10-23 15:01:13,543 >> Model config CodeGenConfig {\n",
            "  \"_name_or_path\": \"Salesforce/codegen-350M-multi\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"CodeGenForCausalLM\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"codegen\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 20,\n",
            "  \"n_positions\": 2048,\n",
            "  \"resid_pdrop\": 0.0,\n",
            "  \"rotary_dim\": 32,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50,\n",
            "      \"temperature\": 1.0\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.24.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1775] 2022-10-23 15:01:14,495 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-multi/snapshots/1748d49531519340782a2c6ed3f436ec2c521167/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1775] 2022-10-23 15:01:14,496 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-multi/snapshots/1748d49531519340782a2c6ed3f436ec2c521167/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1775] 2022-10-23 15:01:14,496 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-multi/snapshots/1748d49531519340782a2c6ed3f436ec2c521167/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1775] 2022-10-23 15:01:14,496 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-multi/snapshots/1748d49531519340782a2c6ed3f436ec2c521167/added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:1775] 2022-10-23 15:01:14,496 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-multi/snapshots/1748d49531519340782a2c6ed3f436ec2c521167/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1775] 2022-10-23 15:01:14,496 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-multi/snapshots/1748d49531519340782a2c6ed3f436ec2c521167/tokenizer_config.json\n",
            "[INFO|modeling_utils.py:2156] 2022-10-23 15:01:14,568 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--Salesforce--codegen-350M-multi/snapshots/1748d49531519340782a2c6ed3f436ec2c521167/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:2606] 2022-10-23 15:01:18,367 >> All model checkpoint weights were used when initializing CodeGenForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:2615] 2022-10-23 15:01:18,367 >> All the weights of CodeGenForCausalLM were initialized from the model checkpoint at Salesforce/codegen-350M-multi.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use CodeGenForCausalLM for predictions without further training.\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-07ceba0c76421595/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-72f307ff44e247fc.arrow\n",
            "Running tokenizer on dataset:   0% 0/1 [00:00<?, ?ba/s][WARNING|tokenization_utils_base.py:3522] 2022-10-23 15:01:20,645 >> Token indices sequence length is longer than the specified maximum sequence length for this model (2453 > 2048). Running this sequence through the model will result in indexing errors\n",
            "[WARNING|run_clm.py:409] 2022-10-23 15:01:20,645 >> ^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits before being passed to the model.\n",
            "INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-07ceba0c76421595/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-25bded92bf7699f4.arrow\n",
            "Running tokenizer on dataset:   0% 0/1 [00:00<?, ?ba/s]\n",
            "WARNING:__main__:The tokenizer picked seems to have a very large `model_max_length` (2048). Picking 1024 instead. You can change that default value by passing --block_size xxx.\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-07ceba0c76421595/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-5cddc02d96cb88b9.arrow\n",
            "Grouping texts in chunks of 1024:   0% 0/1 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-07ceba0c76421595/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-a9c2490b6d5c8c39.arrow\n",
            "Grouping texts in chunks of 1024:   0% 0/1 [00:00<?, ?ba/s]\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1607] 2022-10-23 15:01:26,055 >> ***** Running training *****\n",
            "[INFO|trainer.py:1608] 2022-10-23 15:01:26,055 >>   Num examples = 1075\n",
            "[INFO|trainer.py:1609] 2022-10-23 15:01:26,055 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1610] 2022-10-23 15:01:26,055 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1611] 2022-10-23 15:01:26,055 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1612] 2022-10-23 15:01:26,055 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1613] 2022-10-23 15:01:26,055 >>   Total optimization steps = 3225\n",
            "  0% 0/3225 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py:167: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:402.)\n",
            "  attn_weights = torch.where(causal_mask, attn_weights, mask_value)\n",
            "{'loss': 1.0842, 'learning_rate': 4.2248062015503877e-05, 'epoch': 0.47}\n",
            " 16% 500/3225 [07:22<40:12,  1.13it/s][INFO|trainer.py:2671] 2022-10-23 15:08:48,818 >> Saving model checkpoint to /outputs/test-clm/checkpoint-500\n",
            "[INFO|configuration_utils.py:447] 2022-10-23 15:08:48,819 >> Configuration saved in /outputs/test-clm/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-10-23 15:08:54,496 >> Model weights saved in /outputs/test-clm/checkpoint-500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2125] 2022-10-23 15:08:54,496 >> tokenizer config file saved in /outputs/test-clm/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2132] 2022-10-23 15:08:54,497 >> Special tokens file saved in /outputs/test-clm/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 0.9003, 'learning_rate': 3.449612403100775e-05, 'epoch': 0.93}\n",
            " 31% 1000/3225 [15:03<32:52,  1.13it/s][INFO|trainer.py:2671] 2022-10-23 15:16:29,245 >> Saving model checkpoint to /outputs/test-clm/checkpoint-1000\n",
            "[INFO|configuration_utils.py:447] 2022-10-23 15:16:29,246 >> Configuration saved in /outputs/test-clm/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-10-23 15:16:34,839 >> Model weights saved in /outputs/test-clm/checkpoint-1000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2125] 2022-10-23 15:16:34,840 >> tokenizer config file saved in /outputs/test-clm/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2132] 2022-10-23 15:16:34,840 >> Special tokens file saved in /outputs/test-clm/checkpoint-1000/special_tokens_map.json\n",
            "{'loss': 0.6446, 'learning_rate': 2.674418604651163e-05, 'epoch': 1.4}\n",
            " 47% 1500/3225 [22:44<25:30,  1.13it/s][INFO|trainer.py:2671] 2022-10-23 15:24:10,085 >> Saving model checkpoint to /outputs/test-clm/checkpoint-1500\n",
            "[INFO|configuration_utils.py:447] 2022-10-23 15:24:10,086 >> Configuration saved in /outputs/test-clm/checkpoint-1500/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-10-23 15:24:15,856 >> Model weights saved in /outputs/test-clm/checkpoint-1500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2125] 2022-10-23 15:24:15,856 >> tokenizer config file saved in /outputs/test-clm/checkpoint-1500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2132] 2022-10-23 15:24:15,857 >> Special tokens file saved in /outputs/test-clm/checkpoint-1500/special_tokens_map.json\n",
            "{'loss': 0.5357, 'learning_rate': 1.8992248062015506e-05, 'epoch': 1.86}\n",
            " 62% 2000/3225 [30:25<18:06,  1.13it/s][INFO|trainer.py:2671] 2022-10-23 15:31:51,437 >> Saving model checkpoint to /outputs/test-clm/checkpoint-2000\n",
            "[INFO|configuration_utils.py:447] 2022-10-23 15:31:51,438 >> Configuration saved in /outputs/test-clm/checkpoint-2000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-10-23 15:31:57,236 >> Model weights saved in /outputs/test-clm/checkpoint-2000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2125] 2022-10-23 15:31:57,237 >> tokenizer config file saved in /outputs/test-clm/checkpoint-2000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2132] 2022-10-23 15:31:57,237 >> Special tokens file saved in /outputs/test-clm/checkpoint-2000/special_tokens_map.json\n",
            "{'loss': 0.4134, 'learning_rate': 1.1240310077519382e-05, 'epoch': 2.33}\n",
            " 78% 2500/3225 [38:06<10:42,  1.13it/s][INFO|trainer.py:2671] 2022-10-23 15:39:32,316 >> Saving model checkpoint to /outputs/test-clm/checkpoint-2500\n",
            "[INFO|configuration_utils.py:447] 2022-10-23 15:39:32,317 >> Configuration saved in /outputs/test-clm/checkpoint-2500/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-10-23 15:39:38,086 >> Model weights saved in /outputs/test-clm/checkpoint-2500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2125] 2022-10-23 15:39:38,086 >> tokenizer config file saved in /outputs/test-clm/checkpoint-2500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2132] 2022-10-23 15:39:38,087 >> Special tokens file saved in /outputs/test-clm/checkpoint-2500/special_tokens_map.json\n",
            "{'loss': 0.2808, 'learning_rate': 3.488372093023256e-06, 'epoch': 2.79}\n",
            " 93% 3000/3225 [45:47<03:19,  1.13it/s][INFO|trainer.py:2671] 2022-10-23 15:47:13,131 >> Saving model checkpoint to /outputs/test-clm/checkpoint-3000\n",
            "[INFO|configuration_utils.py:447] 2022-10-23 15:47:13,134 >> Configuration saved in /outputs/test-clm/checkpoint-3000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-10-23 15:47:18,929 >> Model weights saved in /outputs/test-clm/checkpoint-3000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2125] 2022-10-23 15:47:19,016 >> tokenizer config file saved in /outputs/test-clm/checkpoint-3000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2132] 2022-10-23 15:47:19,016 >> Special tokens file saved in /outputs/test-clm/checkpoint-3000/special_tokens_map.json\n",
            "100% 3225/3225 [49:23<00:00,  1.13it/s][INFO|trainer.py:1852] 2022-10-23 15:50:50,049 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 2964.0525, 'train_samples_per_second': 1.088, 'train_steps_per_second': 1.088, 'train_loss': 0.6181490781325703, 'epoch': 3.0}\n",
            "100% 3225/3225 [49:24<00:00,  1.09it/s]\n",
            "[INFO|trainer.py:2671] 2022-10-23 15:50:50,113 >> Saving model checkpoint to /outputs/test-clm\n",
            "[INFO|configuration_utils.py:447] 2022-10-23 15:50:50,113 >> Configuration saved in /outputs/test-clm/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-10-23 15:50:55,922 >> Model weights saved in /outputs/test-clm/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2125] 2022-10-23 15:50:55,922 >> tokenizer config file saved in /outputs/test-clm/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2132] 2022-10-23 15:50:55,922 >> Special tokens file saved in /outputs/test-clm/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =     0.6181\n",
            "  train_runtime            = 0:49:24.05\n",
            "  train_samples            =       1075\n",
            "  train_samples_per_second =      1.088\n",
            "  train_steps_per_second   =      1.088\n",
            "INFO:__main__:*** Evaluate ***\n",
            "[INFO|trainer.py:2922] 2022-10-23 15:50:56,028 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2924] 2022-10-23 15:50:56,028 >>   Num examples = 442\n",
            "[INFO|trainer.py:2927] 2022-10-23 15:50:56,028 >>   Batch size = 1\n",
            "100% 442/442 [02:01<00:00,  3.64it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_accuracy           =     0.7871\n",
            "  eval_loss               =     1.2533\n",
            "  eval_runtime            = 0:02:01.92\n",
            "  eval_samples            =        442\n",
            "  eval_samples_per_second =      3.625\n",
            "  eval_steps_per_second   =      3.625\n",
            "  perplexity              =     3.5019\n",
            "[INFO|modelcard.py:444] 2022-10-23 15:52:58,921 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.787100312717011}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## results...?"
      ],
      "metadata": {
        "id": "LhnsqnGNvA6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
        "model2 = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
        "model = torch.load('/outputs/test-clm/pytorch_model.bin')"
      ],
      "metadata": {
        "id": "-mwiN5fEj4i9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du /outputs -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0ouds41qcM-",
        "outputId": "558e2d06-9d9c-4e37-f2f5-fec6e3170d2d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.1G\t/outputs/test-clm/checkpoint-1500\n",
            "4.1G\t/outputs/test-clm/checkpoint-1000\n",
            "4.1G\t/outputs/test-clm/checkpoint-3000\n",
            "4.1G\t/outputs/test-clm/checkpoint-500\n",
            "12K\t/outputs/test-clm/runs/Oct23_15-01-10_e0ad22031bf2/1666537286.063863\n",
            "28K\t/outputs/test-clm/runs/Oct23_15-01-10_e0ad22031bf2\n",
            "32K\t/outputs/test-clm/runs\n",
            "4.1G\t/outputs/test-clm/checkpoint-2000\n",
            "4.1G\t/outputs/test-clm/checkpoint-2500\n",
            "26G\t/outputs/test-clm\n",
            "26G\t/outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.resize_token_embeddings(50295)\n",
        "model2.state_dict()"
      ],
      "metadata": {
        "id": "FaRJ0-bip7xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model2 = model2.resize_token_embeddings(50295)\n",
        "model2.load_state_dict(model, strict=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6qA5AXLmDm7",
        "outputId": "baa5cd7b-2497-4b6f-adf1-a0970f0e9534"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output(text): #text = \"%draw = function():\"\n",
        "  input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "  generated_ids = model2.generate(input_ids, max_length=128)\n",
        "  print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "xjLZWl9-nCVy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_output(\"%movements = function()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBw270mBtG58",
        "outputId": "585dfd8f-5925-445d-8a77-355989508758"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%movements = function()\n",
            "%  if cash > 0 then\n",
            "%    if direction == 1 then\n",
            "%      x += speed * cash\n",
            "%    elsif direction == -1 then\n",
            "%      x -= speed * cash\n",
            "%    end\n",
            "%  end\n",
            "%  \n",
            "%  if cash < 0 then\n",
            "%    if direction == 1 then\n",
            "%      x -= speed\n",
            "%    elsif direction == -1 then\n",
            "%      x += speed\n",
            "%    end\n",
            "%  end\n",
            "%  \n",
            "%  if cash > 0 then\n",
            "%    if direction == 1 then\n",
            "%      y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_output(\"%move_player = function()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLXMpNAqtVGx",
        "outputId": "8c7979d1-f81c-4b73-d197-6f1f23584a81"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%move_player = function()\n",
            "%  if is_taking_turn(player) then \n",
            "%    is_taking_turn = false\n",
            "%    take_turn = true\n",
            "%    turning_left = false\n",
            "%    turning_right = false\n",
            "%    \n",
            "%    local player_x = player.x\n",
            "%    local player_y = player.y\n",
            "%    \n",
            "%    // if player is moving left, check if there is any obstacles on the left\n",
            "%    if player.vx < 0 and \n",
            "%      (map.get_block(player_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_output(\"% //flip the sprite\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_50Z6KAMtsHz",
        "outputId": "dc7a838b-640a-41ce-aed5-db57e2d8224e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% //flip the sprite if facing left\n",
            "%      if o.x<0 then\n",
            "%        o.vx = -o.vx\n",
            "%        o.x = -o.x\n",
            "%        o.hflip = -1\n",
            "%      elsif o.x>0 then\n",
            "%        o.vx =  o.vx\n",
            "%        o.x = -o.x\n",
            "%        o.hflip = 1\n",
            "%      end\n",
            "%    end\n",
            "%  end\n",
            "%end\n",
            "%\n",
            "%// sets the length of a movement vector to 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_output(\"% if onLadder then \\n%  //climb ladder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpUESXjft5sw",
        "outputId": "e8afe2be-f4e9-4598-fffa-6dfb217f0ae5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% if onLadder then \n",
            "%  //climb ladder\n",
            "%  //Add upper/lower link\n",
            "%  //Go to ladder rest\n",
            "%  //Climbing state\n",
            "%  if not onLadder.isTop then\n",
            "%    if not onLadder.isOpen then\n",
            "%      if not onLadder.isBottom then\n",
            "%        if not onLadder.isTop then\n",
            "%          onLadder = onLadder.clone()\n",
            "%          onLadder.setTop(false)\n",
            "%        end\n",
            "%      else\n",
            "%        onLadder.set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_output(\"% //show text on screen\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LZtnDKbukek",
        "outputId": "9adcc614-c026-45f5-b5c7-fafadd65ce27"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% //show text on screen\n",
            "%  if show_timer then\n",
            "%    // draw timer\n",
            "%    if timer<60 then\n",
            "%      screen.setAlpha(0.4)\n",
            "%      screen.fillRect(95, 90, 100, 20, \"#000\")\n",
            "%      screen.setAlpha(1)\n",
            "%      if show_timer<10 then\n",
            "%        screen.drawText(\"h:mm:ss.0000\", 100, 90, 10, \"#FFF\")\n",
            "%      else\n",
            "%        screen.drawText(\"h:mm:ss.000000\", 100, 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_output(\"% //print 'BMO chatbot' on screen\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-4kFkuvvLFQ",
        "outputId": "21c47b51-53ff-404d-9f35-7db1a2ef20e6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% //print 'BMO chatbot' on screen\n",
            "%    if keyboard.press.SPACE or mouse.press or touch.press then\n",
            "%      if (not status) then\n",
            "%        status = \"movel\"\n",
            "%        if random.next()<0.005 then\n",
            "%          if mouse.x<-40 and mouse.x>=-40 and mouse.y<-80 and mouse.y>=-80 then\n",
            "%            status = \"run\"\n",
            "%          end\n",
            "%        end\n",
            "%      end\n",
            "%    end\n",
            "%    \n",
            "%    if status == \"run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_output(\"% name = \\\"bmo says hi\\\"\\n% //show name on top left\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aeiDfOtvbcV",
        "outputId": "75260d63-e9c6-4dac-9cc2-3b0e103b2f83"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% name = \"bmo says hi\"\n",
            "% //show name on top left\n",
            "%  h = 80\n",
            "%  x = 170\n",
            "%  y = -80\n",
            "%  l = 50\n",
            "%  w = 170\n",
            "%  h = 40\n",
            "%  bg =\"rgb(0,0,0)\"\n",
            "%  text = \"microStudio Jam #3\"\n",
            "%  text_size = 15\n",
            "%  score = 0\n",
            "%  highscore = storage.get(high)\n",
            "%  if(highscore) then\n",
            "%    highscore = highscore+1\n",
            "%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_output(\"%//show name on top left\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGQRAqYHwWYm",
        "outputId": "e95bde1f-3bd9-436d-d9b4-7d8ed5cfaf1c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%//show name on top left\n",
            "%  if global.show_name then\n",
            "%    screen.drawText(name,0,global.SW-10,9,\"rgb(255,255,255)\")\n",
            "%  end\n",
            "%  \n",
            "%  //if invert then\n",
            "%    screen.drawSprite(\"invert\",0,0,width,height)\n",
            "%  //end\n",
            "%  \n",
            "%  //if not show_controls then\n",
            "%    screen.drawSprite(\"touchcontrols\",0,global.SW-10,12,12)\n",
            "%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_output(\"%//show name on top right\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i28foLJkw8fn",
        "outputId": "95f208ba-f12b-45e9-fe40-8ee69fa9bbc0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%//show name on top right\n",
            "%  if global.show_name then\n",
            "%    screen.drawTextOutline(\"microStudio Jam #3\", 0, -55, 21,\"rgb(255,0,0)\")\n",
            "%    screen.drawText(\"microStudio Jam #3\", 0, -55, 20, \"#FFF\")\n",
            "%    screen.drawTextOutline(\"by MGB\", 0, -64, 52,\"rgb(255,0,0)\")\n",
            "%    screen.drawText(\"by MGB\", 0, -64, 50, \"#FFF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C78H1Tnx3maJ"
      },
      "source": [
        "# trying something with the comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNzc6asg34Rd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1QuvFwh3w-X",
        "outputId": "95a2020b-7045-4e64-f929-66037015fe2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       if start then\\n  credits = {}\\n  \\n  \\n  credi...\n",
              "1       if start then\\n  map = {}\\n  \\n  \\n  map.name ...\n",
              "2       if start then\\n  player = {}\\n  \\n  \\n  player...\n",
              "3       function init()\\n  screen:setPixelated(\"pixela...\n",
              "4       function string:split(sep)\\n  local sep, field...\n",
              "                              ...                        \n",
              "1232    /*\\n  All of the code here is the level design...\n",
              "1233    mower=object\\n  \\n  init=function()\\n    ACC=0...\n",
              "1234    sfx=object\\n  \\n  init=function()\\n    sfxvol=...\n",
              "1235    /*\\n  Level section - Draws the 4x4 preview le...\n",
              "1236    game=object\\n  \\n  init=function()\\n    MAPXOF...\n",
              "Name: codes, Length: 1237, dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"data.csv\", index_col=False)\n",
        "df['codes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mh61mDkIl9Tb"
      },
      "outputs": [],
      "source": [
        "def add_comment_code(string, spans):\n",
        "  coms = [string[a:b] for (a,b) in spans]\n",
        "  codes = []\n",
        "\n",
        "  for i in range(len(spans)):\n",
        "    start = spans[i][1]\n",
        "    if(i==len(spans)-1):\n",
        "      end = -1\n",
        "    else:\n",
        "      end = spans[i+1][0]\n",
        "    codes.append(string[start:end])\n",
        "\n",
        "  coms = [com.replace(\"//\", \" \").replace(\"\\n\",\" \") for com in coms]\n",
        "  \n",
        "  return coms, codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVWbvQdR4ZWH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# comment_block , all code before next comment\n",
        "l_comments = []\n",
        "l_codes = []\n",
        "\n",
        "for string in df['codes']:\n",
        "  if(type(string) != str):\n",
        "    continue\n",
        "  \n",
        "  l_spans = []\n",
        "  prev = -1\n",
        "\n",
        "  for i in re.finditer(r'\\s*//.*\\n',string):\n",
        "    if(prev == i.span()[0]):\n",
        "      temp = l_spans[-1][0]\n",
        "      del l_spans[-1]\n",
        "      l_spans.append((temp, i.span()[1]))\n",
        "    else:\n",
        "      l_spans.append((i.span()[0],i.span()[1]))\n",
        "    prev = i.span()[1]\n",
        "\n",
        "  com, cod = add_comment_code(string, l_spans)\n",
        "  l_comments += com\n",
        "  l_codes += cod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoIfCvmfrzcR"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(columns= [\"comments\", \"codes\"], data = [[l_comments[i], l_codes[i]] for i in range(len(l_comments))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "A6qYXH-kr0l2",
        "outputId": "5d002ecf-e1dc-48c3-9493-bccba5194150"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-41f2aba8-dd59-432d-98bf-3ab86c98e4e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>codes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lets climb tht ladder</td>\n",
              "      <td>hero.fall = 0\\n              her...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>lets climb tht ladder</td>\n",
              "      <td>e.fall = 0\\n                e....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>lets climb tht ladder</td>\n",
              "      <td>hero.fall = 0\\n              her...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>lets climb tht ladder</td>\n",
              "      <td>e.fall = 0\\n                e....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>lets climb tht ladder</td>\n",
              "      <td>e.fall = 0\\n                e....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>lets climb tht ladder</td>\n",
              "      <td>e.fall = 0\\n              e.x = ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41f2aba8-dd59-432d-98bf-3ab86c98e4e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41f2aba8-dd59-432d-98bf-3ab86c98e4e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41f2aba8-dd59-432d-98bf-3ab86c98e4e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     comments  \\\n",
              "3      lets climb tht ladder    \n",
              "13     lets climb tht ladder    \n",
              "58     lets climb tht ladder    \n",
              "72     lets climb tht ladder    \n",
              "92     lets climb tht ladder    \n",
              "95     lets climb tht ladder    \n",
              "\n",
              "                                                codes  \n",
              "3                 hero.fall = 0\\n              her...  \n",
              "13                  e.fall = 0\\n                e....  \n",
              "58                hero.fall = 0\\n              her...  \n",
              "72                  e.fall = 0\\n                e....  \n",
              "92                  e.fall = 0\\n                e....  \n",
              "95                e.fall = 0\\n              e.x = ...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df[\"comments\"].str.contains('door')][df[\"comments\"].str.contains('open')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN3BAMn4ZSbK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "irm1lCf4zPWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UORF0W9E3gda"
      },
      "source": [
        "# copy paste train codegen by salesforce\n",
        " do not run, does not work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MfT6GjcRdg4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03d1bd80-529b-4215-c312-1997905e7cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.3-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 36.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-65.5.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 52.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\n",
            "Successfully installed pip-22.3 setuptools-65.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.21.1\n",
            "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==1.16.1\n",
            "  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.3/298.3 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepspeed==0.7.0\n",
            "  Downloading deepspeed-0.7.0.tar.gz (629 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.0/630.0 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.1) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.1) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.1) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.1) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.1) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.1) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.1) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.1) (2.23.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (6.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (1.3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (3.8.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (2022.8.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (0.3.5.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hjson\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.10.2.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.7.0) (5.4.8)\n",
            "Collecting py-cpuinfo\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.7.0) (1.9.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.7.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (1.8.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (4.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (6.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.21.1) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.21.1) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.21.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.21.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.21.1) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.21.1) (3.9.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.16.1) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.16.1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.16.1) (1.15.0)\n",
            "Building wheels for collected packages: deepspeed, py-cpuinfo\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.7.0-py3-none-any.whl size=644033 sha256=06ee08a62863411daf97b0afa90d59edcae3bdb0f39e0185eac5fb305495c91b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/98/32/bcab430f41969e2dfa19820d64189625737f41418e4efaf601\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22243 sha256=a38a37347ee35534ff7b27cb0e70d6bbeab920c203b09d5882162b48ed882808\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/a4/3c/0eb9f15dfa1d2de2a34da6ec21d91f549b69544030b81f4476\n",
            "Successfully built deepspeed py-cpuinfo\n",
            "Installing collected packages: tokenizers, py-cpuinfo, ninja, hjson, xxhash, multiprocess, huggingface-hub, deepspeed, transformers, datasets\n",
            "Successfully installed datasets-1.16.1 deepspeed-0.7.0 hjson-3.1.0 huggingface-hub-0.10.1 multiprocess-0.70.13 ninja-1.10.2.4 py-cpuinfo-8.0.0 tokenizers-0.12.1 transformers-4.21.1 xxhash-3.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2185278 sha256=5c3c01b7ef53089476b1b2c36f39d47794fbcfe021d00cf57211ac68fdecebab\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/78/7b/ee362defd6dd48e47794585f4c9e0262cbcafeba96fbde1ee6\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip setuptools\n",
        "!pip install torch --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install transformers==4.21.1 datasets==1.16.1 deepspeed==0.7.0\n",
        "!pip install mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzGfeNbdeTL4",
        "outputId": "0344dac2-3291-4bfe-e153-640a838f016b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-10-23 13:54:41,546] [WARNING] [runner.py:178:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2022-10-23 13:54:41,579] [INFO] [runner.py:504:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 train_deepspeed.py\n",
            "[2022-10-23 13:54:43,679] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.8.4-1+cuda11.2\n",
            "[2022-10-23 13:54:43,679] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.8.4-1\n",
            "[2022-10-23 13:54:43,679] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-23 13:54:43,679] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.8.4-1+cuda11.2\n",
            "[2022-10-23 13:54:43,679] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2022-10-23 13:54:43,680] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2022-10-23 13:54:43,680] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-23 13:54:43,680] [INFO] [launch.py:136:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2022-10-23 13:54:43,680] [INFO] [launch.py:143:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2022-10-23 13:54:43,680] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2022-10-23 13:54:43,680] [INFO] [launch.py:156:main] dist_world_size=1\n",
            "[2022-10-23 13:54:43,680] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "/usr/bin/python3: can't open file 'train_deepspeed.py': [Errno 2] No such file or directory\n",
            "[2022-10-23 13:54:44,689] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 675\n",
            "[2022-10-23 13:54:44,690] [ERROR] [launch.py:292:sigkill_handler] ['/usr/bin/python3', '-u', 'train_deepspeed.py', '--local_rank=0'] exits with return code = 2\n"
          ]
        }
      ],
      "source": [
        "!deepspeed --num_gpus=1 train_deepspeed.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87MPUIeVWytA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import random\n",
        "import math\n",
        "import mpi4py\n",
        "\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "from transformers import AutoConfig, AutoModelForCausalLM\n",
        "\n",
        "import deepspeed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CGaM1Rweezu"
      },
      "outputs": [],
      "source": [
        "DEEPSPEED_CONFIG = \\\n",
        "{\n",
        "    'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1},\n",
        "    'optimizer': {'type': 'AdamW', 'params': {'lr': 1e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}},\n",
        "    'scheduler': {'type': 'WarmupLR', 'params': {'warmup_min_lr': 0, 'warmup_max_lr': 1e-05, 'warmup_num_steps': 100}},\n",
        "    'zero_optimization': {\n",
        "        'stage': 3,\n",
        "        'offload_optimizer': {'device': 'cpu', 'pin_memory': False},\n",
        "        'offload_param': {'device': 'cpu', 'pin_memory': False},\n",
        "        'overlap_comm': True,\n",
        "        'contiguous_gradients': True,\n",
        "        'sub_group_size': 1e9,\n",
        "        'reduce_bucket_size': 16777216,\n",
        "        'stage3_prefetch_bucket_size': 15099494.4,\n",
        "        'stage3_param_persistence_threshold': 40960,\n",
        "        'stage3_max_live_parameters': 1e9,\n",
        "        'stage3_max_reuse_distance': 1e9,\n",
        "        'stage3_gather_fp16_weights_on_model_save': True\n",
        "    },\n",
        "    'train_batch_size': 32,\n",
        "    'train_micro_batch_size_per_gpu': 2,\n",
        "    'gradient_accumulation_steps': 16,\n",
        "    'gradient_clipping': 1.0,\n",
        "    'steps_per_print': 8,\n",
        "    'wall_clock_breakdown': False,\n",
        "    'compression_training': {'weight_quantization': {'shared_parameters': {}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {}, 'different_groups': {}}}\n",
        "}\n",
        "\n",
        "\n",
        "def create_args(args=argparse.Namespace()):\n",
        "\n",
        "    args.seed = 42\n",
        "\n",
        "    args.model = 'Salesforce/codegen-350M-multi'\n",
        "\n",
        "    args.deepspeed_config = DEEPSPEED_CONFIG\n",
        "\n",
        "    args.opt_steps_train = 1000\n",
        "\n",
        "    return args\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PDoyH8oenVX"
      },
      "outputs": [],
      "source": [
        "## train\n",
        "\n",
        "def train(args):\n",
        "\n",
        "    #######################\n",
        "    ## preamble\n",
        "\n",
        "    set_seed(args.seed)\n",
        "\n",
        "\n",
        "    #######################\n",
        "    ## model\n",
        "\n",
        "    print('initializing model')\n",
        "\n",
        "    config = AutoConfig.from_pretrained(args.model)\n",
        "    config.gradient_checkpointing = True\n",
        "    config.use_cache = False\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(args.model, config=config)\n",
        "\n",
        "    model.train()\n",
        "    # TODO(enijkamp): we need to set this flag twice?\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "\n",
        "    #######################\n",
        "    ## deepspeed\n",
        "\n",
        "    print('initializing deepspeed')\n",
        "\n",
        "    model_parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "    model_engine, optimizer, _, _ = deepspeed.initialize(config=args.deepspeed_config, model=model, model_parameters=model_parameters)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    #######################\n",
        "    ## train\n",
        "\n",
        "    print('starting training')\n",
        "\n",
        "    input_ids = torch.randint(low=0, high=10, size=[args.deepspeed_config['train_micro_batch_size_per_gpu'], 1024], dtype=torch.int64).cuda()\n",
        "\n",
        "    for step in range(args.opt_steps_train+1):\n",
        "\n",
        "        loss = model_engine(input_ids=input_ids, labels=input_ids).loss\n",
        "\n",
        "        model_engine.backward(loss)\n",
        "        model_engine.step()\n",
        "\n",
        "        print(f'{step} {loss:8.3f}')\n",
        "    return model_engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrHn3XBeeo00"
      },
      "outputs": [],
      "source": [
        "########################################################################################################\n",
        "## preamble\n",
        "\n",
        "def set_gpus(gpu):\n",
        "    torch.cuda.set_device(gpu)\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def set_cuda(deterministic=True):\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.deterministic = deterministic\n",
        "        torch.backends.cudnn.benchmark = not deterministic\n",
        "\n",
        "\n",
        "def get_exp_id(file):\n",
        "    return os.path.splitext(os.path.basename(file))[0]\n",
        "\n",
        "\n",
        "def get_output_dir(exp_id):\n",
        "    import datetime\n",
        "    t = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
        "    output_dir = os.path.join('output/' + exp_id, t)\n",
        "    return output_dir\n",
        "\n",
        "\n",
        "def copy_source(file, output_dir):\n",
        "    import shutil\n",
        "    shutil.copyfile(file, os.path.join(output_dir, os.path.basename(file)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "de464b0b27c449068b075748fd465955",
            "75815fd97d9e4d8784cded0f21b2dea4",
            "ef09095f1fdc48398b36a3881739d420",
            "4f5afca4602a4486a7e0c58b15083523",
            "7d1362e7ca4e4f0b98abbf34770adadc",
            "1c587423bf6e498ebb36c3b1af6b4cb7",
            "2a89bba7dfea42c992948aafd35a82fd",
            "7c4aead564ba4d4dbd9c45d5cfc09eda",
            "5d3f45991e574f189ff1c59d169ffe6c",
            "ef34cace72294c5b9adce212ac088419",
            "921a9667feff46388793156cbf625744",
            "ebcd505f95144660bdaa08c0e9a05564",
            "310611d138214baeaadc384de00275c3",
            "deb380e3e41948e8a8abe10411afab13",
            "03dfe8c4fc4a4a3f98a1a58cc0488674",
            "d1403a202a53419ea804d3dc51c0727e",
            "0fbb776fed954969a323bec7c981841a",
            "a783168c5b864219a5ea33826eb42167",
            "92ff073c83f4480f91fcdd4ca4a93c4c",
            "ba0ee532ff694eb59d943fb138d0b337",
            "53467e262e66486dbb717850cfc9d910",
            "f495032fb20246f7826164396699c1c8"
          ]
        },
        "id": "5SzDVgsne1W-",
        "outputId": "86d83e3e-14f8-4793-c89d-7378111b71fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initializing model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de464b0b27c449068b075748fd465955"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/760M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebcd505f95144660bdaa08c0e9a05564"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initializing deepspeed\n",
            "[2022-10-23 13:55:21,868] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.0, git-hash=unknown, git-branch=unknown\n",
            "[2022-10-23 13:55:21,874] [INFO] [comm.py:613:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
            "[2022-10-23 13:55:22,368] [INFO] [comm.py:670:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=172.28.0.2, master_port=29500\n",
            "[2022-10-23 13:55:22,371] [INFO] [comm.py:630:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[2022-10-23 13:55:22,382] [WARNING] [config_utils.py:64:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\n",
            "[2022-10-23 13:55:27,220] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/_distutils_hack/__init__.py:19: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
            "  \"Distutils was imported before Setuptools, but importing Setuptools \"\n",
            "/usr/local/lib/python3.7/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed CUDA version 11.2 does not match the version torch was compiled with 11.3 but since the APIs are compatible, accepting this combination\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py37_cu113/cpu_adam...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/cpu_adam/build.ninja...\n",
            "Building extension module cpu_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module cpu_adam...\n",
            "Time to load cpu_adam op: 31.845327854156494 seconds\n",
            "[2022-10-23 13:56:04,485] [INFO] [logging.py:68:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
            "[2022-10-23 13:56:04,496] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = {basic_optimizer.__class__.__name__}\n",
            "[2022-10-23 13:56:04,506] [INFO] [utils.py:53:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
            "[2022-10-23 13:56:04,507] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer\n",
            "[2022-10-23 13:56:04,621] [INFO] [utils.py:827:see_memory_usage] Stage 3 initialize beginning\n",
            "[2022-10-23 13:56:04,624] [INFO] [utils.py:832:see_memory_usage] MA 0.74 GB         Max_MA 0.74 GB         CA 0.76 GB         Max_CA 1 GB \n",
            "[2022-10-23 13:56:04,627] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 2.62 GB, percent = 20.7%\n",
            "[2022-10-23 13:56:04,633] [INFO] [stage3.py:114:__init__] Reduce bucket size 16777216\n",
            "[2022-10-23 13:56:04,634] [INFO] [stage3.py:115:__init__] Prefetch bucket size 15099494\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py37_cu113/utils...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 14.894068717956543 seconds\n",
            "[2022-10-23 13:56:19,638] [INFO] [utils.py:827:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
            "[2022-10-23 13:56:19,641] [INFO] [utils.py:832:see_memory_usage] MA 0.74 GB         Max_MA 0.74 GB         CA 0.76 GB         Max_CA 1 GB \n",
            "[2022-10-23 13:56:19,645] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 2.62 GB, percent = 20.7%\n",
            "[2022-10-23 13:56:19,652] [WARNING] [config_utils.py:64:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\n",
            "Parameter Offload: Total persistent parameters: 145408 in 82 params\n",
            "[2022-10-23 13:56:20,144] [INFO] [utils.py:827:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
            "[2022-10-23 13:56:20,146] [INFO] [utils.py:832:see_memory_usage] MA 0.08 GB         Max_MA 0.74 GB         CA 0.76 GB         Max_CA 1 GB \n",
            "[2022-10-23 13:56:20,154] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 2.82 GB, percent = 22.3%\n",
            "[2022-10-23 13:56:25,928] [INFO] [stage3.py:368:_setup_for_real_optimizer] optimizer state initialized\n",
            "[2022-10-23 13:56:26,689] [INFO] [utils.py:827:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2022-10-23 13:56:26,693] [INFO] [utils.py:832:see_memory_usage] MA 0.11 GB         Max_MA 0.3 GB         CA 0.96 GB         Max_CA 1 GB \n",
            "[2022-10-23 13:56:26,696] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 11.34 GB, percent = 89.5%\n",
            "[2022-10-23 13:56:26,698] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
            "[2022-10-23 13:56:26,701] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\n",
            "[2022-10-23 13:56:26,703] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f6330772a50>\n",
            "[2022-10-23 13:56:26,705] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[[0.9, 0.999]]\n",
            "[2022-10-23 13:56:26,707] [INFO] [config.py:975:print] DeepSpeedEngine configuration:\n",
            "[2022-10-23 13:56:26,709] [INFO] [config.py:979:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2022-10-23 13:56:26,710] [INFO] [config.py:979:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2022-10-23 13:56:26,711] [INFO] [config.py:979:print]   amp_enabled .................. False\n",
            "[2022-10-23 13:56:26,713] [INFO] [config.py:979:print]   amp_params ................... False\n",
            "[2022-10-23 13:56:26,716] [INFO] [config.py:979:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": null, \n",
            "    \"exps_dir\": null, \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2022-10-23 13:56:26,718] [INFO] [config.py:979:print]   bfloat16_enabled ............. False\n",
            "[2022-10-23 13:56:26,719] [INFO] [config.py:979:print]   checkpoint_tag_validation_enabled  True\n",
            "[2022-10-23 13:56:26,720] [INFO] [config.py:979:print]   checkpoint_tag_validation_fail  False\n",
            "[2022-10-23 13:56:26,721] [INFO] [config.py:979:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f63c60f4890>\n",
            "[2022-10-23 13:56:26,723] [INFO] [config.py:979:print]   communication_data_type ...... None\n",
            "[2022-10-23 13:56:26,724] [INFO] [config.py:979:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2022-10-23 13:56:26,725] [INFO] [config.py:979:print]   curriculum_enabled ........... False\n",
            "[2022-10-23 13:56:26,726] [INFO] [config.py:979:print]   curriculum_params ............ False\n",
            "[2022-10-23 13:56:26,727] [INFO] [config.py:979:print]   dataloader_drop_last ......... False\n",
            "[2022-10-23 13:56:26,729] [INFO] [config.py:979:print]   disable_allgather ............ False\n",
            "[2022-10-23 13:56:26,730] [INFO] [config.py:979:print]   dump_state ................... False\n",
            "[2022-10-23 13:56:26,731] [INFO] [config.py:979:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
            "[2022-10-23 13:56:26,733] [INFO] [config.py:979:print]   eigenvalue_enabled ........... False\n",
            "[2022-10-23 13:56:26,734] [INFO] [config.py:979:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2022-10-23 13:56:26,735] [INFO] [config.py:979:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2022-10-23 13:56:26,736] [INFO] [config.py:979:print]   eigenvalue_layer_num ......... 0\n",
            "[2022-10-23 13:56:26,738] [INFO] [config.py:979:print]   eigenvalue_max_iter .......... 100\n",
            "[2022-10-23 13:56:26,743] [INFO] [config.py:979:print]   eigenvalue_stability ......... 1e-06\n",
            "[2022-10-23 13:56:26,744] [INFO] [config.py:979:print]   eigenvalue_tol ............... 0.01\n",
            "[2022-10-23 13:56:26,745] [INFO] [config.py:979:print]   eigenvalue_verbose ........... False\n",
            "[2022-10-23 13:56:26,748] [INFO] [config.py:979:print]   elasticity_enabled ........... False\n",
            "[2022-10-23 13:56:26,749] [INFO] [config.py:979:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2022-10-23 13:56:26,751] [INFO] [config.py:979:print]   fp16_auto_cast ............... False\n",
            "[2022-10-23 13:56:26,752] [INFO] [config.py:979:print]   fp16_enabled ................. True\n",
            "[2022-10-23 13:56:26,754] [INFO] [config.py:979:print]   fp16_master_weights_and_gradients  False\n",
            "[2022-10-23 13:56:26,755] [INFO] [config.py:979:print]   global_rank .................. 0\n",
            "[2022-10-23 13:56:26,757] [INFO] [config.py:979:print]   gradient_accumulation_steps .. 16\n",
            "[2022-10-23 13:56:26,758] [INFO] [config.py:979:print]   gradient_clipping ............ 1.0\n",
            "[2022-10-23 13:56:26,759] [INFO] [config.py:979:print]   gradient_predivide_factor .... 1.0\n",
            "[2022-10-23 13:56:26,760] [INFO] [config.py:979:print]   initial_dynamic_scale ........ 4096\n",
            "[2022-10-23 13:56:26,761] [INFO] [config.py:979:print]   load_universal_checkpoint .... False\n",
            "[2022-10-23 13:56:26,762] [INFO] [config.py:979:print]   loss_scale ................... 0\n",
            "[2022-10-23 13:56:26,764] [INFO] [config.py:979:print]   memory_breakdown ............. False\n",
            "[2022-10-23 13:56:26,765] [INFO] [config.py:979:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f63c60f4850>\n",
            "[2022-10-23 13:56:26,766] [INFO] [config.py:979:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2022-10-23 13:56:26,768] [INFO] [config.py:979:print]   optimizer_legacy_fusion ...... False\n",
            "[2022-10-23 13:56:26,769] [INFO] [config.py:979:print]   optimizer_name ............... adamw\n",
            "[2022-10-23 13:56:26,770] [INFO] [config.py:979:print]   optimizer_params ............. {'lr': 1e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}\n",
            "[2022-10-23 13:56:26,771] [INFO] [config.py:979:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2022-10-23 13:56:26,772] [INFO] [config.py:979:print]   pld_enabled .................. False\n",
            "[2022-10-23 13:56:26,774] [INFO] [config.py:979:print]   pld_params ................... False\n",
            "[2022-10-23 13:56:26,779] [INFO] [config.py:979:print]   prescale_gradients ........... False\n",
            "[2022-10-23 13:56:26,781] [INFO] [config.py:979:print]   scheduler_name ............... WarmupLR\n",
            "[2022-10-23 13:56:26,782] [INFO] [config.py:979:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 1e-05, 'warmup_num_steps': 100}\n",
            "[2022-10-23 13:56:26,783] [INFO] [config.py:979:print]   sparse_attention ............. None\n",
            "[2022-10-23 13:56:26,788] [INFO] [config.py:979:print]   sparse_gradients_enabled ..... False\n",
            "[2022-10-23 13:56:26,789] [INFO] [config.py:979:print]   steps_per_print .............. 8\n",
            "[2022-10-23 13:56:26,790] [INFO] [config.py:979:print]   train_batch_size ............. 32\n",
            "[2022-10-23 13:56:26,791] [INFO] [config.py:979:print]   train_micro_batch_size_per_gpu  2\n",
            "[2022-10-23 13:56:26,792] [INFO] [config.py:979:print]   wall_clock_breakdown ......... False\n",
            "[2022-10-23 13:56:26,793] [INFO] [config.py:979:print]   world_size ................... 1\n",
            "[2022-10-23 13:56:26,794] [INFO] [config.py:979:print]   zero_allow_untested_optimizer  False\n",
            "[2022-10-23 13:56:26,806] [INFO] [config.py:979:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=16777216 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=15099494 param_persistence_threshold=40960 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=True ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
            "[2022-10-23 13:56:26,807] [INFO] [config.py:979:print]   zero_enabled ................. True\n",
            "[2022-10-23 13:56:26,808] [INFO] [config.py:979:print]   zero_optimization_stage ...... 3\n",
            "[2022-10-23 13:56:26,811] [INFO] [config.py:987:print]   json = {\n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"loss_scale\": 0, \n",
            "        \"loss_scale_window\": 1000, \n",
            "        \"initial_scale_power\": 12, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1\n",
            "    }, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"AdamW\", \n",
            "        \"params\": {\n",
            "            \"lr\": 1e-05, \n",
            "            \"betas\": [0.9, 0.999], \n",
            "            \"eps\": 1e-08, \n",
            "            \"weight_decay\": 0.0\n",
            "        }\n",
            "    }, \n",
            "    \"scheduler\": {\n",
            "        \"type\": \"WarmupLR\", \n",
            "        \"params\": {\n",
            "            \"warmup_min_lr\": 0, \n",
            "            \"warmup_max_lr\": 1e-05, \n",
            "            \"warmup_num_steps\": 100\n",
            "        }\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 3, \n",
            "        \"offload_optimizer\": {\n",
            "            \"device\": \"cpu\", \n",
            "            \"pin_memory\": false\n",
            "        }, \n",
            "        \"offload_param\": {\n",
            "            \"device\": \"cpu\", \n",
            "            \"pin_memory\": false\n",
            "        }, \n",
            "        \"overlap_comm\": true, \n",
            "        \"contiguous_gradients\": true, \n",
            "        \"sub_group_size\": 1.000000e+09, \n",
            "        \"reduce_bucket_size\": 1.677722e+07, \n",
            "        \"stage3_prefetch_bucket_size\": 1.509949e+07, \n",
            "        \"stage3_param_persistence_threshold\": 4.096000e+04, \n",
            "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
            "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
            "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
            "    }, \n",
            "    \"train_batch_size\": 32, \n",
            "    \"train_micro_batch_size_per_gpu\": 2, \n",
            "    \"gradient_accumulation_steps\": 16, \n",
            "    \"gradient_clipping\": 1.0, \n",
            "    \"steps_per_print\": 8, \n",
            "    \"wall_clock_breakdown\": false, \n",
            "    \"compression_training\": {\n",
            "        \"weight_quantization\": {\n",
            "            \"shared_parameters\": {\n",
            "            }, \n",
            "            \"different_groups\": {\n",
            "            }\n",
            "        }, \n",
            "        \"activation_quantization\": {\n",
            "            \"shared_parameters\": {\n",
            "            }, \n",
            "            \"different_groups\": {\n",
            "            }\n",
            "        }, \n",
            "        \"sparse_pruning\": {\n",
            "            \"shared_parameters\": {\n",
            "            }, \n",
            "            \"different_groups\": {\n",
            "            }\n",
            "        }, \n",
            "        \"row_pruning\": {\n",
            "            \"shared_parameters\": {\n",
            "            }, \n",
            "            \"different_groups\": {\n",
            "            }\n",
            "        }, \n",
            "        \"head_pruning\": {\n",
            "            \"shared_parameters\": {\n",
            "            }, \n",
            "            \"different_groups\": {\n",
            "            }\n",
            "        }, \n",
            "        \"channel_pruning\": {\n",
            "            \"shared_parameters\": {\n",
            "            }, \n",
            "            \"different_groups\": {\n",
            "            }\n",
            "        }\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "No modifications detected for re-loaded extension module utils, skipping build step...\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.013203144073486328 seconds\n",
            "starting training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py:167: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:402.)\n",
            "  attn_weights = torch.where(causal_mask, attn_weights, mask_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    3.805\n",
            "1    3.805\n",
            "2    3.805\n",
            "3    3.805\n",
            "4    3.805\n",
            "5    3.805\n",
            "6    3.805\n",
            "[2022-10-23 13:56:43,243] [INFO] [timer.py:207:stop] 0/8, RunningAvgSamplesPerSec=1.5181804679522688, CurrSamplesPerSec=1.5049135777929032, MemAllocated=0.21GB, MaxMemAllocated=2.03GB\n",
            "7    3.805\n",
            "8    3.805\n",
            "9    3.805\n",
            "10    3.805\n",
            "11    3.805\n",
            "12    3.805\n",
            "13    3.805\n",
            "14    3.805\n",
            "[2022-10-23 13:56:55,191] [INFO] [timer.py:207:stop] 0/16, RunningAvgSamplesPerSec=1.4110797731439624, CurrSamplesPerSec=0.7400870765617877, MemAllocated=0.11GB, MaxMemAllocated=2.03GB\n",
            "15    3.805\n",
            "16    3.027\n",
            "17    3.027\n",
            "18    3.027\n",
            "19    3.027\n",
            "20    3.027\n",
            "21    3.027\n",
            "22    3.027\n",
            "[2022-10-23 13:57:05,841] [INFO] [timer.py:207:stop] 0/24, RunningAvgSamplesPerSec=1.443356124437662, CurrSamplesPerSec=1.5129302151098094, MemAllocated=0.21GB, MaxMemAllocated=2.03GB\n",
            "23    3.027\n",
            "24    3.027\n",
            "25    3.027\n",
            "26    3.027\n",
            "27    3.027\n",
            "28    3.027\n",
            "29    3.027\n",
            "30    3.027\n",
            "[2022-10-23 13:57:17,764] [INFO] [timer.py:207:stop] 0/32, RunningAvgSamplesPerSec=1.4151309245371517, CurrSamplesPerSec=0.7494354626311819, MemAllocated=0.11GB, MaxMemAllocated=2.03GB\n",
            "31    3.027\n",
            "32    3.027\n",
            "33    3.027\n",
            "34    3.027\n",
            "35    3.027\n",
            "36    3.027\n",
            "37    3.027\n",
            "38    3.027\n",
            "[2022-10-23 13:57:28,376] [INFO] [timer.py:207:stop] 0/40, RunningAvgSamplesPerSec=1.4339684761319185, CurrSamplesPerSec=1.5185133694795867, MemAllocated=0.21GB, MaxMemAllocated=2.03GB\n",
            "39    3.027\n",
            "40    3.027\n",
            "41    3.027\n",
            "42    3.027\n",
            "43    3.027\n",
            "44    3.027\n",
            "45    3.027\n",
            "46    3.027\n",
            "[2022-10-23 13:57:40,388] [INFO] [timer.py:207:stop] 0/48, RunningAvgSamplesPerSec=1.4153092788980361, CurrSamplesPerSec=0.7344217653246026, MemAllocated=0.11GB, MaxMemAllocated=2.03GB\n",
            "47    3.027\n",
            "48    2.811\n",
            "49    2.811\n",
            "50    2.811\n",
            "51    2.811\n",
            "52    2.811\n",
            "53    2.811\n",
            "54    2.811\n",
            "[2022-10-23 13:57:50,977] [INFO] [timer.py:207:stop] 0/56, RunningAvgSamplesPerSec=1.4288724499407188, CurrSamplesPerSec=1.500532697006665, MemAllocated=0.21GB, MaxMemAllocated=2.03GB\n",
            "55    2.811\n",
            "56    2.811\n",
            "57    2.811\n",
            "58    2.811\n",
            "59    2.811\n",
            "60    2.811\n",
            "61    2.811\n",
            "62    2.811\n",
            "[2022-10-23 13:58:02,963] [INFO] [timer.py:207:stop] 0/64, RunningAvgSamplesPerSec=1.4161646273621624, CurrSamplesPerSec=0.7439840812427074, MemAllocated=0.11GB, MaxMemAllocated=2.03GB\n",
            "63    2.811\n",
            "64    2.746\n",
            "65    2.746\n",
            "66    2.746\n",
            "67    2.746\n",
            "68    2.746\n",
            "69    2.746\n",
            "70    2.746\n",
            "[2022-10-23 13:58:13,563] [INFO] [timer.py:207:stop] 0/72, RunningAvgSamplesPerSec=1.426377632968799, CurrSamplesPerSec=1.500750947249064, MemAllocated=0.21GB, MaxMemAllocated=2.03GB\n",
            "71    2.746\n",
            "72    2.746\n",
            "73    2.746\n",
            "74    2.746\n",
            "75    2.746\n",
            "76    2.746\n",
            "77    2.746\n",
            "78    2.746\n",
            "[2022-10-23 13:58:25,451] [INFO] [timer.py:207:stop] 0/80, RunningAvgSamplesPerSec=1.4177957769379137, CurrSamplesPerSec=0.7588138323508425, MemAllocated=0.11GB, MaxMemAllocated=2.03GB\n",
            "79    2.746\n",
            "80    2.629\n",
            "81    2.629\n",
            "82    2.629\n",
            "83    2.629\n",
            "84    2.629\n",
            "85    2.629\n",
            "86    2.629\n",
            "[2022-10-23 13:58:35,981] [INFO] [timer.py:207:stop] 0/88, RunningAvgSamplesPerSec=1.4267709433251274, CurrSamplesPerSec=1.5076052344688198, MemAllocated=0.21GB, MaxMemAllocated=2.03GB\n",
            "87    2.629\n",
            "88    2.629\n",
            "89    2.629\n",
            "90    2.629\n",
            "91    2.629\n",
            "92    2.629\n",
            "93    2.629\n",
            "94    2.629\n",
            "[2022-10-23 13:58:47,863] [INFO] [timer.py:207:stop] 0/96, RunningAvgSamplesPerSec=1.4196734194538705, CurrSamplesPerSec=0.7542814825178623, MemAllocated=0.11GB, MaxMemAllocated=2.03GB\n",
            "95    2.629\n",
            "96    2.549\n",
            "97    2.549\n",
            "98    2.549\n",
            "99    2.549\n",
            "100    2.549\n",
            "101    2.549\n",
            "102    2.549\n",
            "[2022-10-23 13:58:58,478] [INFO] [timer.py:207:stop] 0/104, RunningAvgSamplesPerSec=1.4262901924379046, CurrSamplesPerSec=1.5174033806266523, MemAllocated=0.21GB, MaxMemAllocated=2.03GB\n",
            "103    2.549\n",
            "104    2.549\n",
            "105    2.549\n",
            "106    2.549\n",
            "107    2.549\n",
            "108    2.549\n",
            "109    2.549\n",
            "110    2.549\n",
            "[2022-10-23 13:59:10,774] [INFO] [timer.py:207:stop] 0/112, RunningAvgSamplesPerSec=1.4164737664134253, CurrSamplesPerSec=0.6634020393942728, MemAllocated=0.11GB, MaxMemAllocated=2.42GB\n",
            "111    2.549\n",
            "112    2.480\n",
            "113    2.480\n",
            "114    2.480\n",
            "115    2.480\n",
            "116    2.480\n",
            "117    2.480\n",
            "118    2.480\n",
            "[2022-10-23 13:59:26,895] [INFO] [timer.py:207:stop] 0/120, RunningAvgSamplesPerSec=1.376828822411964, CurrSamplesPerSec=1.1049147757283044, MemAllocated=0.21GB, MaxMemAllocated=2.42GB\n",
            "119    2.480\n",
            "120    2.480\n",
            "121    2.480\n",
            "122    2.480\n",
            "123    2.480\n",
            "124    2.480\n",
            "125    2.480\n",
            "126    2.480\n",
            "[2022-10-23 13:59:40,037] [INFO] [logging.py:68:log_dist] [Rank 0] step=8, skipped=0, lr=[4.515449934959717e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-23 13:59:40,040] [INFO] [timer.py:207:stop] 0/128, RunningAvgSamplesPerSec=1.3656312290034436, CurrSamplesPerSec=0.7215980190352844, MemAllocated=0.11GB, MaxMemAllocated=2.42GB\n",
            "127    2.480\n",
            "128    2.422\n",
            "129    2.422\n",
            "130    2.422\n",
            "131    2.422\n",
            "132    2.422\n",
            "133    2.422\n",
            "134    2.422\n",
            "[2022-10-23 13:59:50,631] [INFO] [timer.py:207:stop] 0/136, RunningAvgSamplesPerSec=1.3735740837882124, CurrSamplesPerSec=1.524478574523208, MemAllocated=0.21GB, MaxMemAllocated=2.42GB\n",
            "135    2.422\n",
            "136    2.422\n",
            "137    2.422\n",
            "138    2.422\n",
            "139    2.422\n",
            "140    2.422\n",
            "141    2.422\n",
            "142    2.422\n",
            "[2022-10-23 14:00:02,558] [INFO] [timer.py:207:stop] 0/144, RunningAvgSamplesPerSec=1.3717783336316043, CurrSamplesPerSec=0.7507002851255152, MemAllocated=0.11GB, MaxMemAllocated=2.42GB\n",
            "143    2.422\n",
            "144    2.383\n",
            "145    2.383\n",
            "146    2.383\n",
            "147    2.383\n",
            "148    2.383\n",
            "149    2.383\n",
            "150    2.383\n",
            "[2022-10-23 14:00:13,126] [INFO] [timer.py:207:stop] 0/152, RunningAvgSamplesPerSec=1.3787350192059415, CurrSamplesPerSec=1.5170779160535106, MemAllocated=0.21GB, MaxMemAllocated=2.42GB\n",
            "151    2.383\n",
            "152    2.383\n",
            "153    2.383\n",
            "154    2.383\n",
            "155    2.383\n",
            "156    2.383\n",
            "157    2.383\n",
            "158    2.383\n",
            "[2022-10-23 14:00:25,011] [INFO] [timer.py:207:stop] 0/160, RunningAvgSamplesPerSec=1.37709937953873, CurrSamplesPerSec=0.7557749118033701, MemAllocated=0.11GB, MaxMemAllocated=2.42GB\n",
            "159    2.383\n",
            "160    2.355\n",
            "161    2.355\n",
            "162    2.355\n",
            "163    2.355\n",
            "164    2.355\n",
            "165    2.355\n",
            "166    2.355\n",
            "[2022-10-23 14:00:36,101] [INFO] [timer.py:207:stop] 0/168, RunningAvgSamplesPerSec=1.380186911850623, CurrSamplesPerSec=1.5046636169003738, MemAllocated=0.21GB, MaxMemAllocated=2.42GB\n",
            "167    2.355\n",
            "168    2.355\n",
            "169    2.355\n",
            "170    2.355\n",
            "171    2.355\n",
            "172    2.355\n",
            "173    2.355\n",
            "174    2.355\n",
            "[2022-10-23 14:00:47,978] [INFO] [timer.py:207:stop] 0/176, RunningAvgSamplesPerSec=1.3786826984541003, CurrSamplesPerSec=0.7590723519610798, MemAllocated=0.11GB, MaxMemAllocated=2.42GB\n",
            "175    2.355\n",
            "176    2.336\n",
            "177    2.336\n",
            "178    2.336\n",
            "179    2.336\n",
            "180    2.336\n",
            "181    2.336\n",
            "182    2.336\n",
            "[2022-10-23 14:00:58,594] [INFO] [timer.py:207:stop] 0/184, RunningAvgSamplesPerSec=1.383910243717667, CurrSamplesPerSec=1.5235684661621771, MemAllocated=0.21GB, MaxMemAllocated=2.42GB\n",
            "183    2.336\n",
            "184    2.336\n",
            "185    2.336\n",
            "186    2.336\n",
            "187    2.336\n",
            "188    2.336\n",
            "189    2.336\n",
            "190    2.336\n",
            "[2022-10-23 14:01:10,521] [INFO] [timer.py:207:stop] 0/192, RunningAvgSamplesPerSec=1.3821113309068342, CurrSamplesPerSec=0.7622624906166636, MemAllocated=0.11GB, MaxMemAllocated=2.42GB\n",
            "191    2.336\n",
            "192    2.316\n",
            "193    2.316\n",
            "194    2.316\n",
            "195    2.316\n",
            "196    2.316\n",
            "197    2.316\n",
            "198    2.316\n",
            "[2022-10-23 14:01:21,092] [INFO] [timer.py:207:stop] 0/200, RunningAvgSamplesPerSec=1.387015443113642, CurrSamplesPerSec=1.4901302899077458, MemAllocated=0.21GB, MaxMemAllocated=2.42GB\n",
            "199    2.316\n",
            "200    2.316\n",
            "201    2.316\n",
            "202    2.316\n",
            "203    2.316\n",
            "204    2.316\n",
            "205    2.316\n",
            "206    2.316\n",
            "[2022-10-23 14:01:33,028] [INFO] [timer.py:207:stop] 0/208, RunningAvgSamplesPerSec=1.3851831200386462, CurrSamplesPerSec=0.7433652064545441, MemAllocated=0.11GB, MaxMemAllocated=2.42GB\n",
            "207    2.316\n",
            "208    2.305\n",
            "209    2.305\n",
            "210    2.305\n",
            "211    2.305\n",
            "212    2.305\n",
            "213    2.305\n",
            "214    2.305\n",
            "[2022-10-23 14:01:43,560] [INFO] [timer.py:207:stop] 0/216, RunningAvgSamplesPerSec=1.3897955729524527, CurrSamplesPerSec=1.5270191626286782, MemAllocated=0.21GB, MaxMemAllocated=2.42GB\n",
            "215    2.305\n",
            "216    2.305\n",
            "217    2.305\n",
            "218    2.305\n",
            "219    2.305\n",
            "220    2.305\n",
            "221    2.305\n",
            "222    2.305\n",
            "[2022-10-23 14:01:55,499] [INFO] [timer.py:207:stop] 0/224, RunningAvgSamplesPerSec=1.3879757739262202, CurrSamplesPerSec=0.7380795765975695, MemAllocated=0.11GB, MaxMemAllocated=2.42GB\n",
            "223    2.305\n",
            "224    2.281\n",
            "225    2.281\n",
            "226    2.281\n",
            "227    2.281\n",
            "228    2.281\n",
            "229    2.281\n",
            "230    2.281\n",
            "[2022-10-23 14:02:06,065] [INFO] [timer.py:207:stop] 0/232, RunningAvgSamplesPerSec=1.3920518713239896, CurrSamplesPerSec=1.5152339699937503, MemAllocated=0.21GB, MaxMemAllocated=2.42GB\n",
            "231    2.281\n",
            "232    2.281\n",
            "233    2.281\n",
            "234    2.281\n",
            "235    2.281\n",
            "236    2.281\n",
            "237    2.281\n",
            "238    2.281\n",
            "[2022-10-23 14:02:17,982] [INFO] [timer.py:207:stop] 0/240, RunningAvgSamplesPerSec=1.3903769384671483, CurrSamplesPerSec=0.7603719388704545, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "239    2.281\n",
            "240    2.268\n",
            "241    2.268\n",
            "242    2.268\n",
            "243    2.268\n",
            "244    2.268\n",
            "245    2.268\n",
            "246    2.268\n",
            "[2022-10-23 14:02:28,556] [INFO] [timer.py:207:stop] 0/248, RunningAvgSamplesPerSec=1.3940880805478613, CurrSamplesPerSec=1.5053699840788335, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "247    2.268\n",
            "248    2.268\n",
            "249    2.268\n",
            "250    2.268\n",
            "251    2.268\n",
            "252    2.268\n",
            "253    2.268\n",
            "254    2.268\n",
            "[2022-10-23 14:02:40,364] [INFO] [logging.py:68:log_dist] [Rank 0] step=16, skipped=0, lr=[6.020599913279623e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-23 14:02:40,366] [INFO] [timer.py:207:stop] 0/256, RunningAvgSamplesPerSec=1.392844600719215, CurrSamplesPerSec=0.76280744809116, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "255    2.268\n",
            "256    2.252\n",
            "257    2.252\n",
            "258    2.252\n",
            "259    2.252\n",
            "260    2.252\n",
            "261    2.252\n",
            "262    2.252\n",
            "[2022-10-23 14:02:50,912] [INFO] [timer.py:207:stop] 0/264, RunningAvgSamplesPerSec=1.3963799512780897, CurrSamplesPerSec=1.5244348024248169, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "263    2.252\n",
            "264    2.252\n",
            "265    2.252\n",
            "266    2.252\n",
            "267    2.252\n",
            "268    2.252\n",
            "269    2.252\n",
            "270    2.252\n",
            "[2022-10-23 14:03:02,800] [INFO] [timer.py:207:stop] 0/272, RunningAvgSamplesPerSec=1.3948676598551388, CurrSamplesPerSec=0.7579891899491846, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "271    2.252\n",
            "272    2.240\n",
            "273    2.240\n",
            "274    2.240\n",
            "275    2.240\n",
            "276    2.240\n",
            "277    2.240\n",
            "278    2.240\n",
            "[2022-10-23 14:03:13,355] [INFO] [timer.py:207:stop] 0/280, RunningAvgSamplesPerSec=1.3981199279930951, CurrSamplesPerSec=1.5215800939219204, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "279    2.240\n",
            "280    2.240\n",
            "281    2.240\n",
            "282    2.240\n",
            "283    2.240\n",
            "284    2.240\n",
            "285    2.240\n",
            "286    2.240\n",
            "[2022-10-23 14:03:25,312] [INFO] [timer.py:207:stop] 0/288, RunningAvgSamplesPerSec=1.3963979475502857, CurrSamplesPerSec=0.7405273570951115, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "287    2.240\n",
            "288    2.234\n",
            "289    2.234\n",
            "290    2.234\n",
            "291    2.234\n",
            "292    2.234\n",
            "293    2.234\n",
            "294    2.234\n",
            "[2022-10-23 14:03:35,886] [INFO] [timer.py:207:stop] 0/296, RunningAvgSamplesPerSec=1.399363200373082, CurrSamplesPerSec=1.505163621748289, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "295    2.234\n",
            "296    2.234\n",
            "297    2.234\n",
            "298    2.234\n",
            "299    2.234\n",
            "300    2.234\n",
            "301    2.234\n",
            "302    2.234\n",
            "[2022-10-23 14:03:47,831] [INFO] [timer.py:207:stop] 0/304, RunningAvgSamplesPerSec=1.3977350727478854, CurrSamplesPerSec=0.7458126870897961, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "303    2.234\n",
            "304    2.207\n",
            "305    2.207\n",
            "306    2.207\n",
            "307    2.207\n",
            "308    2.207\n",
            "309    2.207\n",
            "310    2.207\n",
            "[2022-10-23 14:03:58,351] [INFO] [timer.py:207:stop] 0/312, RunningAvgSamplesPerSec=1.4007003644883596, CurrSamplesPerSec=1.528256021535407, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "311    2.207\n",
            "312    2.207\n",
            "313    2.207\n",
            "314    2.207\n",
            "315    2.207\n",
            "316    2.207\n",
            "317    2.207\n",
            "318    2.207\n",
            "[2022-10-23 14:04:10,181] [INFO] [timer.py:207:stop] 0/320, RunningAvgSamplesPerSec=1.399475752748981, CurrSamplesPerSec=0.7659438633424361, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "319    2.207\n",
            "320    2.193\n",
            "321    2.193\n",
            "322    2.193\n",
            "323    2.193\n",
            "324    2.193\n",
            "325    2.193\n",
            "326    2.193\n",
            "[2022-10-23 14:04:20,715] [INFO] [timer.py:207:stop] 0/328, RunningAvgSamplesPerSec=1.4022060305455288, CurrSamplesPerSec=1.5156344940491087, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "327    2.193\n",
            "328    2.193\n",
            "329    2.193\n",
            "330    2.193\n",
            "331    2.193\n",
            "332    2.193\n",
            "333    2.193\n",
            "334    2.193\n",
            "[2022-10-23 14:04:32,555] [INFO] [timer.py:207:stop] 0/336, RunningAvgSamplesPerSec=1.4009695759570502, CurrSamplesPerSec=0.7662360996184534, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "335    2.193\n",
            "336    2.166\n",
            "337    2.166\n",
            "338    2.166\n",
            "339    2.166\n",
            "340    2.166\n",
            "341    2.166\n",
            "342    2.166\n",
            "[2022-10-23 14:04:43,090] [INFO] [timer.py:207:stop] 0/344, RunningAvgSamplesPerSec=1.403542119901953, CurrSamplesPerSec=1.5295339289233996, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "343    2.166\n",
            "344    2.166\n",
            "345    2.166\n",
            "346    2.166\n",
            "347    2.166\n",
            "348    2.166\n",
            "349    2.166\n",
            "350    2.166\n",
            "[2022-10-23 14:04:54,952] [INFO] [timer.py:207:stop] 0/352, RunningAvgSamplesPerSec=1.4022627175546913, CurrSamplesPerSec=0.7602204080641323, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "351    2.166\n",
            "352    2.162\n",
            "353    2.162\n",
            "354    2.162\n",
            "355    2.162\n",
            "356    2.162\n",
            "357    2.162\n",
            "358    2.162\n",
            "[2022-10-23 14:05:05,542] [INFO] [timer.py:207:stop] 0/360, RunningAvgSamplesPerSec=1.4045434247599153, CurrSamplesPerSec=1.5289434742011312, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "359    2.162\n",
            "360    2.162\n",
            "361    2.162\n",
            "362    2.162\n",
            "363    2.162\n",
            "364    2.162\n",
            "365    2.162\n",
            "366    2.162\n",
            "[2022-10-23 14:05:17,383] [INFO] [timer.py:207:stop] 0/368, RunningAvgSamplesPerSec=1.403361109683668, CurrSamplesPerSec=0.7541860676290802, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "367    2.162\n",
            "368    2.115\n",
            "369    2.115\n",
            "370    2.115\n",
            "371    2.115\n",
            "372    2.115\n",
            "373    2.115\n",
            "374    2.115\n",
            "[2022-10-23 14:05:27,917] [INFO] [timer.py:207:stop] 0/376, RunningAvgSamplesPerSec=1.4056700320743771, CurrSamplesPerSec=1.5219486352350566, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "375    2.115\n",
            "376    2.115\n",
            "377    2.115\n",
            "378    2.115\n",
            "379    2.115\n",
            "380    2.115\n",
            "381    2.115\n",
            "382    2.115\n",
            "[2022-10-23 14:05:39,864] [INFO] [logging.py:68:log_dist] [Rank 0] step=24, skipped=0, lr=[6.90105620855803e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-23 14:05:39,866] [INFO] [timer.py:207:stop] 0/384, RunningAvgSamplesPerSec=1.4042364540417454, CurrSamplesPerSec=0.7380806805898762, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "383    2.115\n",
            "384    2.074\n",
            "385    2.074\n",
            "386    2.074\n",
            "387    2.074\n",
            "388    2.074\n",
            "389    2.074\n",
            "390    2.074\n",
            "[2022-10-23 14:05:50,454] [INFO] [timer.py:207:stop] 0/392, RunningAvgSamplesPerSec=1.406304395215388, CurrSamplesPerSec=1.5179459488998857, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "391    2.074\n",
            "392    2.074\n",
            "393    2.074\n",
            "394    2.074\n",
            "395    2.074\n",
            "396    2.074\n",
            "397    2.074\n",
            "398    2.074\n",
            "[2022-10-23 14:06:02,343] [INFO] [timer.py:207:stop] 0/400, RunningAvgSamplesPerSec=1.4050584703467452, CurrSamplesPerSec=0.7496412697473666, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "399    2.074\n",
            "400    2.086\n",
            "401    2.086\n",
            "402    2.086\n",
            "403    2.086\n",
            "404    2.086\n",
            "405    2.086\n",
            "406    2.086\n",
            "[2022-10-23 14:06:12,897] [INFO] [timer.py:207:stop] 0/408, RunningAvgSamplesPerSec=1.4071089220359259, CurrSamplesPerSec=1.5210906379558953, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "407    2.086\n",
            "408    2.086\n",
            "409    2.086\n",
            "410    2.086\n",
            "411    2.086\n",
            "412    2.086\n",
            "413    2.086\n",
            "414    2.086\n",
            "[2022-10-23 14:06:24,787] [INFO] [timer.py:207:stop] 0/416, RunningAvgSamplesPerSec=1.405891328510433, CurrSamplesPerSec=0.7587215907035303, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "415    2.086\n",
            "416    2.012\n",
            "417    2.012\n",
            "418    2.012\n",
            "419    2.012\n",
            "420    2.012\n",
            "421    2.012\n",
            "422    2.012\n",
            "[2022-10-23 14:06:35,378] [INFO] [timer.py:207:stop] 0/424, RunningAvgSamplesPerSec=1.4077644973861454, CurrSamplesPerSec=1.5190957942495127, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "423    2.012\n",
            "424    2.012\n",
            "425    2.012\n",
            "426    2.012\n",
            "427    2.012\n",
            "428    2.012\n",
            "429    2.012\n",
            "430    2.012\n",
            "[2022-10-23 14:06:47,209] [INFO] [timer.py:207:stop] 0/432, RunningAvgSamplesPerSec=1.4067155501093642, CurrSamplesPerSec=0.7615479910225919, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "431    2.012\n",
            "432    2.109\n",
            "433    2.109\n",
            "434    2.109\n",
            "435    2.109\n",
            "436    2.109\n",
            "437    2.109\n",
            "438    2.109\n",
            "[2022-10-23 14:06:57,725] [INFO] [timer.py:207:stop] 0/440, RunningAvgSamplesPerSec=1.4086751675400708, CurrSamplesPerSec=1.52665816400813, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "439    2.109\n",
            "440    2.109\n",
            "441    2.109\n",
            "442    2.109\n",
            "443    2.109\n",
            "444    2.109\n",
            "445    2.109\n",
            "446    2.109\n",
            "[2022-10-23 14:07:09,606] [INFO] [timer.py:207:stop] 0/448, RunningAvgSamplesPerSec=1.407532868670789, CurrSamplesPerSec=0.7550557299292641, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "447    2.109\n",
            "448    2.084\n",
            "449    2.084\n",
            "450    2.084\n",
            "451    2.084\n",
            "452    2.084\n",
            "453    2.084\n",
            "454    2.084\n",
            "[2022-10-23 14:07:20,124] [INFO] [timer.py:207:stop] 0/456, RunningAvgSamplesPerSec=1.4094077789709123, CurrSamplesPerSec=1.5119343679155743, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "455    2.084\n",
            "456    2.084\n",
            "457    2.084\n",
            "458    2.084\n",
            "459    2.084\n",
            "460    2.084\n",
            "461    2.084\n",
            "462    2.084\n",
            "[2022-10-23 14:07:32,055] [INFO] [timer.py:207:stop] 0/464, RunningAvgSamplesPerSec=1.4081814937229522, CurrSamplesPerSec=0.7398567244468058, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "463    2.084\n",
            "464    1.922\n",
            "465    1.922\n",
            "466    1.922\n",
            "467    1.922\n",
            "468    1.922\n",
            "469    1.922\n",
            "470    1.922\n",
            "[2022-10-23 14:07:42,664] [INFO] [timer.py:207:stop] 0/472, RunningAvgSamplesPerSec=1.4097891084491205, CurrSamplesPerSec=1.527551105882867, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "471    1.922\n",
            "472    1.922\n",
            "473    1.922\n",
            "474    1.922\n",
            "475    1.922\n",
            "476    1.922\n",
            "477    1.922\n",
            "478    1.922\n",
            "[2022-10-23 14:07:54,529] [INFO] [timer.py:207:stop] 0/480, RunningAvgSamplesPerSec=1.4087331915606403, CurrSamplesPerSec=0.7493264768558153, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "479    1.922\n",
            "480    1.910\n",
            "481    1.910\n",
            "482    1.910\n",
            "483    1.910\n",
            "484    1.910\n",
            "485    1.910\n",
            "486    1.910\n",
            "[2022-10-23 14:08:05,077] [INFO] [timer.py:207:stop] 0/488, RunningAvgSamplesPerSec=1.4104032550473777, CurrSamplesPerSec=1.5245134831881322, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "487    1.910\n",
            "488    1.910\n",
            "489    1.910\n",
            "490    1.910\n",
            "491    1.910\n",
            "492    1.910\n",
            "493    1.910\n",
            "494    1.910\n",
            "[2022-10-23 14:08:16,880] [INFO] [timer.py:207:stop] 0/496, RunningAvgSamplesPerSec=1.4094966299637588, CurrSamplesPerSec=0.7656700199572741, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "495    1.910\n",
            "496    1.899\n",
            "497    1.899\n",
            "498    1.899\n",
            "499    1.899\n",
            "500    1.899\n",
            "501    1.899\n",
            "502    1.899\n",
            "[2022-10-23 14:08:27,449] [INFO] [timer.py:207:stop] 0/504, RunningAvgSamplesPerSec=1.4110620620520276, CurrSamplesPerSec=1.508166033665191, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "503    1.899\n",
            "504    1.899\n",
            "505    1.899\n",
            "506    1.899\n",
            "507    1.899\n",
            "508    1.899\n",
            "509    1.899\n",
            "510    1.899\n",
            "[2022-10-23 14:08:39,283] [INFO] [logging.py:68:log_dist] [Rank 0] step=32, skipped=0, lr=[7.5257498915995295e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-23 14:08:39,285] [INFO] [timer.py:207:stop] 0/512, RunningAvgSamplesPerSec=1.4101075186898266, CurrSamplesPerSec=0.7600676980234689, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "511    1.899\n",
            "512    1.750\n",
            "513    1.750\n",
            "514    1.750\n",
            "515    1.750\n",
            "516    1.750\n",
            "517    1.750\n",
            "518    1.750\n",
            "[2022-10-23 14:08:49,831] [INFO] [timer.py:207:stop] 0/520, RunningAvgSamplesPerSec=1.4116660872703968, CurrSamplesPerSec=1.506509235769566, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "519    1.750\n",
            "520    1.750\n",
            "521    1.750\n",
            "522    1.750\n",
            "523    1.750\n",
            "524    1.750\n",
            "525    1.750\n",
            "526    1.750\n",
            "[2022-10-23 14:09:01,722] [INFO] [timer.py:207:stop] 0/528, RunningAvgSamplesPerSec=1.410629539223766, CurrSamplesPerSec=0.7500607346003029, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "527    1.750\n",
            "528    1.792\n",
            "529    1.792\n",
            "530    1.792\n",
            "531    1.792\n",
            "532    1.792\n",
            "533    1.792\n",
            "534    1.792\n",
            "[2022-10-23 14:09:12,226] [INFO] [timer.py:207:stop] 0/536, RunningAvgSamplesPerSec=1.4122086222184818, CurrSamplesPerSec=1.5301597284874735, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "535    1.792\n",
            "536    1.792\n",
            "537    1.792\n",
            "538    1.792\n",
            "539    1.792\n",
            "540    1.792\n",
            "541    1.792\n",
            "542    1.792\n",
            "[2022-10-23 14:09:24,080] [INFO] [timer.py:207:stop] 0/544, RunningAvgSamplesPerSec=1.4112581151906531, CurrSamplesPerSec=0.7454726792246189, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "543    1.792\n",
            "544    1.755\n",
            "545    1.755\n",
            "546    1.755\n",
            "547    1.755\n",
            "548    1.755\n",
            "549    1.755\n",
            "550    1.755\n",
            "[2022-10-23 14:09:34,615] [INFO] [timer.py:207:stop] 0/552, RunningAvgSamplesPerSec=1.4127281685421345, CurrSamplesPerSec=1.5224228943611642, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "551    1.755\n",
            "552    1.755\n",
            "553    1.755\n",
            "554    1.755\n",
            "555    1.755\n",
            "556    1.755\n",
            "557    1.755\n",
            "558    1.755\n",
            "[2022-10-23 14:09:46,493] [INFO] [timer.py:207:stop] 0/560, RunningAvgSamplesPerSec=1.4117582095581687, CurrSamplesPerSec=0.7440129172851173, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "559    1.755\n",
            "560    1.581\n",
            "561    1.581\n",
            "562    1.581\n",
            "563    1.581\n",
            "564    1.581\n",
            "565    1.581\n",
            "566    1.581\n",
            "[2022-10-23 14:09:57,030] [INFO] [timer.py:207:stop] 0/568, RunningAvgSamplesPerSec=1.4131764825122903, CurrSamplesPerSec=1.5227912912381403, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "567    1.581\n",
            "568    1.581\n",
            "569    1.581\n",
            "570    1.581\n",
            "571    1.581\n",
            "572    1.581\n",
            "573    1.581\n",
            "574    1.581\n",
            "[2022-10-23 14:10:08,894] [INFO] [timer.py:207:stop] 0/576, RunningAvgSamplesPerSec=1.4122474394995068, CurrSamplesPerSec=0.7586066631910265, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "575    1.581\n",
            "576    1.587\n",
            "577    1.587\n",
            "578    1.587\n",
            "579    1.587\n",
            "580    1.587\n",
            "581    1.587\n",
            "582    1.587\n",
            "[2022-10-23 14:10:19,487] [INFO] [timer.py:207:stop] 0/584, RunningAvgSamplesPerSec=1.4135269133073267, CurrSamplesPerSec=1.5199763286462338, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "583    1.587\n",
            "584    1.587\n",
            "585    1.587\n",
            "586    1.587\n",
            "587    1.587\n",
            "588    1.587\n",
            "589    1.587\n",
            "590    1.587\n",
            "[2022-10-23 14:10:31,300] [INFO] [timer.py:207:stop] 0/592, RunningAvgSamplesPerSec=1.41270373713175, CurrSamplesPerSec=0.7662529675535301, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "591    1.587\n",
            "592    1.526\n",
            "593    1.526\n",
            "594    1.526\n",
            "595    1.526\n",
            "596    1.526\n",
            "597    1.526\n",
            "598    1.526\n",
            "[2022-10-23 14:10:41,816] [INFO] [timer.py:207:stop] 0/600, RunningAvgSamplesPerSec=1.4140712442760492, CurrSamplesPerSec=1.5251415580769918, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "599    1.526\n",
            "600    1.526\n",
            "601    1.526\n",
            "602    1.526\n",
            "603    1.526\n",
            "604    1.526\n",
            "605    1.526\n",
            "606    1.526\n",
            "[2022-10-23 14:10:53,675] [INFO] [timer.py:207:stop] 0/608, RunningAvgSamplesPerSec=1.4131866373986555, CurrSamplesPerSec=0.7588506941017567, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "607    1.526\n",
            "608    1.467\n",
            "609    1.467\n",
            "610    1.467\n",
            "611    1.467\n",
            "612    1.467\n",
            "613    1.467\n",
            "614    1.467\n",
            "[2022-10-23 14:11:04,254] [INFO] [timer.py:207:stop] 0/616, RunningAvgSamplesPerSec=1.4144098031713621, CurrSamplesPerSec=1.503809625906962, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "615    1.467\n",
            "616    1.467\n",
            "617    1.467\n",
            "618    1.467\n",
            "619    1.467\n",
            "620    1.467\n",
            "621    1.467\n",
            "622    1.467\n",
            "[2022-10-23 14:11:16,106] [INFO] [timer.py:207:stop] 0/624, RunningAvgSamplesPerSec=1.4135569556282421, CurrSamplesPerSec=0.7596022319893236, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "623    1.467\n",
            "624    1.344\n",
            "625    1.344\n",
            "626    1.344\n",
            "627    1.344\n",
            "628    1.344\n",
            "629    1.344\n",
            "630    1.344\n",
            "[2022-10-23 14:11:26,657] [INFO] [timer.py:207:stop] 0/632, RunningAvgSamplesPerSec=1.4147872719131247, CurrSamplesPerSec=1.5216993326993984, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "631    1.344\n",
            "632    1.344\n",
            "633    1.344\n",
            "634    1.344\n",
            "635    1.344\n",
            "636    1.344\n",
            "637    1.344\n",
            "638    1.344\n",
            "[2022-10-23 14:11:38,586] [INFO] [logging.py:68:log_dist] [Rank 0] step=40, skipped=0, lr=[8.010299956639811e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-23 14:11:38,587] [INFO] [timer.py:207:stop] 0/640, RunningAvgSamplesPerSec=1.4138261325059491, CurrSamplesPerSec=0.7425154810072588, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "639    1.344\n",
            "640    1.188\n",
            "641    1.188\n",
            "642    1.188\n",
            "643    1.188\n",
            "644    1.188\n",
            "645    1.188\n",
            "646    1.188\n",
            "[2022-10-23 14:11:49,205] [INFO] [timer.py:207:stop] 0/648, RunningAvgSamplesPerSec=1.4149258630392676, CurrSamplesPerSec=1.5318717813256304, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "647    1.188\n",
            "648    1.188\n",
            "649    1.188\n",
            "650    1.188\n",
            "651    1.188\n",
            "652    1.188\n",
            "653    1.188\n",
            "654    1.188\n",
            "[2022-10-23 14:12:01,116] [INFO] [timer.py:207:stop] 0/656, RunningAvgSamplesPerSec=1.4140142030610288, CurrSamplesPerSec=0.7437842040126325, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "655    1.188\n",
            "656    1.163\n",
            "657    1.163\n",
            "658    1.163\n",
            "659    1.163\n",
            "660    1.163\n",
            "661    1.163\n",
            "662    1.163\n",
            "[2022-10-23 14:12:11,645] [INFO] [timer.py:207:stop] 0/664, RunningAvgSamplesPerSec=1.415214406653838, CurrSamplesPerSec=1.5234439542019251, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "663    1.163\n",
            "664    1.163\n",
            "665    1.163\n",
            "666    1.163\n",
            "667    1.163\n",
            "668    1.163\n",
            "669    1.163\n",
            "670    1.163\n",
            "[2022-10-23 14:12:23,442] [INFO] [timer.py:207:stop] 0/672, RunningAvgSamplesPerSec=1.4144951740616962, CurrSamplesPerSec=0.7662145433384493, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "671    1.163\n",
            "672    0.987\n",
            "673    0.987\n",
            "674    0.987\n",
            "675    0.987\n",
            "676    0.987\n",
            "677    0.987\n",
            "678    0.987\n",
            "[2022-10-23 14:12:33,945] [INFO] [timer.py:207:stop] 0/680, RunningAvgSamplesPerSec=1.415700012244394, CurrSamplesPerSec=1.5298971260700343, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "679    0.987\n",
            "680    0.987\n",
            "681    0.987\n",
            "682    0.987\n",
            "683    0.987\n",
            "684    0.987\n",
            "685    0.987\n",
            "686    0.987\n",
            "[2022-10-23 14:12:45,768] [INFO] [timer.py:207:stop] 0/688, RunningAvgSamplesPerSec=1.4149508565549016, CurrSamplesPerSec=0.7635138203915682, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "687    0.987\n",
            "688    0.956\n",
            "689    0.956\n",
            "690    0.956\n",
            "691    0.956\n",
            "692    0.956\n",
            "693    0.956\n",
            "694    0.956\n",
            "[2022-10-23 14:12:56,329] [INFO] [timer.py:207:stop] 0/696, RunningAvgSamplesPerSec=1.416039833404133, CurrSamplesPerSec=1.5084922967810015, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "695    0.956\n",
            "696    0.956\n",
            "697    0.956\n",
            "698    0.956\n",
            "699    0.956\n",
            "700    0.956\n",
            "701    0.956\n",
            "702    0.956\n",
            "[2022-10-23 14:13:08,205] [INFO] [timer.py:207:stop] 0/704, RunningAvgSamplesPerSec=1.4152288835207094, CurrSamplesPerSec=0.7626571639028561, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "703    0.956\n",
            "704    0.823\n",
            "705    0.823\n",
            "706    0.823\n",
            "707    0.823\n",
            "708    0.823\n",
            "709    0.823\n",
            "710    0.823\n",
            "[2022-10-23 14:13:18,721] [INFO] [timer.py:207:stop] 0/712, RunningAvgSamplesPerSec=1.4163553634825754, CurrSamplesPerSec=1.5170046646140003, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "711    0.823\n",
            "712    0.823\n",
            "713    0.823\n",
            "714    0.823\n",
            "715    0.823\n",
            "716    0.823\n",
            "717    0.823\n",
            "718    0.823\n",
            "[2022-10-23 14:13:30,649] [INFO] [timer.py:207:stop] 0/720, RunningAvgSamplesPerSec=1.4154839453820385, CurrSamplesPerSec=0.7422691650926593, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "719    0.823\n",
            "720    0.697\n",
            "721    0.697\n",
            "722    0.697\n",
            "723    0.697\n",
            "724    0.697\n",
            "725    0.697\n",
            "726    0.697\n",
            "[2022-10-23 14:13:41,183] [INFO] [timer.py:207:stop] 0/728, RunningAvgSamplesPerSec=1.4165585688942859, CurrSamplesPerSec=1.5238701461722985, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "727    0.697\n",
            "728    0.697\n",
            "729    0.697\n",
            "730    0.697\n",
            "731    0.697\n",
            "732    0.697\n",
            "733    0.697\n",
            "734    0.697\n",
            "[2022-10-23 14:13:53,107] [INFO] [timer.py:207:stop] 0/736, RunningAvgSamplesPerSec=1.415709159426771, CurrSamplesPerSec=0.7467113213010671, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "735    0.697\n",
            "736    0.645\n",
            "737    0.645\n",
            "738    0.645\n",
            "739    0.645\n",
            "740    0.645\n",
            "741    0.645\n",
            "742    0.645\n",
            "[2022-10-23 14:14:03,650] [INFO] [timer.py:207:stop] 0/744, RunningAvgSamplesPerSec=1.416745258601418, CurrSamplesPerSec=1.5345917610395978, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "743    0.645\n",
            "744    0.645\n",
            "745    0.645\n",
            "746    0.645\n",
            "747    0.645\n",
            "748    0.645\n",
            "749    0.645\n",
            "750    0.645\n",
            "[2022-10-23 14:14:15,442] [INFO] [timer.py:207:stop] 0/752, RunningAvgSamplesPerSec=1.4160892823376157, CurrSamplesPerSec=0.7615357541358299, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "751    0.645\n",
            "752    0.467\n",
            "753    0.467\n",
            "754    0.467\n",
            "755    0.467\n",
            "756    0.467\n",
            "757    0.467\n",
            "758    0.467\n",
            "[2022-10-23 14:14:25,967] [INFO] [timer.py:207:stop] 0/760, RunningAvgSamplesPerSec=1.4171240434011896, CurrSamplesPerSec=1.517400635822205, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "759    0.467\n",
            "760    0.467\n",
            "761    0.467\n",
            "762    0.467\n",
            "763    0.467\n",
            "764    0.467\n",
            "765    0.467\n",
            "766    0.467\n",
            "[2022-10-23 14:14:37,762] [INFO] [logging.py:68:log_dist] [Rank 0] step=48, skipped=0, lr=[8.406206186877936e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-23 14:14:37,764] [INFO] [timer.py:207:stop] 0/768, RunningAvgSamplesPerSec=1.4164704384974225, CurrSamplesPerSec=0.7639833983176098, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "767    0.467\n",
            "768    0.404\n",
            "769    0.404\n",
            "770    0.404\n",
            "771    0.404\n",
            "772    0.404\n",
            "773    0.404\n",
            "774    0.404\n",
            "[2022-10-23 14:14:48,318] [INFO] [timer.py:207:stop] 0/776, RunningAvgSamplesPerSec=1.4174480961324067, CurrSamplesPerSec=1.5061843706812332, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "775    0.404\n",
            "776    0.404\n",
            "777    0.404\n",
            "778    0.404\n",
            "779    0.404\n",
            "780    0.404\n",
            "781    0.404\n",
            "782    0.404\n",
            "[2022-10-23 14:15:00,171] [INFO] [timer.py:207:stop] 0/784, RunningAvgSamplesPerSec=1.4167317899661993, CurrSamplesPerSec=0.7627235951100486, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "783    0.404\n",
            "784    0.308\n",
            "785    0.308\n",
            "786    0.308\n",
            "787    0.308\n",
            "788    0.308\n",
            "789    0.308\n",
            "790    0.308\n",
            "[2022-10-23 14:15:10,709] [INFO] [timer.py:207:stop] 0/792, RunningAvgSamplesPerSec=1.417702166447759, CurrSamplesPerSec=1.5211212542066708, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "791    0.308\n",
            "792    0.308\n",
            "793    0.308\n",
            "794    0.308\n",
            "795    0.308\n",
            "796    0.308\n",
            "797    0.308\n",
            "798    0.308\n",
            "[2022-10-23 14:15:22,559] [INFO] [timer.py:207:stop] 0/800, RunningAvgSamplesPerSec=1.4170008979953834, CurrSamplesPerSec=0.7515805072711129, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "799    0.308\n",
            "800    0.219\n",
            "801    0.219\n",
            "802    0.219\n",
            "803    0.219\n",
            "804    0.219\n",
            "805    0.219\n",
            "806    0.219\n",
            "[2022-10-23 14:15:33,077] [INFO] [timer.py:207:stop] 0/808, RunningAvgSamplesPerSec=1.4179763662307907, CurrSamplesPerSec=1.5271556584589516, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "807    0.219\n",
            "808    0.219\n",
            "809    0.219\n",
            "810    0.219\n",
            "811    0.219\n",
            "812    0.219\n",
            "813    0.219\n",
            "814    0.219\n",
            "[2022-10-23 14:15:44,964] [INFO] [timer.py:207:stop] 0/816, RunningAvgSamplesPerSec=1.4172404120806965, CurrSamplesPerSec=0.7450842702242898, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "815    0.219\n",
            "816    0.155\n",
            "817    0.155\n",
            "818    0.155\n",
            "819    0.155\n",
            "820    0.155\n",
            "821    0.155\n",
            "822    0.155\n",
            "[2022-10-23 14:15:55,496] [INFO] [timer.py:207:stop] 0/824, RunningAvgSamplesPerSec=1.4181773573783374, CurrSamplesPerSec=1.5155857518525646, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "823    0.155\n",
            "824    0.155\n",
            "825    0.155\n",
            "826    0.155\n",
            "827    0.155\n",
            "828    0.155\n",
            "829    0.155\n",
            "830    0.155\n",
            "[2022-10-23 14:16:07,344] [INFO] [timer.py:207:stop] 0/832, RunningAvgSamplesPerSec=1.4175079539739752, CurrSamplesPerSec=0.7610792606416809, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "831    0.155\n",
            "832    0.115\n",
            "833    0.115\n",
            "834    0.115\n",
            "835    0.115\n",
            "836    0.115\n",
            "837    0.115\n",
            "838    0.115\n",
            "[2022-10-23 14:16:17,885] [INFO] [timer.py:207:stop] 0/840, RunningAvgSamplesPerSec=1.4184158387103878, CurrSamplesPerSec=1.5292043554737738, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "839    0.115\n",
            "840    0.115\n",
            "841    0.115\n",
            "842    0.115\n",
            "843    0.115\n",
            "844    0.115\n",
            "845    0.115\n",
            "846    0.115\n",
            "[2022-10-23 14:16:29,632] [INFO] [timer.py:207:stop] 0/848, RunningAvgSamplesPerSec=1.417870823260645, CurrSamplesPerSec=0.76658193571121, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "847    0.115\n",
            "848    0.068\n",
            "849    0.068\n",
            "850    0.068\n",
            "851    0.068\n",
            "852    0.068\n",
            "853    0.068\n",
            "854    0.068\n",
            "[2022-10-23 14:16:40,152] [INFO] [timer.py:207:stop] 0/856, RunningAvgSamplesPerSec=1.4187828607647148, CurrSamplesPerSec=1.5337057132978993, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "855    0.068\n",
            "856    0.068\n",
            "857    0.068\n",
            "858    0.068\n",
            "859    0.068\n",
            "860    0.068\n",
            "861    0.068\n",
            "862    0.068\n",
            "[2022-10-23 14:16:51,994] [INFO] [timer.py:207:stop] 0/864, RunningAvgSamplesPerSec=1.4181362333908334, CurrSamplesPerSec=0.7617862392763519, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "863    0.068\n",
            "864    0.039\n",
            "865    0.039\n",
            "866    0.039\n",
            "867    0.039\n",
            "868    0.039\n",
            "869    0.039\n",
            "870    0.039\n",
            "[2022-10-23 14:17:02,547] [INFO] [timer.py:207:stop] 0/872, RunningAvgSamplesPerSec=1.4189888000835893, CurrSamplesPerSec=1.5143682150145912, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "871    0.039\n",
            "872    0.039\n",
            "873    0.039\n",
            "874    0.039\n",
            "875    0.039\n",
            "876    0.039\n",
            "877    0.039\n",
            "878    0.039\n",
            "[2022-10-23 14:17:14,464] [INFO] [timer.py:207:stop] 0/880, RunningAvgSamplesPerSec=1.418266201807194, CurrSamplesPerSec=0.7526876259603855, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "879    0.039\n",
            "880    0.024\n",
            "881    0.024\n",
            "882    0.024\n",
            "883    0.024\n",
            "884    0.024\n",
            "885    0.024\n",
            "886    0.024\n",
            "[2022-10-23 14:17:24,973] [INFO] [timer.py:207:stop] 0/888, RunningAvgSamplesPerSec=1.4191521998840775, CurrSamplesPerSec=1.5424380596402931, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "887    0.024\n",
            "888    0.024\n",
            "889    0.024\n",
            "890    0.024\n",
            "891    0.024\n",
            "892    0.024\n",
            "893    0.024\n",
            "894    0.024\n",
            "[2022-10-23 14:17:36,858] [INFO] [logging.py:68:log_dist] [Rank 0] step=56, skipped=0, lr=[8.740940135031001e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-23 14:17:36,860] [INFO] [timer.py:207:stop] 0/896, RunningAvgSamplesPerSec=1.418473461886218, CurrSamplesPerSec=0.7503460080558851, MemAllocated=0.11GB, MaxMemAllocated=2.84GB\n",
            "895    0.024\n",
            "896    0.014\n",
            "897    0.014\n",
            "898    0.014\n",
            "899    0.014\n",
            "900    0.014\n",
            "901    0.014\n",
            "902    0.014\n",
            "[2022-10-23 14:17:47,390] [INFO] [timer.py:207:stop] 0/904, RunningAvgSamplesPerSec=1.4193261181087657, CurrSamplesPerSec=1.5143080729263039, MemAllocated=0.21GB, MaxMemAllocated=2.84GB\n",
            "903    0.014\n",
            "904    0.014\n",
            "905    0.014\n",
            "906    0.014\n",
            "907    0.014\n",
            "908    0.014\n",
            "909    0.014\n",
            "910    0.014\n",
            "[2022-10-23 14:17:59,263] [INFO] [timer.py:207:stop] 0/912, RunningAvgSamplesPerSec=1.4186716822007872, CurrSamplesPerSec=0.752507413741971, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "911    0.014\n",
            "912    0.008\n",
            "913    0.008\n",
            "914    0.008\n",
            "915    0.008\n",
            "916    0.008\n",
            "917    0.008\n",
            "918    0.008\n",
            "[2022-10-23 14:18:09,815] [INFO] [timer.py:207:stop] 0/920, RunningAvgSamplesPerSec=1.4194773512627243, CurrSamplesPerSec=1.517035665296165, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "919    0.008\n",
            "920    0.008\n",
            "921    0.008\n",
            "922    0.008\n",
            "923    0.008\n",
            "924    0.008\n",
            "925    0.008\n",
            "926    0.008\n",
            "[2022-10-23 14:18:21,688] [INFO] [timer.py:207:stop] 0/928, RunningAvgSamplesPerSec=1.4188308208902853, CurrSamplesPerSec=0.7568212275674436, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "927    0.008\n",
            "928    0.006\n",
            "929    0.006\n",
            "930    0.006\n",
            "931    0.006\n",
            "932    0.006\n",
            "933    0.006\n",
            "934    0.006\n",
            "[2022-10-23 14:18:32,184] [INFO] [timer.py:207:stop] 0/936, RunningAvgSamplesPerSec=1.4196841505387672, CurrSamplesPerSec=1.5128682772820914, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "935    0.006\n",
            "936    0.006\n",
            "937    0.006\n",
            "938    0.006\n",
            "939    0.006\n",
            "940    0.006\n",
            "941    0.006\n",
            "942    0.006\n",
            "[2022-10-23 14:18:43,969] [INFO] [timer.py:207:stop] 0/944, RunningAvgSamplesPerSec=1.4191409972563043, CurrSamplesPerSec=0.7673752664189984, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "943    0.006\n",
            "944    0.003\n",
            "945    0.003\n",
            "946    0.003\n",
            "947    0.003\n",
            "948    0.003\n",
            "949    0.003\n",
            "950    0.003\n",
            "[2022-10-23 14:18:54,494] [INFO] [timer.py:207:stop] 0/952, RunningAvgSamplesPerSec=1.419944857502001, CurrSamplesPerSec=1.5445467623302995, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "951    0.003\n",
            "952    0.003\n",
            "953    0.003\n",
            "954    0.003\n",
            "955    0.003\n",
            "956    0.003\n",
            "957    0.003\n",
            "958    0.003\n",
            "[2022-10-23 14:19:06,324] [INFO] [timer.py:207:stop] 0/960, RunningAvgSamplesPerSec=1.4193622187928354, CurrSamplesPerSec=0.7582775799862493, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "959    0.003\n",
            "960    0.002\n",
            "961    0.002\n",
            "962    0.002\n",
            "963    0.002\n",
            "964    0.002\n",
            "965    0.002\n",
            "966    0.002\n",
            "[2022-10-23 14:19:16,818] [INFO] [timer.py:207:stop] 0/968, RunningAvgSamplesPerSec=1.4201833849928944, CurrSamplesPerSec=1.5342667393140892, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "967    0.002\n",
            "968    0.002\n",
            "969    0.002\n",
            "970    0.002\n",
            "971    0.002\n",
            "972    0.002\n",
            "973    0.002\n",
            "974    0.002\n",
            "[2022-10-23 14:19:28,672] [INFO] [timer.py:207:stop] 0/976, RunningAvgSamplesPerSec=1.4195831639012484, CurrSamplesPerSec=0.7507541005672669, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "975    0.002\n",
            "976    0.002\n",
            "977    0.002\n",
            "978    0.002\n",
            "979    0.002\n",
            "980    0.002\n",
            "981    0.002\n",
            "982    0.002\n",
            "[2022-10-23 14:19:39,189] [INFO] [timer.py:207:stop] 0/984, RunningAvgSamplesPerSec=1.4203651381407905, CurrSamplesPerSec=1.5096381827994705, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "983    0.002\n",
            "984    0.002\n",
            "985    0.002\n",
            "986    0.002\n",
            "987    0.002\n",
            "988    0.002\n",
            "989    0.002\n",
            "990    0.002\n",
            "[2022-10-23 14:19:51,054] [INFO] [timer.py:207:stop] 0/992, RunningAvgSamplesPerSec=1.4197626982335678, CurrSamplesPerSec=0.7546760795817878, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "991    0.002\n",
            "992    0.001\n",
            "993    0.001\n",
            "994    0.001\n",
            "995    0.001\n",
            "996    0.001\n",
            "997    0.001\n",
            "998    0.001\n",
            "[2022-10-23 14:20:01,546] [INFO] [timer.py:207:stop] 0/1000, RunningAvgSamplesPerSec=1.420556415668965, CurrSamplesPerSec=1.522373714569447, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "999    0.001\n",
            "1000    0.001\n"
          ]
        }
      ],
      "source": [
        "# def main():\n",
        "# data_s = \"/content/data.csv\"\n",
        "data_s = \"/content/data_m_lines.csv\"\n",
        "# preamble\n",
        "exp_id = get_exp_id(data_s)\n",
        "output_dir = get_output_dir(exp_id)\n",
        "\n",
        "# args\n",
        "args = create_args()\n",
        "args.output_dir = output_dir\n",
        "args.exp_id = exp_id\n",
        "\n",
        "# output\n",
        "os.makedirs(args.output_dir, exist_ok=True)\n",
        "copy_source(data_s, args.output_dir)\n",
        "\n",
        "# train\n",
        "me = train(args=args)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## testing the model"
      ],
      "metadata": {
        "id": "kwDAUx43CeLv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385,
          "referenced_widgets": [
            "777f0b4a63f447e4ae4baffc01372ac9",
            "6b6941b61dc348928be8063f19600427",
            "62df38d6a4b448b1911214155156b704",
            "eb5dafc8a1cf458ba7c0e0342eefbc7c",
            "9077192e2fc843568527a349b9b6c494",
            "2c6b53a5645441a5941e12c4763ae88a",
            "84e831ce6276495c8433221688e6ccf2",
            "be8c8fd8e4334b26ad13b3c94ab065e4",
            "388c9bd247794926a45dc188980914bd",
            "63c91caa4c2e45a3a7982d6a40ee5d56",
            "34e77a2742e1427e99f75dff648f6965",
            "7a0b1720b307475ba83be52e06c688d4",
            "859cffb18b2e42a48dcc8927d737babe",
            "a53fa81fdbf64faaad2e6aa3dcb1c9e4",
            "924da18213244578a5a83e8227bde5d2",
            "28539ebbe2664820a068a68ebaca3425",
            "7a67160e87224337b6193216df436fba",
            "142c08cd5ebe45ca8d771c51fecb9952",
            "d04656f112f24bdd9052773b390b9416",
            "e159d45ae931401ab255e64aa809beb6",
            "096e541b6a6748029ecfade2758366e3",
            "20fe3b0b566246868b2b8df0f86b5ef5",
            "061f42bb208b4055b266721860065758",
            "07779955324d4b5bb0fd49ad90291a6e",
            "333cdab9680840a3875ec63cab5c25f8",
            "0ad289143ced4c8888416e6f4543085e",
            "5599f945c139492187434a124ae64693",
            "bbd1e575d10e4ddc9d2ab981abfec9e1",
            "bf8ca83a72c142b0a1b4786c6fc53ad6",
            "41ab15856e0e4c8f8329a1610fb6c1bf",
            "2d9ec703e3c44dcd999b336dd9364d20",
            "390d5cb9f865490aa1a2657f73ffe9dd",
            "94d6fed7a6c24a51b59340ab8854785f",
            "0b67e65b194e4d7a80562a1be9d2fce1",
            "a578e1761c914b9cb9890b87285bccb3",
            "d539cda78c644982a6ac59b8cd620ffe",
            "617b10f0450548db91f05bb3e9676c6e",
            "39a4b16ee57d4bb891cd66c09515c347",
            "9fb8cc83e3f344d3a561700cdf4e28f6",
            "d5a91fe634674450a2f01a6267db4170",
            "9809ae29f59c4638a9eaaf0a26bc2883",
            "df735fba4d4f4966a1f6ffd9ea1fd0af",
            "52977da3492c452e99cb332ac9a40088",
            "ccaed21ee492489e9520b69f4d16a9ae",
            "0d52b20d127b416389b0e8d343d56896",
            "d472981fbbeb4b25bc39b9e7ea0e05ec",
            "27b6e75704e6489f8ec04af7a955c750",
            "50c0acd2833f41cd93b7eb80ca8741d3",
            "7186e704c1d9420d9b8acd8c8b4bcb2c",
            "ceb3b5939aa442ef9233136e27f7e561",
            "d7fbd49b52af42619e7d18990ba2e255",
            "9a86a575224140c4931000f435ad1969",
            "94982e4c25934de0a5030536e3cfb120",
            "5342ca7413e04729a57dd5ba4ee62b2e",
            "25f0022df62e4b4a8f96b17268543f04",
            "93be151011f54860bc41015f0f8f2dd3",
            "27eef7d5554c4a16a3b61c634a133d1d",
            "4461a1b94adb4380bf9bb47c102e5c01",
            "644eeb0d9e35474b85b6461c19cb9fee",
            "c8b4af3d8b1045fabc5494814905f3e2",
            "788a971d7fdd4b6f874149c9ec15f8eb",
            "eae9cb0a98d14d60ad90244793728797",
            "bcf60f3146a74394804b30695e2d55f5",
            "3110e025472f4282869026b091b4edc6",
            "bb15d79e2fc24b5dbf0c05f9a68ca074",
            "8faa84bd2b844dfb97ec802be8ff1b95"
          ]
        },
        "id": "QXJTcWjZn4Wv",
        "outputId": "322bd831-03c7-46cb-fcbe-d03c7b08fbb7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/240 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "777f0b4a63f447e4ae4baffc01372ac9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.json:   0%|          | 0.00/779k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a0b1720b307475ba83be52e06c688d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "061f42bb208b4055b266721860065758"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/2.02M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b67e65b194e4d7a80562a1be9d2fce1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading added_tokens.json:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d52b20d127b416389b0e8d343d56896"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93be151011f54860bc41015f0f8f2dd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def hello_world():\n",
            "    print('Hello World!')\n",
            "\n",
            "hello_world()\n",
            "\n"
          ]
        }
      ],
      "source": [
        "an = []\n",
        "for a  in me.children():\n",
        "  an = a\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
        "\n",
        "text = \"def hello_world():\"\n",
        "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.cuda()\n",
        "\n",
        "# an.to_device(\"cpu\")\n",
        "\n",
        "generated_ids = an.generate(input_ids, max_length=128)\n",
        "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4kH5EhMe7Dx",
        "outputId": "0793280f-779b-4859-f01b-a7992b889293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%draw = function() {\n",
            "\t$(this).html($(\"#\"+\"\"*\"\"*\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
            "\t$(\"#\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n"
          ]
        }
      ],
      "source": [
        "text = \"%draw = function()\"\n",
        "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.cuda()\n",
        "\n",
        "# an.to_device(\"cpu\")\n",
        "\n",
        "generated_ids = an.generate(input_ids, max_length=128)\n",
        "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgUpZpLAmGNH"
      },
      "outputs": [],
      "source": [
        "def gene(text):\n",
        "  # text = \"draw = function()\"\n",
        "  input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.cuda()\n",
        "\n",
        "  # an.to_device(\"cpu\")\n",
        "\n",
        "  generated_ids = me.generate(input_ids, max_length=128)\n",
        "  print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAeCfwaU2nBQ"
      },
      "outputs": [],
      "source": [
        "me.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtG_jEq52RjL"
      },
      "outputs": [],
      "source": [
        "torch.save(me, \"/content/drive/MyDrive/bmo s/model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86Q0_y2L11Tz",
        "outputId": "fc6d8aef-667e-487d-a507-75c92d23fa7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "move_player = function() {\n",
            "    $(\".move-player\").removeClass(\"move-player\");\n",
            "    $(\".move-player\").addClass(\"move-player-\" + $(\"#\" + $.cookie(\"move_player\")).val());\n",
            "    $(\".move-player\").val($(\"#\" + $.cookie(\"move_player\")).val());\n",
            "    $(\".move-player\").change(function() {\n",
            "      $(\".move-player\").removeClass(\"move-player\");\n",
            "      $(\".move-player\").addClass(\"move-\n"
          ]
        }
      ],
      "source": [
        "gene(\"move_player = function()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAUm2dR5RcfM"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
        "\n",
        "# text = \"def hello_world():\"\n",
        "# input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# generated_ids = model.generate(input_ids, max_length=128)\n",
        "# print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yGcRA9HFOWYB",
        "UORF0W9E3gda",
        "kwDAUx43CeLv"
      ],
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "de464b0b27c449068b075748fd465955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75815fd97d9e4d8784cded0f21b2dea4",
              "IPY_MODEL_ef09095f1fdc48398b36a3881739d420",
              "IPY_MODEL_4f5afca4602a4486a7e0c58b15083523"
            ],
            "layout": "IPY_MODEL_7d1362e7ca4e4f0b98abbf34770adadc"
          }
        },
        "75815fd97d9e4d8784cded0f21b2dea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c587423bf6e498ebb36c3b1af6b4cb7",
            "placeholder": "​",
            "style": "IPY_MODEL_2a89bba7dfea42c992948aafd35a82fd",
            "value": "Downloading config.json: 100%"
          }
        },
        "ef09095f1fdc48398b36a3881739d420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c4aead564ba4d4dbd9c45d5cfc09eda",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d3f45991e574f189ff1c59d169ffe6c",
            "value": 1000
          }
        },
        "4f5afca4602a4486a7e0c58b15083523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef34cace72294c5b9adce212ac088419",
            "placeholder": "​",
            "style": "IPY_MODEL_921a9667feff46388793156cbf625744",
            "value": " 0.98k/0.98k [00:00&lt;00:00, 30.1kB/s]"
          }
        },
        "7d1362e7ca4e4f0b98abbf34770adadc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c587423bf6e498ebb36c3b1af6b4cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a89bba7dfea42c992948aafd35a82fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c4aead564ba4d4dbd9c45d5cfc09eda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d3f45991e574f189ff1c59d169ffe6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef34cace72294c5b9adce212ac088419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "921a9667feff46388793156cbf625744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebcd505f95144660bdaa08c0e9a05564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_310611d138214baeaadc384de00275c3",
              "IPY_MODEL_deb380e3e41948e8a8abe10411afab13",
              "IPY_MODEL_03dfe8c4fc4a4a3f98a1a58cc0488674"
            ],
            "layout": "IPY_MODEL_d1403a202a53419ea804d3dc51c0727e"
          }
        },
        "310611d138214baeaadc384de00275c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fbb776fed954969a323bec7c981841a",
            "placeholder": "​",
            "style": "IPY_MODEL_a783168c5b864219a5ea33826eb42167",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "deb380e3e41948e8a8abe10411afab13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92ff073c83f4480f91fcdd4ca4a93c4c",
            "max": 797367631,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba0ee532ff694eb59d943fb138d0b337",
            "value": 797367631
          }
        },
        "03dfe8c4fc4a4a3f98a1a58cc0488674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53467e262e66486dbb717850cfc9d910",
            "placeholder": "​",
            "style": "IPY_MODEL_f495032fb20246f7826164396699c1c8",
            "value": " 760M/760M [00:26&lt;00:00, 45.7MB/s]"
          }
        },
        "d1403a202a53419ea804d3dc51c0727e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fbb776fed954969a323bec7c981841a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a783168c5b864219a5ea33826eb42167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92ff073c83f4480f91fcdd4ca4a93c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba0ee532ff694eb59d943fb138d0b337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53467e262e66486dbb717850cfc9d910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f495032fb20246f7826164396699c1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "777f0b4a63f447e4ae4baffc01372ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b6941b61dc348928be8063f19600427",
              "IPY_MODEL_62df38d6a4b448b1911214155156b704",
              "IPY_MODEL_eb5dafc8a1cf458ba7c0e0342eefbc7c"
            ],
            "layout": "IPY_MODEL_9077192e2fc843568527a349b9b6c494"
          }
        },
        "6b6941b61dc348928be8063f19600427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c6b53a5645441a5941e12c4763ae88a",
            "placeholder": "​",
            "style": "IPY_MODEL_84e831ce6276495c8433221688e6ccf2",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "62df38d6a4b448b1911214155156b704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be8c8fd8e4334b26ad13b3c94ab065e4",
            "max": 240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_388c9bd247794926a45dc188980914bd",
            "value": 240
          }
        },
        "eb5dafc8a1cf458ba7c0e0342eefbc7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63c91caa4c2e45a3a7982d6a40ee5d56",
            "placeholder": "​",
            "style": "IPY_MODEL_34e77a2742e1427e99f75dff648f6965",
            "value": " 240/240 [00:00&lt;00:00, 7.14kB/s]"
          }
        },
        "9077192e2fc843568527a349b9b6c494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c6b53a5645441a5941e12c4763ae88a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e831ce6276495c8433221688e6ccf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be8c8fd8e4334b26ad13b3c94ab065e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "388c9bd247794926a45dc188980914bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63c91caa4c2e45a3a7982d6a40ee5d56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e77a2742e1427e99f75dff648f6965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a0b1720b307475ba83be52e06c688d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_859cffb18b2e42a48dcc8927d737babe",
              "IPY_MODEL_a53fa81fdbf64faaad2e6aa3dcb1c9e4",
              "IPY_MODEL_924da18213244578a5a83e8227bde5d2"
            ],
            "layout": "IPY_MODEL_28539ebbe2664820a068a68ebaca3425"
          }
        },
        "859cffb18b2e42a48dcc8927d737babe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a67160e87224337b6193216df436fba",
            "placeholder": "​",
            "style": "IPY_MODEL_142c08cd5ebe45ca8d771c51fecb9952",
            "value": "Downloading vocab.json: 100%"
          }
        },
        "a53fa81fdbf64faaad2e6aa3dcb1c9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d04656f112f24bdd9052773b390b9416",
            "max": 798156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e159d45ae931401ab255e64aa809beb6",
            "value": 798156
          }
        },
        "924da18213244578a5a83e8227bde5d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_096e541b6a6748029ecfade2758366e3",
            "placeholder": "​",
            "style": "IPY_MODEL_20fe3b0b566246868b2b8df0f86b5ef5",
            "value": " 779k/779k [00:01&lt;00:00, 507kB/s]"
          }
        },
        "28539ebbe2664820a068a68ebaca3425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a67160e87224337b6193216df436fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142c08cd5ebe45ca8d771c51fecb9952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d04656f112f24bdd9052773b390b9416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e159d45ae931401ab255e64aa809beb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "096e541b6a6748029ecfade2758366e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20fe3b0b566246868b2b8df0f86b5ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "061f42bb208b4055b266721860065758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07779955324d4b5bb0fd49ad90291a6e",
              "IPY_MODEL_333cdab9680840a3875ec63cab5c25f8",
              "IPY_MODEL_0ad289143ced4c8888416e6f4543085e"
            ],
            "layout": "IPY_MODEL_5599f945c139492187434a124ae64693"
          }
        },
        "07779955324d4b5bb0fd49ad90291a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbd1e575d10e4ddc9d2ab981abfec9e1",
            "placeholder": "​",
            "style": "IPY_MODEL_bf8ca83a72c142b0a1b4786c6fc53ad6",
            "value": "Downloading merges.txt: 100%"
          }
        },
        "333cdab9680840a3875ec63cab5c25f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41ab15856e0e4c8f8329a1610fb6c1bf",
            "max": 456356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d9ec703e3c44dcd999b336dd9364d20",
            "value": 456356
          }
        },
        "0ad289143ced4c8888416e6f4543085e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390d5cb9f865490aa1a2657f73ffe9dd",
            "placeholder": "​",
            "style": "IPY_MODEL_94d6fed7a6c24a51b59340ab8854785f",
            "value": " 446k/446k [00:00&lt;00:00, 317kB/s]"
          }
        },
        "5599f945c139492187434a124ae64693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbd1e575d10e4ddc9d2ab981abfec9e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf8ca83a72c142b0a1b4786c6fc53ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41ab15856e0e4c8f8329a1610fb6c1bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9ec703e3c44dcd999b336dd9364d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "390d5cb9f865490aa1a2657f73ffe9dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94d6fed7a6c24a51b59340ab8854785f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b67e65b194e4d7a80562a1be9d2fce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a578e1761c914b9cb9890b87285bccb3",
              "IPY_MODEL_d539cda78c644982a6ac59b8cd620ffe",
              "IPY_MODEL_617b10f0450548db91f05bb3e9676c6e"
            ],
            "layout": "IPY_MODEL_39a4b16ee57d4bb891cd66c09515c347"
          }
        },
        "a578e1761c914b9cb9890b87285bccb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fb8cc83e3f344d3a561700cdf4e28f6",
            "placeholder": "​",
            "style": "IPY_MODEL_d5a91fe634674450a2f01a6267db4170",
            "value": "Downloading tokenizer.json: 100%"
          }
        },
        "d539cda78c644982a6ac59b8cd620ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9809ae29f59c4638a9eaaf0a26bc2883",
            "max": 2114827,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df735fba4d4f4966a1f6ffd9ea1fd0af",
            "value": 2114827
          }
        },
        "617b10f0450548db91f05bb3e9676c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52977da3492c452e99cb332ac9a40088",
            "placeholder": "​",
            "style": "IPY_MODEL_ccaed21ee492489e9520b69f4d16a9ae",
            "value": " 2.02M/2.02M [00:01&lt;00:00, 1.99MB/s]"
          }
        },
        "39a4b16ee57d4bb891cd66c09515c347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fb8cc83e3f344d3a561700cdf4e28f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a91fe634674450a2f01a6267db4170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9809ae29f59c4638a9eaaf0a26bc2883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df735fba4d4f4966a1f6ffd9ea1fd0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52977da3492c452e99cb332ac9a40088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccaed21ee492489e9520b69f4d16a9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d52b20d127b416389b0e8d343d56896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d472981fbbeb4b25bc39b9e7ea0e05ec",
              "IPY_MODEL_27b6e75704e6489f8ec04af7a955c750",
              "IPY_MODEL_50c0acd2833f41cd93b7eb80ca8741d3"
            ],
            "layout": "IPY_MODEL_7186e704c1d9420d9b8acd8c8b4bcb2c"
          }
        },
        "d472981fbbeb4b25bc39b9e7ea0e05ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceb3b5939aa442ef9233136e27f7e561",
            "placeholder": "​",
            "style": "IPY_MODEL_d7fbd49b52af42619e7d18990ba2e255",
            "value": "Downloading added_tokens.json: 100%"
          }
        },
        "27b6e75704e6489f8ec04af7a955c750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a86a575224140c4931000f435ad1969",
            "max": 1001,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94982e4c25934de0a5030536e3cfb120",
            "value": 1001
          }
        },
        "50c0acd2833f41cd93b7eb80ca8741d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5342ca7413e04729a57dd5ba4ee62b2e",
            "placeholder": "​",
            "style": "IPY_MODEL_25f0022df62e4b4a8f96b17268543f04",
            "value": " 0.98k/0.98k [00:00&lt;00:00, 34.3kB/s]"
          }
        },
        "7186e704c1d9420d9b8acd8c8b4bcb2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceb3b5939aa442ef9233136e27f7e561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7fbd49b52af42619e7d18990ba2e255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a86a575224140c4931000f435ad1969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94982e4c25934de0a5030536e3cfb120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5342ca7413e04729a57dd5ba4ee62b2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25f0022df62e4b4a8f96b17268543f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93be151011f54860bc41015f0f8f2dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27eef7d5554c4a16a3b61c634a133d1d",
              "IPY_MODEL_4461a1b94adb4380bf9bb47c102e5c01",
              "IPY_MODEL_644eeb0d9e35474b85b6461c19cb9fee"
            ],
            "layout": "IPY_MODEL_c8b4af3d8b1045fabc5494814905f3e2"
          }
        },
        "27eef7d5554c4a16a3b61c634a133d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_788a971d7fdd4b6f874149c9ec15f8eb",
            "placeholder": "​",
            "style": "IPY_MODEL_eae9cb0a98d14d60ad90244793728797",
            "value": "Downloading special_tokens_map.json: 100%"
          }
        },
        "4461a1b94adb4380bf9bb47c102e5c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcf60f3146a74394804b30695e2d55f5",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3110e025472f4282869026b091b4edc6",
            "value": 90
          }
        },
        "644eeb0d9e35474b85b6461c19cb9fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb15d79e2fc24b5dbf0c05f9a68ca074",
            "placeholder": "​",
            "style": "IPY_MODEL_8faa84bd2b844dfb97ec802be8ff1b95",
            "value": " 90.0/90.0 [00:00&lt;00:00, 2.15kB/s]"
          }
        },
        "c8b4af3d8b1045fabc5494814905f3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "788a971d7fdd4b6f874149c9ec15f8eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eae9cb0a98d14d60ad90244793728797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcf60f3146a74394804b30695e2d55f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3110e025472f4282869026b091b4edc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb15d79e2fc24b5dbf0c05f9a68ca074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8faa84bd2b844dfb97ec802be8ff1b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
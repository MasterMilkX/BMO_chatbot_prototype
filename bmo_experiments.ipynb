{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yGcRA9HFOWYB",
        "UORF0W9E3gda"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasterMilkX/BMO_chatbot_prototype/blob/main/bmo_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa3GPYKSblkU",
        "outputId": "82a8a0b3-0142-4b4f-da41-394a98e7783c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#scrapper"
      ],
      "metadata": {
        "id": "yGcRA9HFOWYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use the microstudio_scrapper to get links.txt"
      ],
      "metadata": {
        "id": "OQDwP3rqw5V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wget\n",
        "import wget\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "EdwWL8gjF00e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find source \n",
        "def author_game(string):\n",
        "    index = []\n",
        "    for i, c in enumerate(string):\n",
        "        if c == '/':\n",
        "            index.append(i)\n",
        "    return string[index[2] : index[4]]\n",
        "\n",
        "# extract ms folder from the zip file\n",
        "def extract_zip(file_name):\n",
        "    archive = zipfile.ZipFile(file_name+'.zip')\n",
        "\n",
        "    for file in archive.namelist():\n",
        "        if file.startswith('ms'):\n",
        "            archive.extract(file, 'codes/'+file_name)\n",
        "        if file.startswith('sprites'):\n",
        "            archive.extract(file, 'sprites/'+file_name)"
      ],
      "metadata": {
        "id": "0GgW4Fb5FT5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkbkQL4KFJO1"
      },
      "outputs": [],
      "source": [
        "file1 = open('links.txt', 'r')\n",
        "lines = file1.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for line in lines:\n",
        "    url = line\n",
        "    url_name = \"_\".join(author_game(url).split(\"/\")[1:])\n",
        "    wget.download(url, url_name + '.zip')\n",
        "    extract_zip(url_name)\n",
        "    # os.remove(url_name + '.zip')"
      ],
      "metadata": {
        "id": "eFQe7-zzFpt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir zips"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubYGf3L_Glwq",
        "outputId": "1c54163a-abcf-4730-f078-9ac0b84cef3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘zips’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv sprites /content/drive/MyDrive/microstudio_games"
      ],
      "metadata": {
        "id": "YPdHXvHwGJdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du /content/drive/MyDrive/microstudio_games -h"
      ],
      "metadata": {
        "id": "gc6pB6TIGvdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "2z0TSDzPOaKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#path to zip file\n",
        "!cp \"/content/drive/MyDrive/bmo s/microstudio_games.zip\" ./"
      ],
      "metadata": {
        "id": "UX6laYDxVgTy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"microstudio_games.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./\")"
      ],
      "metadata": {
        "id": "CiEz5BAmcUYN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert directories to list of source code\n",
        "import os\n",
        "def getListOfFiles(dirName):\n",
        "    listOfFile = os.listdir(dirName)\n",
        "    allFiles = list()\n",
        "    for entry in listOfFile:\n",
        "        fullPath = os.path.join(dirName, entry)\n",
        "        if os.path.isdir(fullPath):\n",
        "            allFiles = allFiles + getListOfFiles(fullPath)\n",
        "        else:\n",
        "            allFiles.append(fullPath)\n",
        "                \n",
        "    return allFiles \n",
        "code_list = getListOfFiles(\"microstudio_games/codes\")"
      ],
      "metadata": {
        "id": "x27TZ0QdV97b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(columns = [\"codes\"])\n",
        "for file in code_list:\n",
        "  with open(file, 'r') as f:\n",
        "    string = f.read()\n",
        "    df = df.append({\"codes\" : string}, ignore_index=True)\n",
        "\n",
        "# converting into pandas df/csv\n",
        "df.to_csv('data.csv')"
      ],
      "metadata": {
        "id": "7Jz3SGs4crKE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# copy paste train codegen by salesforce"
      ],
      "metadata": {
        "id": "UORF0W9E3gda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade pip setuptools\n",
        "# !pip install torch --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "# !pip install transformers==4.21.1 datasets==1.16.1 deepspeed==0.7.0\n",
        "!pip install mpi4py"
      ],
      "metadata": {
        "id": "5MfT6GjcRdg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!deepspeed --num_gpus=1 train_deepspeed.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzGfeNbdeTL4",
        "outputId": "98251d1a-a5ea-454c-caa6-70f7311ab6ad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-10-08 12:02:02,124] [WARNING] [runner.py:178:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2022-10-08 12:02:02,158] [INFO] [runner.py:504:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 train_deepspeed.py\n",
            "[2022-10-08 12:02:05,360] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.8.4-1+cuda11.2\n",
            "[2022-10-08 12:02:05,360] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.8.4-1\n",
            "[2022-10-08 12:02:05,360] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-08 12:02:05,360] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.8.4-1+cuda11.2\n",
            "[2022-10-08 12:02:05,360] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2022-10-08 12:02:05,360] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2022-10-08 12:02:05,360] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-08 12:02:05,360] [INFO] [launch.py:136:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2022-10-08 12:02:05,360] [INFO] [launch.py:143:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2022-10-08 12:02:05,361] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2022-10-08 12:02:05,361] [INFO] [launch.py:156:main] dist_world_size=1\n",
            "[2022-10-08 12:02:05,361] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "/usr/bin/python3: can't open file 'train_deepspeed.py': [Errno 2] No such file or directory\n",
            "[2022-10-08 12:02:06,372] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 527\n",
            "[2022-10-08 12:02:06,373] [ERROR] [launch.py:292:sigkill_handler] ['/usr/bin/python3', '-u', 'train_deepspeed.py', '--local_rank=0'] exits with return code = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import random\n",
        "import math\n",
        "import mpi4py\n",
        "\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "from transformers import AutoConfig, AutoModelForCausalLM\n",
        "\n",
        "import deepspeed"
      ],
      "metadata": {
        "id": "87MPUIeVWytA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEEPSPEED_CONFIG = \\\n",
        "{\n",
        "    'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1},\n",
        "    'optimizer': {'type': 'AdamW', 'params': {'lr': 1e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}},\n",
        "    'scheduler': {'type': 'WarmupLR', 'params': {'warmup_min_lr': 0, 'warmup_max_lr': 1e-05, 'warmup_num_steps': 100}},\n",
        "    'zero_optimization': {\n",
        "        'stage': 3,\n",
        "        'offload_optimizer': {'device': 'cpu', 'pin_memory': False},\n",
        "        'offload_param': {'device': 'cpu', 'pin_memory': False},\n",
        "        'overlap_comm': True,\n",
        "        'contiguous_gradients': True,\n",
        "        'sub_group_size': 1e9,\n",
        "        'reduce_bucket_size': 16777216,\n",
        "        'stage3_prefetch_bucket_size': 15099494.4,\n",
        "        'stage3_param_persistence_threshold': 40960,\n",
        "        'stage3_max_live_parameters': 1e9,\n",
        "        'stage3_max_reuse_distance': 1e9,\n",
        "        'stage3_gather_fp16_weights_on_model_save': True\n",
        "    },\n",
        "    'train_batch_size': 32,\n",
        "    'train_micro_batch_size_per_gpu': 2,\n",
        "    'gradient_accumulation_steps': 16,\n",
        "    'gradient_clipping': 1.0,\n",
        "    'steps_per_print': 8,\n",
        "    'wall_clock_breakdown': False,\n",
        "    'compression_training': {'weight_quantization': {'shared_parameters': {}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {}, 'different_groups': {}}}\n",
        "}\n",
        "\n",
        "\n",
        "def create_args(args=argparse.Namespace()):\n",
        "\n",
        "    args.seed = 42\n",
        "\n",
        "    args.model = 'Salesforce/codegen-350M-multi'\n",
        "\n",
        "    args.deepspeed_config = DEEPSPEED_CONFIG\n",
        "\n",
        "    args.opt_steps_train = 1000\n",
        "\n",
        "    return args\n"
      ],
      "metadata": {
        "id": "2CGaM1Rweezu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train\n",
        "\n",
        "def train(args):\n",
        "\n",
        "    #######################\n",
        "    ## preamble\n",
        "\n",
        "    set_seed(args.seed)\n",
        "\n",
        "\n",
        "    #######################\n",
        "    ## model\n",
        "\n",
        "    print('initializing model')\n",
        "\n",
        "    config = AutoConfig.from_pretrained(args.model)\n",
        "    config.gradient_checkpointing = True\n",
        "    config.use_cache = False\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(args.model, config=config)\n",
        "\n",
        "    model.train()\n",
        "    # TODO(enijkamp): we need to set this flag twice?\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "\n",
        "    #######################\n",
        "    ## deepspeed\n",
        "\n",
        "    print('initializing deepspeed')\n",
        "\n",
        "    model_parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "    model_engine, optimizer, _, _ = deepspeed.initialize(config=args.deepspeed_config, model=model, model_parameters=model_parameters)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    #######################\n",
        "    ## train\n",
        "\n",
        "    print('starting training')\n",
        "\n",
        "    input_ids = torch.randint(low=0, high=10, size=[args.deepspeed_config['train_micro_batch_size_per_gpu'], 1024], dtype=torch.int64).cuda()\n",
        "\n",
        "    for step in range(args.opt_steps_train+1):\n",
        "\n",
        "        loss = model_engine(input_ids=input_ids, labels=input_ids).loss\n",
        "\n",
        "        model_engine.backward(loss)\n",
        "        model_engine.step()\n",
        "\n",
        "        print(f'{step} {loss:8.3f}')\n",
        "    return model_engine"
      ],
      "metadata": {
        "id": "_PDoyH8oenVX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################################################################################\n",
        "## preamble\n",
        "\n",
        "def set_gpus(gpu):\n",
        "    torch.cuda.set_device(gpu)\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def set_cuda(deterministic=True):\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.deterministic = deterministic\n",
        "        torch.backends.cudnn.benchmark = not deterministic\n",
        "\n",
        "\n",
        "def get_exp_id(file):\n",
        "    return os.path.splitext(os.path.basename(file))[0]\n",
        "\n",
        "\n",
        "def get_output_dir(exp_id):\n",
        "    import datetime\n",
        "    t = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
        "    output_dir = os.path.join('output/' + exp_id, t)\n",
        "    return output_dir\n",
        "\n",
        "\n",
        "def copy_source(file, output_dir):\n",
        "    import shutil\n",
        "    shutil.copyfile(file, os.path.join(output_dir, os.path.basename(file)))"
      ],
      "metadata": {
        "id": "UrHn3XBeeo00"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def main():\n",
        "\n",
        "# preamble\n",
        "exp_id = get_exp_id(\"/content/data.csv\")\n",
        "output_dir = get_output_dir(exp_id)\n",
        "\n",
        "# args\n",
        "args = create_args()\n",
        "args.output_dir = output_dir\n",
        "args.exp_id = exp_id\n",
        "\n",
        "# output\n",
        "os.makedirs(args.output_dir, exist_ok=True)\n",
        "copy_source(\"/content/data.csv\", args.output_dir)\n",
        "\n",
        "# train\n",
        "me = train(args=args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SzDVgsne1W-",
        "outputId": "19ebe617-5859-4eab-d3f4-615131e3f440"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initializing model\n",
            "initializing deepspeed\n",
            "[2022-10-08 12:57:41,220] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.0, git-hash=unknown, git-branch=unknown\n",
            "[2022-10-08 12:57:41,224] [INFO] [comm.py:613:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
            "[2022-10-08 12:57:41,662] [INFO] [comm.py:670:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=172.28.0.2, master_port=29500\n",
            "[2022-10-08 12:57:41,664] [INFO] [comm.py:630:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[2022-10-08 12:57:41,675] [WARNING] [config_utils.py:64:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\n",
            "[2022-10-08 12:57:45,217] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "Installed CUDA version 11.2 does not match the version torch was compiled with 11.3 but since the APIs are compatible, accepting this combination\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/cpu_adam/build.ninja...\n",
            "Building extension module cpu_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module cpu_adam...\n",
            "Time to load cpu_adam op: 3.559765338897705 seconds\n",
            "[2022-10-08 12:57:55,636] [INFO] [logging.py:68:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
            "[2022-10-08 12:57:55,661] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = {basic_optimizer.__class__.__name__}\n",
            "[2022-10-08 12:57:55,674] [INFO] [utils.py:53:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
            "[2022-10-08 12:57:55,675] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer\n",
            "[2022-10-08 12:57:55,852] [INFO] [utils.py:827:see_memory_usage] Stage 3 initialize beginning\n",
            "[2022-10-08 12:57:55,861] [INFO] [utils.py:832:see_memory_usage] MA 0.74 GB         Max_MA 0.74 GB         CA 0.76 GB         Max_CA 1 GB \n",
            "[2022-10-08 12:57:55,867] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 3.08 GB, percent = 24.3%\n",
            "[2022-10-08 12:57:55,875] [INFO] [stage3.py:114:__init__] Reduce bucket size 16777216\n",
            "[2022-10-08 12:57:55,882] [INFO] [stage3.py:115:__init__] Prefetch bucket size 15099494\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.488325834274292 seconds\n",
            "[2022-10-08 12:57:56,478] [INFO] [utils.py:827:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
            "[2022-10-08 12:57:56,480] [INFO] [utils.py:832:see_memory_usage] MA 0.74 GB         Max_MA 0.74 GB         CA 0.76 GB         Max_CA 1 GB \n",
            "[2022-10-08 12:57:56,484] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 3.08 GB, percent = 24.3%\n",
            "[2022-10-08 12:57:56,492] [WARNING] [config_utils.py:64:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\n",
            "Parameter Offload: Total persistent parameters: 145408 in 82 params\n",
            "[2022-10-08 12:57:56,937] [INFO] [utils.py:827:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
            "[2022-10-08 12:57:56,939] [INFO] [utils.py:832:see_memory_usage] MA 0.08 GB         Max_MA 0.74 GB         CA 0.76 GB         Max_CA 1 GB \n",
            "[2022-10-08 12:57:56,946] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 3.08 GB, percent = 24.3%\n",
            "[2022-10-08 12:58:02,257] [INFO] [stage3.py:368:_setup_for_real_optimizer] optimizer state initialized\n",
            "[2022-10-08 12:58:03,144] [INFO] [utils.py:827:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2022-10-08 12:58:03,146] [INFO] [utils.py:832:see_memory_usage] MA 0.11 GB         Max_MA 0.3 GB         CA 0.96 GB         Max_CA 1 GB \n",
            "[2022-10-08 12:58:03,151] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 11.56 GB, percent = 91.2%\n",
            "[2022-10-08 12:58:03,154] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
            "[2022-10-08 12:58:03,157] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\n",
            "[2022-10-08 12:58:03,160] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fc1c0560fd0>\n",
            "[2022-10-08 12:58:03,163] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[[0.9, 0.999]]\n",
            "[2022-10-08 12:58:03,167] [INFO] [config.py:975:print] DeepSpeedEngine configuration:\n",
            "[2022-10-08 12:58:03,169] [INFO] [config.py:979:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2022-10-08 12:58:03,171] [INFO] [config.py:979:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2022-10-08 12:58:03,174] [INFO] [config.py:979:print]   amp_enabled .................. False\n",
            "[2022-10-08 12:58:03,175] [INFO] [config.py:979:print]   amp_params ................... False\n",
            "[2022-10-08 12:58:03,177] [INFO] [config.py:979:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": null, \n",
            "    \"exps_dir\": null, \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2022-10-08 12:58:03,179] [INFO] [config.py:979:print]   bfloat16_enabled ............. False\n",
            "[2022-10-08 12:58:03,181] [INFO] [config.py:979:print]   checkpoint_tag_validation_enabled  True\n",
            "[2022-10-08 12:58:03,183] [INFO] [config.py:979:print]   checkpoint_tag_validation_fail  False\n",
            "[2022-10-08 12:58:03,184] [INFO] [config.py:979:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc256771f90>\n",
            "[2022-10-08 12:58:03,186] [INFO] [config.py:979:print]   communication_data_type ...... None\n",
            "[2022-10-08 12:58:03,188] [INFO] [config.py:979:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2022-10-08 12:58:03,190] [INFO] [config.py:979:print]   curriculum_enabled ........... False\n",
            "[2022-10-08 12:58:03,192] [INFO] [config.py:979:print]   curriculum_params ............ False\n",
            "[2022-10-08 12:58:03,193] [INFO] [config.py:979:print]   dataloader_drop_last ......... False\n",
            "[2022-10-08 12:58:03,196] [INFO] [config.py:979:print]   disable_allgather ............ False\n",
            "[2022-10-08 12:58:03,198] [INFO] [config.py:979:print]   dump_state ................... False\n",
            "[2022-10-08 12:58:03,199] [INFO] [config.py:979:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
            "[2022-10-08 12:58:03,201] [INFO] [config.py:979:print]   eigenvalue_enabled ........... False\n",
            "[2022-10-08 12:58:03,203] [INFO] [config.py:979:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2022-10-08 12:58:03,205] [INFO] [config.py:979:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2022-10-08 12:58:03,207] [INFO] [config.py:979:print]   eigenvalue_layer_num ......... 0\n",
            "[2022-10-08 12:58:03,209] [INFO] [config.py:979:print]   eigenvalue_max_iter .......... 100\n",
            "[2022-10-08 12:58:03,212] [INFO] [config.py:979:print]   eigenvalue_stability ......... 1e-06\n",
            "[2022-10-08 12:58:03,215] [INFO] [config.py:979:print]   eigenvalue_tol ............... 0.01\n",
            "[2022-10-08 12:58:03,217] [INFO] [config.py:979:print]   eigenvalue_verbose ........... False\n",
            "[2022-10-08 12:58:03,220] [INFO] [config.py:979:print]   elasticity_enabled ........... False\n",
            "[2022-10-08 12:58:03,221] [INFO] [config.py:979:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2022-10-08 12:58:03,223] [INFO] [config.py:979:print]   fp16_auto_cast ............... False\n",
            "[2022-10-08 12:58:03,225] [INFO] [config.py:979:print]   fp16_enabled ................. True\n",
            "[2022-10-08 12:58:03,227] [INFO] [config.py:979:print]   fp16_master_weights_and_gradients  False\n",
            "[2022-10-08 12:58:03,229] [INFO] [config.py:979:print]   global_rank .................. 0\n",
            "[2022-10-08 12:58:03,231] [INFO] [config.py:979:print]   gradient_accumulation_steps .. 16\n",
            "[2022-10-08 12:58:03,232] [INFO] [config.py:979:print]   gradient_clipping ............ 1.0\n",
            "[2022-10-08 12:58:03,235] [INFO] [config.py:979:print]   gradient_predivide_factor .... 1.0\n",
            "[2022-10-08 12:58:03,237] [INFO] [config.py:979:print]   initial_dynamic_scale ........ 4096\n",
            "[2022-10-08 12:58:03,239] [INFO] [config.py:979:print]   load_universal_checkpoint .... False\n",
            "[2022-10-08 12:58:03,240] [INFO] [config.py:979:print]   loss_scale ................... 0\n",
            "[2022-10-08 12:58:03,243] [INFO] [config.py:979:print]   memory_breakdown ............. False\n",
            "[2022-10-08 12:58:03,245] [INFO] [config.py:979:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fc256771ed0>\n",
            "[2022-10-08 12:58:03,247] [INFO] [config.py:979:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2022-10-08 12:58:03,250] [INFO] [config.py:979:print]   optimizer_legacy_fusion ...... False\n",
            "[2022-10-08 12:58:03,251] [INFO] [config.py:979:print]   optimizer_name ............... adamw\n",
            "[2022-10-08 12:58:03,252] [INFO] [config.py:979:print]   optimizer_params ............. {'lr': 1e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}\n",
            "[2022-10-08 12:58:03,255] [INFO] [config.py:979:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2022-10-08 12:58:03,257] [INFO] [config.py:979:print]   pld_enabled .................. False\n",
            "[2022-10-08 12:58:03,258] [INFO] [config.py:979:print]   pld_params ................... False\n",
            "[2022-10-08 12:58:03,262] [INFO] [config.py:979:print]   prescale_gradients ........... False\n",
            "[2022-10-08 12:58:03,264] [INFO] [config.py:979:print]   scheduler_name ............... WarmupLR\n",
            "[2022-10-08 12:58:03,265] [INFO] [config.py:979:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 1e-05, 'warmup_num_steps': 100}\n",
            "[2022-10-08 12:58:03,269] [INFO] [config.py:979:print]   sparse_attention ............. None\n",
            "[2022-10-08 12:58:03,270] [INFO] [config.py:979:print]   sparse_gradients_enabled ..... False\n",
            "[2022-10-08 12:58:03,271] [INFO] [config.py:979:print]   steps_per_print .............. 8\n",
            "[2022-10-08 12:58:03,273] [INFO] [config.py:979:print]   train_batch_size ............. 32\n",
            "[2022-10-08 12:58:03,277] [INFO] [config.py:979:print]   train_micro_batch_size_per_gpu  2\n",
            "[2022-10-08 12:58:03,278] [INFO] [config.py:979:print]   wall_clock_breakdown ......... False\n",
            "[2022-10-08 12:58:03,279] [INFO] [config.py:979:print]   world_size ................... 1\n",
            "[2022-10-08 12:58:03,282] [INFO] [config.py:979:print]   zero_allow_untested_optimizer  False\n",
            "[2022-10-08 12:58:03,306] [INFO] [config.py:979:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=16777216 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=15099494 param_persistence_threshold=40960 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=True ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
            "[2022-10-08 12:58:03,307] [INFO] [config.py:979:print]   zero_enabled ................. True\n",
            "[2022-10-08 12:58:03,308] [INFO] [config.py:979:print]   zero_optimization_stage ...... 3\n",
            "[2022-10-08 12:58:03,310] [INFO] [config.py:987:print]   json = {\n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"loss_scale\": 0, \n",
            "        \"loss_scale_window\": 1000, \n",
            "        \"initial_scale_power\": 12, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1\n",
            "    }, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"AdamW\", \n",
            "        \"params\": {\n",
            "            \"lr\": 1e-05, \n",
            "            \"betas\": [0.9, 0.999], \n",
            "            \"eps\": 1e-08, \n",
            "            \"weight_decay\": 0.0\n",
            "        }\n",
            "    }, \n",
            "    \"scheduler\": {\n",
            "        \"type\": \"WarmupLR\", \n",
            "        \"params\": {\n",
            "            \"warmup_min_lr\": 0, \n",
            "            \"warmup_max_lr\": 1e-05, \n",
            "            \"warmup_num_steps\": 100\n",
            "        }\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 3, \n",
            "        \"offload_optimizer\": {\n",
            "            \"device\": \"cpu\", \n",
            "            \"pin_memory\": false\n",
            "        }, \n",
            "        \"offload_param\": {\n",
            "            \"device\": \"cpu\", \n",
            "            \"pin_memory\": false\n",
            "        }, \n",
            "        \"overlap_comm\": true, \n",
            "        \"contiguous_gradients\": true, \n",
            "        \"sub_group_size\": 1.000000e+09, \n",
            "        \"reduce_bucket_size\": 1.677722e+07, \n",
            "        \"stage3_prefetch_bucket_size\": 1.509949e+07, \n",
            "        \"stage3_param_persistence_threshold\": 4.096000e+04, \n",
            "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
            "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
            "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
            "    }, \n",
            "    \"train_batch_size\": 32, \n",
            "    \"train_micro_batch_size_per_gpu\": 2, \n",
            "    \"gradient_accumulation_steps\": 16, \n",
            "    \"gradient_clipping\": 1.0, \n",
            "    \"steps_per_print\": 8, \n",
            "    \"wall_clock_breakdown\": false, \n",
            "    \"compression_training\": {\n",
            "        \"weight_quantization\": {\n",
            "            \"shared_parameters\": {\n",
            "            }, \n",
            "            \"different_groups\": {\n",
            "            }\n",
            "        }, \n",
            "        \"activation_quantization\": {\n",
            "            \"shared_parameters\": {\n",
            "            }, \n",
            "            \"different_groups\": {\n",
            "            }\n",
            "        }, \n",
            "        \"sparse_pruning\": {\n",
            "            \"shared_parameters\": {\n",
            "            }, \n",
            "            \"different_groups\": {\n",
            "            }\n",
            "        }, \n",
            "        \"row_pruning\": {\n",
            "            \"shared_parameters\": {\n",
            "            }, \n",
            "            \"different_groups\": {\n",
            "            }\n",
            "        }, \n",
            "        \"head_pruning\": {\n",
            "            \"shared_parameters\": {\n",
            "            }, \n",
            "            \"different_groups\": {\n",
            "            }\n",
            "        }, \n",
            "        \"channel_pruning\": {\n",
            "            \"shared_parameters\": {\n",
            "            }, \n",
            "            \"different_groups\": {\n",
            "            }\n",
            "        }\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "No modifications detected for re-loaded extension module utils, skipping build step...\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.0009007453918457031 seconds\n",
            "starting training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py:167: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:402.)\n",
            "  attn_weights = torch.where(causal_mask, attn_weights, mask_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    3.805\n",
            "1    3.805\n",
            "2    3.805\n",
            "3    3.805\n",
            "4    3.805\n",
            "5    3.805\n",
            "6    3.805\n",
            "[2022-10-08 12:58:19,263] [INFO] [timer.py:207:stop] 0/8, RunningAvgSamplesPerSec=1.4251343101927376, CurrSamplesPerSec=1.4708660577895545, MemAllocated=0.21GB, MaxMemAllocated=2.25GB\n",
            "7    3.805\n",
            "8    3.805\n",
            "9    3.805\n",
            "10    3.805\n",
            "11    3.805\n",
            "12    3.805\n",
            "13    3.805\n",
            "14    3.805\n",
            "[2022-10-08 12:58:32,096] [INFO] [timer.py:207:stop] 0/16, RunningAvgSamplesPerSec=1.3179210559302654, CurrSamplesPerSec=0.7086238201651883, MemAllocated=0.11GB, MaxMemAllocated=2.25GB\n",
            "15    3.805\n",
            "16    3.027\n",
            "17    3.027\n",
            "18    3.027\n",
            "19    3.027\n",
            "20    3.027\n",
            "21    3.027\n",
            "22    3.027\n",
            "[2022-10-08 12:58:43,772] [INFO] [timer.py:207:stop] 0/24, RunningAvgSamplesPerSec=1.3369556950075212, CurrSamplesPerSec=1.4982632265549873, MemAllocated=0.21GB, MaxMemAllocated=2.25GB\n",
            "23    3.027\n",
            "24    3.027\n",
            "25    3.027\n",
            "26    3.027\n",
            "27    3.027\n",
            "28    3.027\n",
            "29    3.027\n",
            "30    3.027\n",
            "[2022-10-08 12:58:55,752] [INFO] [timer.py:207:stop] 0/32, RunningAvgSamplesPerSec=1.336864033326066, CurrSamplesPerSec=0.7279871235111429, MemAllocated=0.11GB, MaxMemAllocated=2.25GB\n",
            "31    3.027\n",
            "32    3.027\n",
            "33    3.027\n",
            "34    3.027\n",
            "35    3.027\n",
            "36    3.027\n",
            "37    3.027\n",
            "38    3.027\n",
            "[2022-10-08 12:59:06,295] [INFO] [timer.py:207:stop] 0/40, RunningAvgSamplesPerSec=1.3714840874777388, CurrSamplesPerSec=1.5248172006109006, MemAllocated=0.21GB, MaxMemAllocated=2.25GB\n",
            "39    3.027\n",
            "40    3.027\n",
            "41    3.027\n",
            "42    3.027\n",
            "43    3.027\n",
            "44    3.027\n",
            "45    3.027\n",
            "46    3.027\n",
            "[2022-10-08 12:59:18,795] [INFO] [timer.py:207:stop] 0/48, RunningAvgSamplesPerSec=1.3548104753490064, CurrSamplesPerSec=0.6186471121089773, MemAllocated=0.11GB, MaxMemAllocated=2.25GB\n",
            "47    3.027\n",
            "48    2.811\n",
            "49    2.811\n",
            "50    2.811\n",
            "51    2.811\n",
            "52    2.811\n",
            "53    2.811\n",
            "54    2.811\n",
            "[2022-10-08 12:59:29,629] [INFO] [timer.py:207:stop] 0/56, RunningAvgSamplesPerSec=1.3717284275468318, CurrSamplesPerSec=1.515309787761816, MemAllocated=0.21GB, MaxMemAllocated=2.25GB\n",
            "55    2.811\n",
            "56    2.811\n",
            "57    2.811\n",
            "58    2.811\n",
            "59    2.811\n",
            "60    2.811\n",
            "61    2.811\n",
            "62    2.811\n",
            "[2022-10-08 12:59:41,646] [INFO] [timer.py:207:stop] 0/64, RunningAvgSamplesPerSec=1.3665516093863963, CurrSamplesPerSec=0.7278575709922058, MemAllocated=0.11GB, MaxMemAllocated=2.25GB\n",
            "63    2.811\n",
            "64    2.746\n",
            "65    2.746\n",
            "66    2.746\n",
            "67    2.746\n",
            "68    2.746\n",
            "69    2.746\n",
            "70    2.746\n",
            "[2022-10-08 12:59:52,263] [INFO] [timer.py:207:stop] 0/72, RunningAvgSamplesPerSec=1.3813821071884842, CurrSamplesPerSec=1.517205505675001, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "71    2.746\n",
            "72    2.746\n",
            "73    2.746\n",
            "74    2.746\n",
            "75    2.746\n",
            "76    2.746\n",
            "77    2.746\n",
            "78    2.746\n",
            "[2022-10-08 13:00:04,222] [INFO] [timer.py:207:stop] 0/80, RunningAvgSamplesPerSec=1.3768859886401503, CurrSamplesPerSec=0.742827075696102, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "79    2.746\n",
            "80    2.629\n",
            "81    2.629\n",
            "82    2.629\n",
            "83    2.629\n",
            "84    2.629\n",
            "85    2.629\n",
            "86    2.629\n",
            "[2022-10-08 13:00:14,783] [INFO] [timer.py:207:stop] 0/88, RunningAvgSamplesPerSec=1.388753833136248, CurrSamplesPerSec=1.5262226362366091, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "87    2.629\n",
            "88    2.629\n",
            "89    2.629\n",
            "90    2.629\n",
            "91    2.629\n",
            "92    2.629\n",
            "93    2.629\n",
            "94    2.629\n",
            "[2022-10-08 13:00:26,788] [INFO] [timer.py:207:stop] 0/96, RunningAvgSamplesPerSec=1.3838759619547971, CurrSamplesPerSec=0.7286952019750135, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "95    2.629\n",
            "96    2.549\n",
            "97    2.549\n",
            "98    2.549\n",
            "99    2.549\n",
            "100    2.549\n",
            "101    2.549\n",
            "102    2.549\n",
            "[2022-10-08 13:00:37,298] [INFO] [timer.py:207:stop] 0/104, RunningAvgSamplesPerSec=1.3939032974624552, CurrSamplesPerSec=1.5306128667625816, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "103    2.549\n",
            "104    2.549\n",
            "105    2.549\n",
            "106    2.549\n",
            "107    2.549\n",
            "108    2.549\n",
            "109    2.549\n",
            "110    2.549\n",
            "[2022-10-08 13:00:49,266] [INFO] [timer.py:207:stop] 0/112, RunningAvgSamplesPerSec=1.3896671632803956, CurrSamplesPerSec=0.7322991216364739, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "111    2.549\n",
            "112    2.480\n",
            "113    2.480\n",
            "114    2.480\n",
            "115    2.480\n",
            "116    2.480\n",
            "117    2.480\n",
            "118    2.480\n",
            "[2022-10-08 13:01:00,165] [INFO] [timer.py:207:stop] 0/120, RunningAvgSamplesPerSec=1.394789610288054, CurrSamplesPerSec=1.2811842978632286, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "119    2.480\n",
            "120    2.480\n",
            "121    2.480\n",
            "122    2.480\n",
            "123    2.480\n",
            "124    2.480\n",
            "125    2.480\n",
            "126    2.480\n",
            "[2022-10-08 13:01:12,642] [INFO] [logging.py:68:log_dist] [Rank 0] step=8, skipped=0, lr=[4.515449934959717e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-08 13:01:12,644] [INFO] [timer.py:207:stop] 0/128, RunningAvgSamplesPerSec=1.3871878712935284, CurrSamplesPerSec=0.7482084613853234, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "127    2.480\n",
            "128    2.422\n",
            "129    2.422\n",
            "130    2.422\n",
            "131    2.422\n",
            "132    2.422\n",
            "133    2.422\n",
            "134    2.422\n",
            "[2022-10-08 13:01:23,275] [INFO] [timer.py:207:stop] 0/136, RunningAvgSamplesPerSec=1.3938013677012018, CurrSamplesPerSec=1.4992491786718845, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "135    2.422\n",
            "136    2.422\n",
            "137    2.422\n",
            "138    2.422\n",
            "139    2.422\n",
            "140    2.422\n",
            "141    2.422\n",
            "142    2.422\n",
            "[2022-10-08 13:01:35,292] [INFO] [timer.py:207:stop] 0/144, RunningAvgSamplesPerSec=1.390197708547439, CurrSamplesPerSec=0.7317826330418832, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "143    2.422\n",
            "144    2.383\n",
            "145    2.383\n",
            "146    2.383\n",
            "147    2.383\n",
            "148    2.383\n",
            "149    2.383\n",
            "150    2.383\n",
            "[2022-10-08 13:01:45,848] [INFO] [timer.py:207:stop] 0/152, RunningAvgSamplesPerSec=1.3964240294714094, CurrSamplesPerSec=1.510943368766842, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "151    2.383\n",
            "152    2.383\n",
            "153    2.383\n",
            "154    2.383\n",
            "155    2.383\n",
            "156    2.383\n",
            "157    2.383\n",
            "158    2.383\n",
            "[2022-10-08 13:01:57,841] [INFO] [timer.py:207:stop] 0/160, RunningAvgSamplesPerSec=1.3931817616400122, CurrSamplesPerSec=0.741055154960116, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "159    2.383\n",
            "160    2.355\n",
            "161    2.355\n",
            "162    2.355\n",
            "163    2.355\n",
            "164    2.355\n",
            "165    2.355\n",
            "166    2.355\n",
            "[2022-10-08 13:02:08,446] [INFO] [timer.py:207:stop] 0/168, RunningAvgSamplesPerSec=1.3983902272758286, CurrSamplesPerSec=1.4975768791460218, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "167    2.355\n",
            "168    2.355\n",
            "169    2.355\n",
            "170    2.355\n",
            "171    2.355\n",
            "172    2.355\n",
            "173    2.355\n",
            "174    2.355\n",
            "[2022-10-08 13:02:20,439] [INFO] [timer.py:207:stop] 0/176, RunningAvgSamplesPerSec=1.3953405197981394, CurrSamplesPerSec=0.7313069717498668, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "175    2.355\n",
            "176    2.336\n",
            "177    2.336\n",
            "178    2.336\n",
            "179    2.336\n",
            "180    2.336\n",
            "181    2.336\n",
            "182    2.336\n",
            "[2022-10-08 13:02:31,056] [INFO] [timer.py:207:stop] 0/184, RunningAvgSamplesPerSec=1.399942936472279, CurrSamplesPerSec=1.5087334913299975, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "183    2.336\n",
            "184    2.336\n",
            "185    2.336\n",
            "186    2.336\n",
            "187    2.336\n",
            "188    2.336\n",
            "189    2.336\n",
            "190    2.336\n",
            "[2022-10-08 13:02:43,030] [INFO] [timer.py:207:stop] 0/192, RunningAvgSamplesPerSec=1.3971819508417334, CurrSamplesPerSec=0.7335413531947617, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "191    2.336\n",
            "192    2.316\n",
            "193    2.316\n",
            "194    2.316\n",
            "195    2.316\n",
            "196    2.316\n",
            "197    2.316\n",
            "198    2.316\n",
            "[2022-10-08 13:02:53,613] [INFO] [timer.py:207:stop] 0/200, RunningAvgSamplesPerSec=1.4015223077185643, CurrSamplesPerSec=1.5173764819712454, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "199    2.316\n",
            "200    2.316\n",
            "201    2.316\n",
            "202    2.316\n",
            "203    2.316\n",
            "204    2.316\n",
            "205    2.316\n",
            "206    2.316\n",
            "[2022-10-08 13:03:05,546] [INFO] [timer.py:207:stop] 0/208, RunningAvgSamplesPerSec=1.3991000949724086, CurrSamplesPerSec=0.7485554453506235, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "207    2.316\n",
            "208    2.305\n",
            "209    2.305\n",
            "210    2.305\n",
            "211    2.305\n",
            "212    2.305\n",
            "213    2.305\n",
            "214    2.305\n",
            "[2022-10-08 13:03:16,121] [INFO] [timer.py:207:stop] 0/216, RunningAvgSamplesPerSec=1.4030834071405798, CurrSamplesPerSec=1.5092793803263103, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "215    2.305\n",
            "216    2.305\n",
            "217    2.305\n",
            "218    2.305\n",
            "219    2.305\n",
            "220    2.305\n",
            "221    2.305\n",
            "222    2.305\n",
            "[2022-10-08 13:03:28,064] [INFO] [timer.py:207:stop] 0/224, RunningAvgSamplesPerSec=1.4007297185222292, CurrSamplesPerSec=0.7389154638212673, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "223    2.305\n",
            "224    2.281\n",
            "225    2.281\n",
            "226    2.281\n",
            "227    2.281\n",
            "228    2.281\n",
            "229    2.281\n",
            "230    2.281\n",
            "[2022-10-08 13:03:38,608] [INFO] [timer.py:207:stop] 0/232, RunningAvgSamplesPerSec=1.4045209068160722, CurrSamplesPerSec=1.5222491215673166, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "231    2.281\n",
            "232    2.281\n",
            "233    2.281\n",
            "234    2.281\n",
            "235    2.281\n",
            "236    2.281\n",
            "237    2.281\n",
            "238    2.281\n",
            "[2022-10-08 13:03:50,502] [INFO] [timer.py:207:stop] 0/240, RunningAvgSamplesPerSec=1.4024752411176613, CurrSamplesPerSec=0.7519916967774722, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "239    2.281\n",
            "240    2.268\n",
            "241    2.268\n",
            "242    2.268\n",
            "243    2.268\n",
            "244    2.268\n",
            "245    2.268\n",
            "246    2.268\n",
            "[2022-10-08 13:04:01,070] [INFO] [timer.py:207:stop] 0/248, RunningAvgSamplesPerSec=1.4058779481560504, CurrSamplesPerSec=1.5132877527826385, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "247    2.268\n",
            "248    2.268\n",
            "249    2.268\n",
            "250    2.268\n",
            "251    2.268\n",
            "252    2.268\n",
            "253    2.268\n",
            "254    2.268\n",
            "[2022-10-08 13:04:13,071] [INFO] [logging.py:68:log_dist] [Rank 0] step=16, skipped=0, lr=[6.020599913279623e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-08 13:04:13,073] [INFO] [timer.py:207:stop] 0/256, RunningAvgSamplesPerSec=1.403493256042593, CurrSamplesPerSec=0.7354956401719505, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "255    2.268\n",
            "256    2.252\n",
            "257    2.252\n",
            "258    2.252\n",
            "259    2.252\n",
            "260    2.252\n",
            "261    2.252\n",
            "262    2.252\n",
            "[2022-10-08 13:04:23,606] [INFO] [timer.py:207:stop] 0/264, RunningAvgSamplesPerSec=1.4068009213226047, CurrSamplesPerSec=1.5265431471951894, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "263    2.252\n",
            "264    2.252\n",
            "265    2.252\n",
            "266    2.252\n",
            "267    2.252\n",
            "268    2.252\n",
            "269    2.252\n",
            "270    2.252\n",
            "[2022-10-08 13:04:35,583] [INFO] [timer.py:207:stop] 0/272, RunningAvgSamplesPerSec=1.40462704764837, CurrSamplesPerSec=0.7333330710729901, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "271    2.252\n",
            "272    2.240\n",
            "273    2.240\n",
            "274    2.240\n",
            "275    2.240\n",
            "276    2.240\n",
            "277    2.240\n",
            "278    2.240\n",
            "[2022-10-08 13:04:46,178] [INFO] [timer.py:207:stop] 0/280, RunningAvgSamplesPerSec=1.4074812482501378, CurrSamplesPerSec=1.505315957058896, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "279    2.240\n",
            "280    2.240\n",
            "281    2.240\n",
            "282    2.240\n",
            "283    2.240\n",
            "284    2.240\n",
            "285    2.240\n",
            "286    2.240\n",
            "[2022-10-08 13:04:58,133] [INFO] [timer.py:207:stop] 0/288, RunningAvgSamplesPerSec=1.405478723916915, CurrSamplesPerSec=0.7379813994308418, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "287    2.240\n",
            "288    2.234\n",
            "289    2.234\n",
            "290    2.234\n",
            "291    2.234\n",
            "292    2.234\n",
            "293    2.234\n",
            "294    2.234\n",
            "[2022-10-08 13:05:08,680] [INFO] [timer.py:207:stop] 0/296, RunningAvgSamplesPerSec=1.408326187023518, CurrSamplesPerSec=1.5156336725254393, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "295    2.234\n",
            "296    2.234\n",
            "297    2.234\n",
            "298    2.234\n",
            "299    2.234\n",
            "300    2.234\n",
            "301    2.234\n",
            "302    2.234\n",
            "[2022-10-08 13:05:20,601] [INFO] [timer.py:207:stop] 0/304, RunningAvgSamplesPerSec=1.4065136503362463, CurrSamplesPerSec=0.7450339774994376, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "303    2.234\n",
            "304    2.207\n",
            "305    2.207\n",
            "306    2.207\n",
            "307    2.207\n",
            "308    2.207\n",
            "309    2.207\n",
            "310    2.207\n",
            "[2022-10-08 13:05:31,193] [INFO] [timer.py:207:stop] 0/312, RunningAvgSamplesPerSec=1.409044368858474, CurrSamplesPerSec=1.5199540205559425, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "311    2.207\n",
            "312    2.207\n",
            "313    2.207\n",
            "314    2.207\n",
            "315    2.207\n",
            "316    2.207\n",
            "317    2.207\n",
            "318    2.207\n",
            "[2022-10-08 13:05:43,162] [INFO] [timer.py:207:stop] 0/320, RunningAvgSamplesPerSec=1.407163832744791, CurrSamplesPerSec=0.736963443973797, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "319    2.207\n",
            "320    2.193\n",
            "321    2.193\n",
            "322    2.193\n",
            "323    2.193\n",
            "324    2.193\n",
            "325    2.193\n",
            "326    2.193\n",
            "[2022-10-08 13:05:53,750] [INFO] [timer.py:207:stop] 0/328, RunningAvgSamplesPerSec=1.4095781990211644, CurrSamplesPerSec=1.5067730719579284, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "327    2.193\n",
            "328    2.193\n",
            "329    2.193\n",
            "330    2.193\n",
            "331    2.193\n",
            "332    2.193\n",
            "333    2.193\n",
            "334    2.193\n",
            "[2022-10-08 13:06:05,694] [INFO] [timer.py:207:stop] 0/336, RunningAvgSamplesPerSec=1.4078389832477929, CurrSamplesPerSec=0.743018672792731, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "335    2.193\n",
            "336    2.166\n",
            "337    2.166\n",
            "338    2.166\n",
            "339    2.166\n",
            "340    2.166\n",
            "341    2.166\n",
            "342    2.166\n",
            "[2022-10-08 13:06:16,293] [INFO] [timer.py:207:stop] 0/344, RunningAvgSamplesPerSec=1.4100841397069224, CurrSamplesPerSec=1.513559157505919, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "343    2.166\n",
            "344    2.166\n",
            "345    2.166\n",
            "346    2.166\n",
            "347    2.166\n",
            "348    2.166\n",
            "349    2.166\n",
            "350    2.166\n",
            "[2022-10-08 13:06:28,283] [INFO] [timer.py:207:stop] 0/352, RunningAvgSamplesPerSec=1.4082825772749856, CurrSamplesPerSec=0.7346794356865777, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "351    2.166\n",
            "352    2.162\n",
            "353    2.162\n",
            "354    2.162\n",
            "355    2.162\n",
            "356    2.162\n",
            "357    2.162\n",
            "358    2.162\n",
            "[2022-10-08 13:06:38,909] [INFO] [timer.py:207:stop] 0/360, RunningAvgSamplesPerSec=1.410349365983263, CurrSamplesPerSec=1.5055812669585478, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "359    2.162\n",
            "360    2.162\n",
            "361    2.162\n",
            "362    2.162\n",
            "363    2.162\n",
            "364    2.162\n",
            "365    2.162\n",
            "366    2.162\n",
            "[2022-10-08 13:06:50,963] [INFO] [timer.py:207:stop] 0/368, RunningAvgSamplesPerSec=1.4084628493459248, CurrSamplesPerSec=0.7280205455627292, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "367    2.162\n",
            "368    2.115\n",
            "369    2.115\n",
            "370    2.115\n",
            "371    2.115\n",
            "372    2.115\n",
            "373    2.115\n",
            "374    2.115\n",
            "[2022-10-08 13:07:01,544] [INFO] [timer.py:207:stop] 0/376, RunningAvgSamplesPerSec=1.410553621501742, CurrSamplesPerSec=1.5081703720657038, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "375    2.115\n",
            "376    2.115\n",
            "377    2.115\n",
            "378    2.115\n",
            "379    2.115\n",
            "380    2.115\n",
            "381    2.115\n",
            "382    2.115\n",
            "[2022-10-08 13:07:13,412] [INFO] [logging.py:68:log_dist] [Rank 0] step=24, skipped=0, lr=[6.90105620855803e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-08 13:07:13,414] [INFO] [timer.py:207:stop] 0/384, RunningAvgSamplesPerSec=1.4092029387855856, CurrSamplesPerSec=0.7582776485297955, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "383    2.115\n",
            "384    2.074\n",
            "385    2.074\n",
            "386    2.074\n",
            "387    2.074\n",
            "388    2.074\n",
            "389    2.074\n",
            "390    2.074\n",
            "[2022-10-08 13:07:23,988] [INFO] [timer.py:207:stop] 0/392, RunningAvgSamplesPerSec=1.4112252876513605, CurrSamplesPerSec=1.5214161711117287, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "391    2.074\n",
            "392    2.074\n",
            "393    2.074\n",
            "394    2.074\n",
            "395    2.074\n",
            "396    2.074\n",
            "397    2.074\n",
            "398    2.074\n",
            "[2022-10-08 13:07:35,950] [INFO] [timer.py:207:stop] 0/400, RunningAvgSamplesPerSec=1.4096818395388746, CurrSamplesPerSec=0.733860354082078, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "399    2.074\n",
            "400    2.086\n",
            "401    2.086\n",
            "402    2.086\n",
            "403    2.086\n",
            "404    2.086\n",
            "405    2.086\n",
            "406    2.086\n",
            "[2022-10-08 13:07:46,554] [INFO] [timer.py:207:stop] 0/408, RunningAvgSamplesPerSec=1.411529878212383, CurrSamplesPerSec=1.5094078342809034, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "407    2.086\n",
            "408    2.086\n",
            "409    2.086\n",
            "410    2.086\n",
            "411    2.086\n",
            "412    2.086\n",
            "413    2.086\n",
            "414    2.086\n",
            "[2022-10-08 13:07:58,499] [INFO] [timer.py:207:stop] 0/416, RunningAvgSamplesPerSec=1.4100833365352934, CurrSamplesPerSec=0.7515981502779134, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "415    2.086\n",
            "416    2.012\n",
            "417    2.012\n",
            "418    2.012\n",
            "419    2.012\n",
            "420    2.012\n",
            "421    2.012\n",
            "422    2.012\n",
            "[2022-10-08 13:08:09,131] [INFO] [timer.py:207:stop] 0/424, RunningAvgSamplesPerSec=1.4117871928046024, CurrSamplesPerSec=1.524414856479511, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "423    2.012\n",
            "424    2.012\n",
            "425    2.012\n",
            "426    2.012\n",
            "427    2.012\n",
            "428    2.012\n",
            "429    2.012\n",
            "430    2.012\n",
            "[2022-10-08 13:08:21,083] [INFO] [timer.py:207:stop] 0/432, RunningAvgSamplesPerSec=1.410375797270944, CurrSamplesPerSec=0.7340037413277593, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "431    2.012\n",
            "432    2.109\n",
            "433    2.109\n",
            "434    2.109\n",
            "435    2.109\n",
            "436    2.109\n",
            "437    2.109\n",
            "438    2.109\n",
            "[2022-10-08 13:08:31,651] [INFO] [timer.py:207:stop] 0/440, RunningAvgSamplesPerSec=1.4121628492560225, CurrSamplesPerSec=1.5283217317683686, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "439    2.109\n",
            "440    2.109\n",
            "441    2.109\n",
            "442    2.109\n",
            "443    2.109\n",
            "444    2.109\n",
            "445    2.109\n",
            "446    2.109\n",
            "[2022-10-08 13:08:43,608] [INFO] [timer.py:207:stop] 0/448, RunningAvgSamplesPerSec=1.4107800712986036, CurrSamplesPerSec=0.7394594121917688, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "447    2.109\n",
            "448    2.084\n",
            "449    2.084\n",
            "450    2.084\n",
            "451    2.084\n",
            "452    2.084\n",
            "453    2.084\n",
            "454    2.084\n",
            "[2022-10-08 13:08:54,175] [INFO] [timer.py:207:stop] 0/456, RunningAvgSamplesPerSec=1.4124996977449438, CurrSamplesPerSec=1.5331111933129908, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "455    2.084\n",
            "456    2.084\n",
            "457    2.084\n",
            "458    2.084\n",
            "459    2.084\n",
            "460    2.084\n",
            "461    2.084\n",
            "462    2.084\n",
            "[2022-10-08 13:09:06,101] [INFO] [timer.py:207:stop] 0/464, RunningAvgSamplesPerSec=1.4112256355237747, CurrSamplesPerSec=0.7473417080972632, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "463    2.084\n",
            "464    1.922\n",
            "465    1.922\n",
            "466    1.922\n",
            "467    1.922\n",
            "468    1.922\n",
            "469    1.922\n",
            "470    1.922\n",
            "[2022-10-08 13:09:16,756] [INFO] [timer.py:207:stop] 0/472, RunningAvgSamplesPerSec=1.412689114806053, CurrSamplesPerSec=1.4911670576222835, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "471    1.922\n",
            "472    1.922\n",
            "473    1.922\n",
            "474    1.922\n",
            "475    1.922\n",
            "476    1.922\n",
            "477    1.922\n",
            "478    1.922\n",
            "[2022-10-08 13:09:28,724] [INFO] [timer.py:207:stop] 0/480, RunningAvgSamplesPerSec=1.4113662743137478, CurrSamplesPerSec=0.7350838651672791, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "479    1.922\n",
            "480    1.910\n",
            "481    1.910\n",
            "482    1.910\n",
            "483    1.910\n",
            "484    1.910\n",
            "485    1.910\n",
            "486    1.910\n",
            "[2022-10-08 13:09:39,404] [INFO] [timer.py:207:stop] 0/488, RunningAvgSamplesPerSec=1.4127310998796117, CurrSamplesPerSec=1.5112618500157906, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "487    1.910\n",
            "488    1.910\n",
            "489    1.910\n",
            "490    1.910\n",
            "491    1.910\n",
            "492    1.910\n",
            "493    1.910\n",
            "494    1.910\n",
            "[2022-10-08 13:09:51,284] [INFO] [timer.py:207:stop] 0/496, RunningAvgSamplesPerSec=1.4116268724068606, CurrSamplesPerSec=0.7488236652547346, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "495    1.910\n",
            "496    1.899\n",
            "497    1.899\n",
            "498    1.899\n",
            "499    1.899\n",
            "500    1.899\n",
            "501    1.899\n",
            "502    1.899\n",
            "[2022-10-08 13:10:01,961] [INFO] [timer.py:207:stop] 0/504, RunningAvgSamplesPerSec=1.4129489295285107, CurrSamplesPerSec=1.5217280411221368, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "503    1.899\n",
            "504    1.899\n",
            "505    1.899\n",
            "506    1.899\n",
            "507    1.899\n",
            "508    1.899\n",
            "509    1.899\n",
            "510    1.899\n",
            "[2022-10-08 13:10:14,006] [INFO] [logging.py:68:log_dist] [Rank 0] step=32, skipped=0, lr=[7.5257498915995295e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-08 13:10:14,008] [INFO] [timer.py:207:stop] 0/512, RunningAvgSamplesPerSec=1.4115515784003576, CurrSamplesPerSec=0.7218192519369305, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "511    1.899\n",
            "512    1.750\n",
            "513    1.750\n",
            "514    1.750\n",
            "515    1.750\n",
            "516    1.750\n",
            "517    1.750\n",
            "518    1.750\n",
            "[2022-10-08 13:10:24,772] [INFO] [timer.py:207:stop] 0/520, RunningAvgSamplesPerSec=1.4126704583050511, CurrSamplesPerSec=1.5025466032423493, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "519    1.750\n",
            "520    1.750\n",
            "521    1.750\n",
            "522    1.750\n",
            "523    1.750\n",
            "524    1.750\n",
            "525    1.750\n",
            "526    1.750\n",
            "[2022-10-08 13:10:36,831] [INFO] [timer.py:207:stop] 0/528, RunningAvgSamplesPerSec=1.4113055374557637, CurrSamplesPerSec=0.7290455444883702, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "527    1.750\n",
            "528    1.792\n",
            "529    1.792\n",
            "530    1.792\n",
            "531    1.792\n",
            "532    1.792\n",
            "533    1.792\n",
            "534    1.792\n",
            "[2022-10-08 13:10:47,481] [INFO] [timer.py:207:stop] 0/536, RunningAvgSamplesPerSec=1.4126050800787389, CurrSamplesPerSec=1.4963686080053487, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "535    1.792\n",
            "536    1.792\n",
            "537    1.792\n",
            "538    1.792\n",
            "539    1.792\n",
            "540    1.792\n",
            "541    1.792\n",
            "542    1.792\n",
            "[2022-10-08 13:10:59,467] [INFO] [timer.py:207:stop] 0/544, RunningAvgSamplesPerSec=1.4114075744146277, CurrSamplesPerSec=0.744100164873478, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "543    1.792\n",
            "544    1.755\n",
            "545    1.755\n",
            "546    1.755\n",
            "547    1.755\n",
            "548    1.755\n",
            "549    1.755\n",
            "550    1.755\n",
            "[2022-10-08 13:11:10,084] [INFO] [timer.py:207:stop] 0/552, RunningAvgSamplesPerSec=1.4127282823102079, CurrSamplesPerSec=1.4996673010769719, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "551    1.755\n",
            "552    1.755\n",
            "553    1.755\n",
            "554    1.755\n",
            "555    1.755\n",
            "556    1.755\n",
            "557    1.755\n",
            "558    1.755\n",
            "[2022-10-08 13:11:22,025] [INFO] [timer.py:207:stop] 0/560, RunningAvgSamplesPerSec=1.411643073974026, CurrSamplesPerSec=0.7453148433779471, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "559    1.755\n",
            "560    1.581\n",
            "561    1.581\n",
            "562    1.581\n",
            "563    1.581\n",
            "564    1.581\n",
            "565    1.581\n",
            "566    1.581\n",
            "[2022-10-08 13:11:32,620] [INFO] [timer.py:207:stop] 0/568, RunningAvgSamplesPerSec=1.4129598152947451, CurrSamplesPerSec=1.5054664319496118, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "567    1.581\n",
            "568    1.581\n",
            "569    1.581\n",
            "570    1.581\n",
            "571    1.581\n",
            "572    1.581\n",
            "573    1.581\n",
            "574    1.581\n",
            "[2022-10-08 13:11:44,601] [INFO] [timer.py:207:stop] 0/576, RunningAvgSamplesPerSec=1.4118316428435669, CurrSamplesPerSec=0.7416105857680143, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "575    1.581\n",
            "576    1.587\n",
            "577    1.587\n",
            "578    1.587\n",
            "579    1.587\n",
            "580    1.587\n",
            "581    1.587\n",
            "582    1.587\n",
            "[2022-10-08 13:11:55,237] [INFO] [timer.py:207:stop] 0/584, RunningAvgSamplesPerSec=1.4130414390827026, CurrSamplesPerSec=1.5149310483635758, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "583    1.587\n",
            "584    1.587\n",
            "585    1.587\n",
            "586    1.587\n",
            "587    1.587\n",
            "588    1.587\n",
            "589    1.587\n",
            "590    1.587\n",
            "[2022-10-08 13:12:07,212] [INFO] [timer.py:207:stop] 0/592, RunningAvgSamplesPerSec=1.4119524226696532, CurrSamplesPerSec=0.7397479624674785, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "591    1.587\n",
            "592    1.526\n",
            "593    1.526\n",
            "594    1.526\n",
            "595    1.526\n",
            "596    1.526\n",
            "597    1.526\n",
            "598    1.526\n",
            "[2022-10-08 13:12:17,857] [INFO] [timer.py:207:stop] 0/600, RunningAvgSamplesPerSec=1.413111598105724, CurrSamplesPerSec=1.518357801835002, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "599    1.526\n",
            "600    1.526\n",
            "601    1.526\n",
            "602    1.526\n",
            "603    1.526\n",
            "604    1.526\n",
            "605    1.526\n",
            "606    1.526\n",
            "[2022-10-08 13:12:29,839] [INFO] [timer.py:207:stop] 0/608, RunningAvgSamplesPerSec=1.4120376733247768, CurrSamplesPerSec=0.7345934182643222, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "607    1.526\n",
            "608    1.467\n",
            "609    1.467\n",
            "610    1.467\n",
            "611    1.467\n",
            "612    1.467\n",
            "613    1.467\n",
            "614    1.467\n",
            "[2022-10-08 13:12:40,466] [INFO] [timer.py:207:stop] 0/616, RunningAvgSamplesPerSec=1.413194949330748, CurrSamplesPerSec=1.5078434350742318, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "615    1.467\n",
            "616    1.467\n",
            "617    1.467\n",
            "618    1.467\n",
            "619    1.467\n",
            "620    1.467\n",
            "621    1.467\n",
            "622    1.467\n",
            "[2022-10-08 13:12:52,459] [INFO] [timer.py:207:stop] 0/624, RunningAvgSamplesPerSec=1.4121340472590451, CurrSamplesPerSec=0.73383396871389, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "623    1.467\n",
            "624    1.344\n",
            "625    1.344\n",
            "626    1.344\n",
            "627    1.344\n",
            "628    1.344\n",
            "629    1.344\n",
            "630    1.344\n",
            "[2022-10-08 13:13:03,060] [INFO] [timer.py:207:stop] 0/632, RunningAvgSamplesPerSec=1.41330262455772, CurrSamplesPerSec=1.517640569229553, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "631    1.344\n",
            "632    1.344\n",
            "633    1.344\n",
            "634    1.344\n",
            "635    1.344\n",
            "636    1.344\n",
            "637    1.344\n",
            "638    1.344\n",
            "[2022-10-08 13:13:14,930] [INFO] [logging.py:68:log_dist] [Rank 0] step=40, skipped=0, lr=[8.010299956639811e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-08 13:13:14,932] [INFO] [timer.py:207:stop] 0/640, RunningAvgSamplesPerSec=1.4124528773782001, CurrSamplesPerSec=0.7582489984074129, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "639    1.344\n",
            "640    1.188\n",
            "641    1.188\n",
            "642    1.188\n",
            "643    1.188\n",
            "644    1.188\n",
            "645    1.188\n",
            "646    1.188\n",
            "[2022-10-08 13:13:25,553] [INFO] [timer.py:207:stop] 0/648, RunningAvgSamplesPerSec=1.4135623506089376, CurrSamplesPerSec=1.5024096273334198, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "647    1.188\n",
            "648    1.188\n",
            "649    1.188\n",
            "650    1.188\n",
            "651    1.188\n",
            "652    1.188\n",
            "653    1.188\n",
            "654    1.188\n",
            "[2022-10-08 13:13:37,597] [INFO] [timer.py:207:stop] 0/656, RunningAvgSamplesPerSec=1.4124679981675532, CurrSamplesPerSec=0.738215652293596, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "655    1.188\n",
            "656    1.163\n",
            "657    1.163\n",
            "658    1.163\n",
            "659    1.163\n",
            "660    1.163\n",
            "661    1.163\n",
            "662    1.163\n",
            "[2022-10-08 13:13:48,209] [INFO] [timer.py:207:stop] 0/664, RunningAvgSamplesPerSec=1.413559035561932, CurrSamplesPerSec=1.5145626159807635, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "663    1.163\n",
            "664    1.163\n",
            "665    1.163\n",
            "666    1.163\n",
            "667    1.163\n",
            "668    1.163\n",
            "669    1.163\n",
            "670    1.163\n",
            "[2022-10-08 13:14:00,157] [INFO] [timer.py:207:stop] 0/672, RunningAvgSamplesPerSec=1.4126343198365374, CurrSamplesPerSec=0.7507420737254397, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "671    1.163\n",
            "672    0.987\n",
            "673    0.987\n",
            "674    0.987\n",
            "675    0.987\n",
            "676    0.987\n",
            "677    0.987\n",
            "678    0.987\n",
            "[2022-10-08 13:14:10,747] [INFO] [timer.py:207:stop] 0/680, RunningAvgSamplesPerSec=1.4137293330025038, CurrSamplesPerSec=1.504142906887966, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "679    0.987\n",
            "680    0.987\n",
            "681    0.987\n",
            "682    0.987\n",
            "683    0.987\n",
            "684    0.987\n",
            "685    0.987\n",
            "686    0.987\n",
            "[2022-10-08 13:14:22,762] [INFO] [timer.py:207:stop] 0/688, RunningAvgSamplesPerSec=1.412725403698187, CurrSamplesPerSec=0.7326701524495026, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "687    0.987\n",
            "688    0.956\n",
            "689    0.956\n",
            "690    0.956\n",
            "691    0.956\n",
            "692    0.956\n",
            "693    0.956\n",
            "694    0.956\n",
            "[2022-10-08 13:14:33,423] [INFO] [timer.py:207:stop] 0/696, RunningAvgSamplesPerSec=1.4136941547693673, CurrSamplesPerSec=1.4880753279098562, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "695    0.956\n",
            "696    0.956\n",
            "697    0.956\n",
            "698    0.956\n",
            "699    0.956\n",
            "700    0.956\n",
            "701    0.956\n",
            "702    0.956\n",
            "[2022-10-08 13:14:45,490] [INFO] [timer.py:207:stop] 0/704, RunningAvgSamplesPerSec=1.4126413756619849, CurrSamplesPerSec=0.7289199853670447, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "703    0.956\n",
            "704    0.823\n",
            "705    0.823\n",
            "706    0.823\n",
            "707    0.823\n",
            "708    0.823\n",
            "709    0.823\n",
            "710    0.823\n",
            "[2022-10-08 13:14:56,200] [INFO] [timer.py:207:stop] 0/712, RunningAvgSamplesPerSec=1.4135184674370773, CurrSamplesPerSec=1.5159760511939162, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "711    0.823\n",
            "712    0.823\n",
            "713    0.823\n",
            "714    0.823\n",
            "715    0.823\n",
            "716    0.823\n",
            "717    0.823\n",
            "718    0.823\n",
            "[2022-10-08 13:15:08,193] [INFO] [timer.py:207:stop] 0/720, RunningAvgSamplesPerSec=1.4125927382644135, CurrSamplesPerSec=0.7409861609575943, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "719    0.823\n",
            "720    0.697\n",
            "721    0.697\n",
            "722    0.697\n",
            "723    0.697\n",
            "724    0.697\n",
            "725    0.697\n",
            "726    0.697\n",
            "[2022-10-08 13:15:18,863] [INFO] [timer.py:207:stop] 0/728, RunningAvgSamplesPerSec=1.4135081673858017, CurrSamplesPerSec=1.513314233665987, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "727    0.697\n",
            "728    0.697\n",
            "729    0.697\n",
            "730    0.697\n",
            "731    0.697\n",
            "732    0.697\n",
            "733    0.697\n",
            "734    0.697\n",
            "[2022-10-08 13:15:30,964] [INFO] [timer.py:207:stop] 0/736, RunningAvgSamplesPerSec=1.4124579760262532, CurrSamplesPerSec=0.730597056067518, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "735    0.697\n",
            "736    0.645\n",
            "737    0.645\n",
            "738    0.645\n",
            "739    0.645\n",
            "740    0.645\n",
            "741    0.645\n",
            "742    0.645\n",
            "[2022-10-08 13:15:41,615] [INFO] [timer.py:207:stop] 0/744, RunningAvgSamplesPerSec=1.4133808181003948, CurrSamplesPerSec=1.5047726609010617, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "743    0.645\n",
            "744    0.645\n",
            "745    0.645\n",
            "746    0.645\n",
            "747    0.645\n",
            "748    0.645\n",
            "749    0.645\n",
            "750    0.645\n",
            "[2022-10-08 13:15:53,576] [INFO] [timer.py:207:stop] 0/752, RunningAvgSamplesPerSec=1.4125393161088167, CurrSamplesPerSec=0.7492266233763913, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "751    0.645\n",
            "752    0.467\n",
            "753    0.467\n",
            "754    0.467\n",
            "755    0.467\n",
            "756    0.467\n",
            "757    0.467\n",
            "758    0.467\n",
            "[2022-10-08 13:16:04,204] [INFO] [timer.py:207:stop] 0/760, RunningAvgSamplesPerSec=1.4134709750844188, CurrSamplesPerSec=1.5111371635878368, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "759    0.467\n",
            "760    0.467\n",
            "761    0.467\n",
            "762    0.467\n",
            "763    0.467\n",
            "764    0.467\n",
            "765    0.467\n",
            "766    0.467\n",
            "[2022-10-08 13:16:16,242] [INFO] [logging.py:68:log_dist] [Rank 0] step=48, skipped=0, lr=[8.406206186877936e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-08 13:16:16,244] [INFO] [timer.py:207:stop] 0/768, RunningAvgSamplesPerSec=1.4125431064383538, CurrSamplesPerSec=0.7348090467113021, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "767    0.467\n",
            "768    0.404\n",
            "769    0.404\n",
            "770    0.404\n",
            "771    0.404\n",
            "772    0.404\n",
            "773    0.404\n",
            "774    0.404\n",
            "[2022-10-08 13:16:26,848] [INFO] [timer.py:207:stop] 0/776, RunningAvgSamplesPerSec=1.4134891044127245, CurrSamplesPerSec=1.5165197923306684, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "775    0.404\n",
            "776    0.404\n",
            "777    0.404\n",
            "778    0.404\n",
            "779    0.404\n",
            "780    0.404\n",
            "781    0.404\n",
            "782    0.404\n",
            "[2022-10-08 13:16:38,813] [INFO] [timer.py:207:stop] 0/784, RunningAvgSamplesPerSec=1.4126745794365672, CurrSamplesPerSec=0.7376731423248949, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "783    0.404\n",
            "784    0.308\n",
            "785    0.308\n",
            "786    0.308\n",
            "787    0.308\n",
            "788    0.308\n",
            "789    0.308\n",
            "790    0.308\n",
            "[2022-10-08 13:16:49,413] [INFO] [timer.py:207:stop] 0/792, RunningAvgSamplesPerSec=1.4136023407038625, CurrSamplesPerSec=1.512793794893158, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "791    0.308\n",
            "792    0.308\n",
            "793    0.308\n",
            "794    0.308\n",
            "795    0.308\n",
            "796    0.308\n",
            "797    0.308\n",
            "798    0.308\n",
            "[2022-10-08 13:17:01,378] [INFO] [timer.py:207:stop] 0/800, RunningAvgSamplesPerSec=1.4128053558860272, CurrSamplesPerSec=0.742099552498986, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "799    0.308\n",
            "800    0.219\n",
            "801    0.219\n",
            "802    0.219\n",
            "803    0.219\n",
            "804    0.219\n",
            "805    0.219\n",
            "806    0.219\n",
            "[2022-10-08 13:17:12,057] [INFO] [timer.py:207:stop] 0/808, RunningAvgSamplesPerSec=1.4136151261981211, CurrSamplesPerSec=1.507138806981636, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "807    0.219\n",
            "808    0.219\n",
            "809    0.219\n",
            "810    0.219\n",
            "811    0.219\n",
            "812    0.219\n",
            "813    0.219\n",
            "814    0.219\n",
            "[2022-10-08 13:17:24,063] [INFO] [timer.py:207:stop] 0/816, RunningAvgSamplesPerSec=1.4127808392971957, CurrSamplesPerSec=0.7386392043350788, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "815    0.219\n",
            "816    0.155\n",
            "817    0.155\n",
            "818    0.155\n",
            "819    0.155\n",
            "820    0.155\n",
            "821    0.155\n",
            "822    0.155\n",
            "[2022-10-08 13:17:34,743] [INFO] [timer.py:207:stop] 0/824, RunningAvgSamplesPerSec=1.4135763506593169, CurrSamplesPerSec=1.4908959389893106, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "823    0.155\n",
            "824    0.155\n",
            "825    0.155\n",
            "826    0.155\n",
            "827    0.155\n",
            "828    0.155\n",
            "829    0.155\n",
            "830    0.155\n",
            "[2022-10-08 13:17:46,788] [INFO] [timer.py:207:stop] 0/832, RunningAvgSamplesPerSec=1.4127142460981625, CurrSamplesPerSec=0.7410475610630877, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "831    0.155\n",
            "832    0.115\n",
            "833    0.115\n",
            "834    0.115\n",
            "835    0.115\n",
            "836    0.115\n",
            "837    0.115\n",
            "838    0.115\n",
            "[2022-10-08 13:17:57,508] [INFO] [timer.py:207:stop] 0/840, RunningAvgSamplesPerSec=1.4134483071081172, CurrSamplesPerSec=1.474072318144589, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "839    0.115\n",
            "840    0.115\n",
            "841    0.115\n",
            "842    0.115\n",
            "843    0.115\n",
            "844    0.115\n",
            "845    0.115\n",
            "846    0.115\n",
            "[2022-10-08 13:18:09,553] [INFO] [timer.py:207:stop] 0/848, RunningAvgSamplesPerSec=1.4126018299850154, CurrSamplesPerSec=0.7369441506574342, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "847    0.115\n",
            "848    0.068\n",
            "849    0.068\n",
            "850    0.068\n",
            "851    0.068\n",
            "852    0.068\n",
            "853    0.068\n",
            "854    0.068\n",
            "[2022-10-08 13:18:20,241] [INFO] [timer.py:207:stop] 0/856, RunningAvgSamplesPerSec=1.4133577234280783, CurrSamplesPerSec=1.4957952085955273, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "855    0.068\n",
            "856    0.068\n",
            "857    0.068\n",
            "858    0.068\n",
            "859    0.068\n",
            "860    0.068\n",
            "861    0.068\n",
            "862    0.068\n",
            "[2022-10-08 13:18:32,188] [INFO] [timer.py:207:stop] 0/864, RunningAvgSamplesPerSec=1.4126419442005123, CurrSamplesPerSec=0.7412804240509506, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "863    0.068\n",
            "864    0.039\n",
            "865    0.039\n",
            "866    0.039\n",
            "867    0.039\n",
            "868    0.039\n",
            "869    0.039\n",
            "870    0.039\n",
            "[2022-10-08 13:18:42,766] [INFO] [timer.py:207:stop] 0/872, RunningAvgSamplesPerSec=1.4135090633122502, CurrSamplesPerSec=1.519594702672485, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "871    0.039\n",
            "872    0.039\n",
            "873    0.039\n",
            "874    0.039\n",
            "875    0.039\n",
            "876    0.039\n",
            "877    0.039\n",
            "878    0.039\n",
            "[2022-10-08 13:18:54,748] [INFO] [timer.py:207:stop] 0/880, RunningAvgSamplesPerSec=1.4127670476114378, CurrSamplesPerSec=0.7414456647575618, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "879    0.039\n",
            "880    0.024\n",
            "881    0.024\n",
            "882    0.024\n",
            "883    0.024\n",
            "884    0.024\n",
            "885    0.024\n",
            "886    0.024\n",
            "[2022-10-08 13:19:05,313] [INFO] [timer.py:207:stop] 0/888, RunningAvgSamplesPerSec=1.4136325831880638, CurrSamplesPerSec=1.5139522388824709, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "887    0.024\n",
            "888    0.024\n",
            "889    0.024\n",
            "890    0.024\n",
            "891    0.024\n",
            "892    0.024\n",
            "893    0.024\n",
            "894    0.024\n",
            "[2022-10-08 13:19:17,268] [INFO] [logging.py:68:log_dist] [Rank 0] step=56, skipped=0, lr=[8.740940135031001e-06], mom=[[0.9, 0.999]]\n",
            "[2022-10-08 13:19:17,270] [INFO] [timer.py:207:stop] 0/896, RunningAvgSamplesPerSec=1.412928612514893, CurrSamplesPerSec=0.7507756692208314, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "895    0.024\n",
            "896    0.014\n",
            "897    0.014\n",
            "898    0.014\n",
            "899    0.014\n",
            "900    0.014\n",
            "901    0.014\n",
            "902    0.014\n",
            "[2022-10-08 13:19:27,886] [INFO] [timer.py:207:stop] 0/904, RunningAvgSamplesPerSec=1.4137234336265023, CurrSamplesPerSec=1.502768401084681, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "903    0.014\n",
            "904    0.014\n",
            "905    0.014\n",
            "906    0.014\n",
            "907    0.014\n",
            "908    0.014\n",
            "909    0.014\n",
            "910    0.014\n",
            "[2022-10-08 13:19:39,927] [INFO] [timer.py:207:stop] 0/912, RunningAvgSamplesPerSec=1.4129400954281395, CurrSamplesPerSec=0.7349795928273364, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "911    0.014\n",
            "912    0.008\n",
            "913    0.008\n",
            "914    0.008\n",
            "915    0.008\n",
            "916    0.008\n",
            "917    0.008\n",
            "918    0.008\n",
            "[2022-10-08 13:19:50,530] [INFO] [timer.py:207:stop] 0/920, RunningAvgSamplesPerSec=1.4137322391957883, CurrSamplesPerSec=1.50114035808228, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "919    0.008\n",
            "920    0.008\n",
            "921    0.008\n",
            "922    0.008\n",
            "923    0.008\n",
            "924    0.008\n",
            "925    0.008\n",
            "926    0.008\n",
            "[2022-10-08 13:20:02,475] [INFO] [timer.py:207:stop] 0/928, RunningAvgSamplesPerSec=1.4130667961926096, CurrSamplesPerSec=0.7484693537041194, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "927    0.008\n",
            "928    0.006\n",
            "929    0.006\n",
            "930    0.006\n",
            "931    0.006\n",
            "932    0.006\n",
            "933    0.006\n",
            "934    0.006\n",
            "[2022-10-08 13:20:13,090] [INFO] [timer.py:207:stop] 0/936, RunningAvgSamplesPerSec=1.4138321225025954, CurrSamplesPerSec=1.498374021206493, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "935    0.006\n",
            "936    0.006\n",
            "937    0.006\n",
            "938    0.006\n",
            "939    0.006\n",
            "940    0.006\n",
            "941    0.006\n",
            "942    0.006\n",
            "[2022-10-08 13:20:25,114] [INFO] [timer.py:207:stop] 0/944, RunningAvgSamplesPerSec=1.413091447157351, CurrSamplesPerSec=0.7343925106498018, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "943    0.006\n",
            "944    0.003\n",
            "945    0.003\n",
            "946    0.003\n",
            "947    0.003\n",
            "948    0.003\n",
            "949    0.003\n",
            "950    0.003\n",
            "[2022-10-08 13:20:35,673] [INFO] [timer.py:207:stop] 0/952, RunningAvgSamplesPerSec=1.4139039965543425, CurrSamplesPerSec=1.5121344137424813, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "951    0.003\n",
            "952    0.003\n",
            "953    0.003\n",
            "954    0.003\n",
            "955    0.003\n",
            "956    0.003\n",
            "957    0.003\n",
            "958    0.003\n",
            "[2022-10-08 13:20:47,664] [INFO] [timer.py:207:stop] 0/960, RunningAvgSamplesPerSec=1.4132088717728126, CurrSamplesPerSec=0.7358975474666888, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "959    0.003\n",
            "960    0.002\n",
            "961    0.002\n",
            "962    0.002\n",
            "963    0.002\n",
            "964    0.002\n",
            "965    0.002\n",
            "966    0.002\n",
            "[2022-10-08 13:20:58,282] [INFO] [timer.py:207:stop] 0/968, RunningAvgSamplesPerSec=1.4139456506610446, CurrSamplesPerSec=1.511187253479325, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "967    0.002\n",
            "968    0.002\n",
            "969    0.002\n",
            "970    0.002\n",
            "971    0.002\n",
            "972    0.002\n",
            "973    0.002\n",
            "974    0.002\n",
            "[2022-10-08 13:21:10,189] [INFO] [timer.py:207:stop] 0/976, RunningAvgSamplesPerSec=1.4133469037169406, CurrSamplesPerSec=0.757190053655682, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "975    0.002\n",
            "976    0.002\n",
            "977    0.002\n",
            "978    0.002\n",
            "979    0.002\n",
            "980    0.002\n",
            "981    0.002\n",
            "982    0.002\n",
            "[2022-10-08 13:21:20,791] [INFO] [timer.py:207:stop] 0/984, RunningAvgSamplesPerSec=1.4140865213725613, CurrSamplesPerSec=1.5070743640941304, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "983    0.002\n",
            "984    0.002\n",
            "985    0.002\n",
            "986    0.002\n",
            "987    0.002\n",
            "988    0.002\n",
            "989    0.002\n",
            "990    0.002\n",
            "[2022-10-08 13:21:32,802] [INFO] [timer.py:207:stop] 0/992, RunningAvgSamplesPerSec=1.4133911684249978, CurrSamplesPerSec=0.7320044709421484, MemAllocated=0.11GB, MaxMemAllocated=2.86GB\n",
            "991    0.002\n",
            "992    0.001\n",
            "993    0.001\n",
            "994    0.001\n",
            "995    0.001\n",
            "996    0.001\n",
            "997    0.001\n",
            "998    0.001\n",
            "[2022-10-08 13:21:43,435] [INFO] [timer.py:207:stop] 0/1000, RunningAvgSamplesPerSec=1.4140872020974464, CurrSamplesPerSec=1.5123353304640468, MemAllocated=0.21GB, MaxMemAllocated=2.86GB\n",
            "999    0.001\n",
            "1000    0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "an = []\n",
        "for a  in me.children():\n",
        "  an = a\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
        "\n",
        "text = \"def hello_world():\"\n",
        "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.cuda()\n",
        "\n",
        "# an.to_device(\"cpu\")\n",
        "\n",
        "generated_ids = an.generate(input_ids, max_length=128)\n",
        "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXJTcWjZn4Wv",
        "outputId": "912fc0be-c3c8-41b3-9a26-2c4b1fee5f3b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def hello_world():\n",
            "    print('Hello World!')\n",
            "\n",
            "hello_world()\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"draw = function()\"\n",
        "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.cuda()\n",
        "\n",
        "# an.to_device(\"cpu\")\n",
        "\n",
        "generated_ids = an.generate(input_ids, max_length=128)\n",
        "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4kH5EhMe7Dx",
        "outputId": "7a67a98d-a5f2-4ba2-b173-66f4cc10cf52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "draw = function() {\n",
            "    $(document).on('click', '#' + this.id, function(e) {\n",
            "      $(this).toggleClass('active');\n",
            "      $(this).siblings('.active').removeClass('active');\n",
            "      $(this).siblings('.active').addClass('active');\n",
            "      $(this).siblings('.active').siblings('.active').removeClass('active');\n",
            "      $(this).siblings('.active').siblings('.active').addClass('active');\n",
            "      $(this).siblings(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gene(text):\n",
        "  # text = \"draw = function()\"\n",
        "  input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.cuda()\n",
        "\n",
        "  # an.to_device(\"cpu\")\n",
        "\n",
        "  generated_ids = me.generate(input_ids, max_length=128)\n",
        "  print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "AgUpZpLAmGNH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "me.train()"
      ],
      "metadata": {
        "id": "tAeCfwaU2nBQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(me, \"/content/drive/MyDrive/bmo s/model.pt\")"
      ],
      "metadata": {
        "id": "LtG_jEq52RjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gene(\"move_player = function()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86Q0_y2L11Tz",
        "outputId": "fc6d8aef-667e-487d-a507-75c92d23fa7f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "move_player = function() {\n",
            "    $(\".move-player\").removeClass(\"move-player\");\n",
            "    $(\".move-player\").addClass(\"move-player-\" + $(\"#\" + $.cookie(\"move_player\")).val());\n",
            "    $(\".move-player\").val($(\"#\" + $.cookie(\"move_player\")).val());\n",
            "    $(\".move-player\").change(function() {\n",
            "      $(\".move-player\").removeClass(\"move-player\");\n",
            "      $(\".move-player\").addClass(\"move-\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
        "\n",
        "# text = \"def hello_world():\"\n",
        "# input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# generated_ids = model.generate(input_ids, max_length=128)\n",
        "# print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "rAUm2dR5RcfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trying somethign with the comments"
      ],
      "metadata": {
        "id": "C78H1Tnx3maJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "tNzc6asg34Rd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data.csv\", index_col=False)\n",
        "df['codes']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1QuvFwh3w-X",
        "outputId": "277a0b86-0fda-4d77-bcb5-907873f16443"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       if start then\\n  credits = {}\\n  \\n  \\n  credi...\n",
              "1       if start then\\n  map = {}\\n  \\n  \\n  map.name ...\n",
              "2       if start then\\n  player = {}\\n  \\n  \\n  player...\n",
              "3       function init()\\n  screen:setPixelated(\"pixela...\n",
              "4       function string:split(sep)\\n  local sep, field...\n",
              "                              ...                        \n",
              "1232    /*\\n  All of the code here is the level design...\n",
              "1233    mower=object\\n  \\n  init=function()\\n    ACC=0...\n",
              "1234    sfx=object\\n  \\n  init=function()\\n    sfxvol=...\n",
              "1235    /*\\n  Level section - Draws the 4x4 preview le...\n",
              "1236    game=object\\n  \\n  init=function()\\n    MAPXOF...\n",
              "Name: codes, Length: 1237, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_comment_code(string, spans):\n",
        "  coms = [string[a:b] for (a,b) in spans]\n",
        "  codes = []\n",
        "\n",
        "  for i in range(len(spans)):\n",
        "    start = spans[i][1]\n",
        "    if(i==len(spans)-1):\n",
        "      end = -1\n",
        "    else:\n",
        "      end = spans[i+1][0]\n",
        "    codes.append(string[start:end])\n",
        "\n",
        "  coms = [com.replace(\"//\", \" \").replace(\"\\n\",\" \") for com in coms]\n",
        "  \n",
        "  return coms, codes"
      ],
      "metadata": {
        "id": "Mh61mDkIl9Tb"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "l_comments = []\n",
        "l_codes = []\n",
        "\n",
        "for string in df['codes']:\n",
        "  if(type(string) != str):\n",
        "    continue\n",
        "  \n",
        "  l_spans = []\n",
        "  prev = -1\n",
        "\n",
        "  for i in re.finditer(r'\\s*//.*\\n',string):\n",
        "    if(prev == i.span()[0]):\n",
        "      temp = l_spans[-1][0]\n",
        "      del l_spans[-1]\n",
        "      l_spans.append((temp, i.span()[1]))\n",
        "    else:\n",
        "      l_spans.append((i.span()[0],i.span()[1]))\n",
        "    prev = i.span()[1]\n",
        "\n",
        "  com, cod = add_comment_code(string, l_spans)\n",
        "  l_comments += com\n",
        "  l_codes += cod"
      ],
      "metadata": {
        "id": "dVWbvQdR4ZWH"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns= [\"comments\", \"codes\"], data = [[l_comments[i], l_codes[i]] for i in range(len(l_comments))])"
      ],
      "metadata": {
        "id": "YoIfCvmfrzcR"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"comments\"].str.contains('door')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "A6qYXH-kr0l2",
        "outputId": "d355cdf1-d8a6-417f-f5da-b3ddff055632"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               comments  \\\n",
              "4477       outdoor overlay (changes darkness accordi...   \n",
              "4479                                    indoor overlay    \n",
              "4490                                  outdoor position    \n",
              "4584                  house front door target location    \n",
              "4612             At front doorway entry (from outdoor)    \n",
              "4613               At front doorway exit (from indoor)    \n",
              "4614           At rear doorway entry (from store room)    \n",
              "4615                At rear doorway exit (from indoor)    \n",
              "4764          ----        audio.playSound(\"open_door\")    \n",
              "4775                                 check inside door    \n",
              "4777                  print(\"hit closed door: \" + d....   \n",
              "4779                                         door find    \n",
              "\n",
              "                                                  codes  \n",
              "4477    screen.setAlpha(0.0)\\n  if gameclock.h<9 the...  \n",
              "4479    col=rgbToString(fireplace.r,fireplace.g,fire...  \n",
              "4490      if gamemode==\"indoor\" then farmer.x=31 far...  \n",
              "4584                end\\n    collections.push(c)\\n  end  \n",
              "4612      if active==\"enter house from outdoor\" then...  \n",
              "4613      if active==\"exit to outdoor\" then\\n      g...  \n",
              "4614      if active==\"enter house from storeroom\" th...  \n",
              "4615      if active==\"exit to storeroom\" then\\n     ...  \n",
              "4764      end\\n        \\n    \\n    if closed then\\n ...  \n",
              "4775          for d in doors\\n          local inside...  \n",
              "4777              else\\n             \\n             ...  \n",
              "4779            end\\n        end\\n      end\\n      \\...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73bdf54c-da85-4ed9-b527-b96ecba09621\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>codes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4477</th>\n",
              "      <td>outdoor overlay (changes darkness accordi...</td>\n",
              "      <td>screen.setAlpha(0.0)\\n  if gameclock.h&lt;9 the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4479</th>\n",
              "      <td>indoor overlay</td>\n",
              "      <td>col=rgbToString(fireplace.r,fireplace.g,fire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4490</th>\n",
              "      <td>outdoor position</td>\n",
              "      <td>if gamemode==\"indoor\" then farmer.x=31 far...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4584</th>\n",
              "      <td>house front door target location</td>\n",
              "      <td>end\\n    collections.push(c)\\n  end</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4612</th>\n",
              "      <td>At front doorway entry (from outdoor)</td>\n",
              "      <td>if active==\"enter house from outdoor\" then...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4613</th>\n",
              "      <td>At front doorway exit (from indoor)</td>\n",
              "      <td>if active==\"exit to outdoor\" then\\n      g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4614</th>\n",
              "      <td>At rear doorway entry (from store room)</td>\n",
              "      <td>if active==\"enter house from storeroom\" th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4615</th>\n",
              "      <td>At rear doorway exit (from indoor)</td>\n",
              "      <td>if active==\"exit to storeroom\" then\\n     ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4764</th>\n",
              "      <td>----        audio.playSound(\"open_door\")</td>\n",
              "      <td>end\\n        \\n    \\n    if closed then\\n ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4775</th>\n",
              "      <td>check inside door</td>\n",
              "      <td>for d in doors\\n          local inside...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4777</th>\n",
              "      <td>print(\"hit closed door: \" + d....</td>\n",
              "      <td>else\\n             \\n             ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4779</th>\n",
              "      <td>door find</td>\n",
              "      <td>end\\n        end\\n      end\\n      \\...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73bdf54c-da85-4ed9-b527-b96ecba09621')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73bdf54c-da85-4ed9-b527-b96ecba09621 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73bdf54c-da85-4ed9-b527-b96ecba09621');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Z01eM59vYLg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}